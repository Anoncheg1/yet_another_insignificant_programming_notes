<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-01-14 Tue 13:11 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org0c2fd41">1. NumPy</a>
<ul>
<li><a href="#org35339a0">1.1. frequent operations on shape</a>
<ul>
<li><a href="#orgb65d992">1.1.1. reshape((-1, 1)</a></li>
</ul>
</li>
<li><a href="#orgeb6f66f">1.2. theory</a></li>
<li><a href="#orgc47da3a">1.3. shape size dtype etc:</a></li>
<li><a href="#org12cd3f8">1.4. basic</a></li>
<li><a href="#org4e18a72">1.5. masking and comparision</a></li>
<li><a href="#org44c6e56">1.6. LOOPING</a></li>
<li><a href="#org00cf34e">1.7. replace</a></li>
<li><a href="#orge5222e6">1.8. round округление</a></li>
<li><a href="#org3cff5aa">1.9. keras.utils.to<sub>categorical</sub></a>
<ul>
<li><a href="#org2c23f00">1.9.1. basic</a></li>
<li><a href="#org113b087">1.9.2. add sum category</a></li>
</ul>
</li>
<li><a href="#org51ceee0">1.10. save and saves</a></li>
<li><a href="#orgeeac566">1.11. ignore items on diagonal</a></li>
<li><a href="#org5c55378">1.12. get items below diagonal (triangleform from squareform)</a></li>
<li><a href="#org9c71c39">1.13. broadcasting and vectorization</a></li>
</ul>
</li>
<li><a href="#org7d00076">2. pandas</a>
<ul>
<li><a href="#org52172c7">2.1. read csv</a></li>
<li><a href="#org455ceff">2.2. sort</a></li>
<li><a href="#orga28ff35">2.3. replace value</a></li>
<li><a href="#org7d58e53">2.4. <b>analysis</b></a></li>
<li><a href="#org9048027">2.5. Series</a></li>
<li><a href="#org29882cb">2.6. DataFrame</a></li>
<li><a href="#org973a995">2.7. index and levels</a></li>
<li><a href="#orgddde84b">2.8. WHERE AND FILTERS</a>
<ul>
<li><a href="#orgac1045a">2.8.1. filter by date</a></li>
</ul>
</li>
<li><a href="#orgacee716">2.9. COUNT</a>
<ul>
<li><a href="#org28b2fe2">2.9.1. get unique rows with count</a></li>
<li><a href="#orgba8caeb">2.9.2. count example</a></li>
<li><a href="#orgbac5ae4">2.9.3. most frequent</a></li>
</ul>
</li>
<li><a href="#org964248a">2.10. RESHAPINGS guide https://pandas.pydata.org/docs/user_guide/reshaping.html</a>
<ul>
<li><a href="#org088ad54">2.10.1. Resample for timeseries</a></li>
<li><a href="#org78dabfd">2.10.2. pivot - rows to columns without aggregation</a></li>
<li><a href="#org5499d63">2.10.3. stack (levels)</a></li>
<li><a href="#org26d24e5">2.10.4. melt - columns to rows</a></li>
<li><a href="#org11d6725">2.10.5. pivot<sub>table</sub> - allow aggs</a></li>
<li><a href="#orge4593b6">2.10.6. pivot tables(old)</a></li>
<li><a href="#org96b3601">2.10.7. crosstab - frequencies</a></li>
<li><a href="#org58cb77e">2.10.8. cut - transform continuous variables to discrete or categorical variables</a></li>
<li><a href="#orge4f3f80">2.10.9. dummies</a></li>
<li><a href="#org0adb62e">2.10.10. factorize - categories to numbers</a></li>
<li><a href="#orgfe9cdcd">2.10.11. explode</a></li>
<li><a href="#org174ea6c">2.10.12. assign and explode - split values to rows</a></li>
</ul>
</li>
<li><a href="#org17bbc3c">2.11. Merge, join, and concatenate</a>
<ul>
<li><a href="#org89fc0fe">2.11.1. concat series</a></li>
<li><a href="#orgca9fec4">2.11.2. concat datafremes vertically</a></li>
<li><a href="#org084860a">2.11.3. merge</a></li>
<li><a href="#orgdbcfe57">2.11.4. add by date</a></li>
</ul>
</li>
<li><a href="#org5253f24">2.12. DISTICT groupby</a>
<ul>
<li><a href="#org447f718">2.12.1. row number by group - добавить сложную номерацию по группам</a></li>
</ul>
</li>
<li><a href="#orge5a401f">2.13. two dataframes</a>
<ul>
<li><a href="#orge2d723b">2.13.1. sets comparision</a></li>
</ul>
</li>
<li><a href="#org892588d">2.14. Map, Apply, Applymap</a>
<ul>
<li><a href="#org80b16ac">2.14.1. Comparing map, applymap and apply: Context Matters</a></li>
<li><a href="#org67c38fe">2.14.2. apply to column</a></li>
<li><a href="#org71052c2">2.14.3. return multiple rows</a></li>
<li><a href="#orgdec5c9d">2.14.4. example</a></li>
</ul>
</li>
<li><a href="#org07ea1c9">2.15. save and load</a>
<ul>
<li><a href="#org3eb4108">2.15.1. read<sub>csv</sub></a></li>
<li><a href="#org46f5dbd">2.15.2. json</a></li>
</ul>
</li>
<li><a href="#org2ff07a5">2.16. NaN</a>
<ul>
<li><a href="#orgc7194cd">2.16.1. check</a></li>
<li><a href="#org7fa863b">2.16.2. replace</a></li>
<li><a href="#org0965f58">2.16.3. drop</a></li>
<li><a href="#orgc700f32">2.16.4. get not na</a></li>
<li><a href="#org89d50ec">2.16.5. other</a></li>
</ul>
</li>
<li><a href="#org4ec4d7c">2.17. Categorical encoding</a>
<ul>
<li><a href="#org85b1cd5">2.17.1. replace values</a></li>
<li><a href="#orge7c4754">2.17.2. label encoding</a></li>
<li><a href="#org1f0eea3">2.17.3. encode binary</a></li>
<li><a href="#org3e7a773">2.17.4. onehot encode</a></li>
</ul>
</li>
<li><a href="#orgf818c0f">2.18. mem usage</a></li>
<li><a href="#org7f05dbc">2.19. rename column</a></li>
<li><a href="#org24c3b13">2.20. delete column</a></li>
<li><a href="#org3165b56">2.21. delete row</a>
<ul>
<li><a href="#orgc8d7de1">2.21.1. delete NA</a></li>
<li><a href="#org79309aa">2.21.2. delete values that is in other df column</a></li>
</ul>
</li>
<li><a href="#org4dd10fe">2.22. type</a>
<ul>
<li><a href="#org13516b7">2.22.1. types https://numpy.org/doc/stable/reference/arrays.scalars.html</a></li>
<li><a href="#org7be2ee3">2.22.2. Display types</a></li>
<li><a href="#org61677d4">2.22.3. float to int</a></li>
<li><a href="#org48ebf09">2.22.4. string to date</a></li>
<li><a href="#org3b00f96">2.22.5. Category type</a></li>
</ul>
</li>
<li><a href="#orgd1246da">2.23. if a&gt;5 c = True else False</a></li>
<li><a href="#org8b7c5cb">2.24. OTHER USE CASES</a>
<ul>
<li><a href="#org5b0560a">2.24.1. dictionary for panda</a></li>
<li><a href="#org31a34cd">2.24.2. Example from dictionary to onehot</a></li>
<li><a href="#org59094f3">2.24.3. remove meanless columns</a></li>
<li><a href="#org119db94">2.24.4. Sum two columns containing NaN values</a></li>
<li><a href="#orgffd60f9">2.24.5. reorder columns</a></li>
<li><a href="#org893ba78">2.24.6. <span class="todo TODO">TODO</span> remove duplicates</a></li>
<li><a href="#org1f8d14e">2.24.7. replace missing values by groups</a></li>
<li><a href="#org55791aa">2.24.8. add count of occurences column</a></li>
</ul>
</li>
<li><a href="#orgba4b3a2">2.25. troubleshooting</a></li>
<li><a href="#orgf949752">2.26. pandas vs SQL</a></li>
<li><a href="#org9a30cfa">2.27. gentoo extensions</a></li>
</ul>
</li>
<li><a href="#orgde66e1f">3. xlsx Excel file loading</a>
<ul>
<li><a href="#org2d822c5">3.1. partially loading - no solution</a></li>
</ul>
</li>
<li><a href="#org5521d94">4. h5py</a>
<ul>
<li><a href="#orgd88c386">4.1. Dataset object</a></li>
<li><a href="#orgc20f53c">4.2. terms</a></li>
<li><a href="#org586ba49">4.3. open</a></li>
<li><a href="#orgfcbbfbf">4.4. usage</a></li>
<li><a href="#orgb99e276">4.5. links</a></li>
</ul>
</li>
<li><a href="#org3e87dfc">5. DVC</a>
<ul>
<li><a href="#orga6f1ec7">5.1. features:</a></li>
<li><a href="#org0e0abb7">5.2. problem</a></li>
<li><a href="#orgf114e77">5.3. terms</a></li>
<li><a href="#org9c66d72">5.4. steps</a>
<ul>
<li><a href="#org64f0e71">5.4.1. data:</a></li>
<li><a href="#orgaa1b1c1">5.4.2. pipelines</a></li>
</ul>
</li>
<li><a href="#orge8041f8">5.5. CML - Continuous Machine Learning</a></li>
<li><a href="#orgc1f1692">5.6. links</a></li>
</ul>
</li>
<li><a href="#orgd766312">6. matplotlib</a>
<ul>
<li><a href="#org50fe13a">6.1. base</a></li>
<li><a href="#org5ff218d">6.2. subplot or multiple diagram in one window</a></li>
<li><a href="#orgca3a3f9">6.3. x axis labels range</a></li>
<li><a href="#org7c37f00">6.4. Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.</a>
<ul>
<li><a href="#org7573b97">6.4.1. TkAgg</a></li>
<li><a href="#org51366cf">6.4.2. GTK3Agg</a></li>
</ul>
</li>
<li><a href="#org45a0e3d">6.5. usage</a></li>
<li><a href="#orge9857c4">6.6. do not close</a></li>
<li><a href="#org08d3fd5">6.7. Multiple Curves</a></li>
<li><a href="#orgfcaa070">6.8. two windows with separate legend</a></li>
<li><a href="#org6b7e44a">6.9. custom histogram</a></li>
<li><a href="#orgcaff2f6">6.10. rotate x ticks</a></li>
<li><a href="#org516d08b">6.11. CASES</a>
<ul>
<li><a href="#orgf8aab3c">6.11.1. <span class="todo TODO">TODO</span> bar plot with two y axes</a></li>
<li><a href="#org32c03d8">6.11.2. varible in time</a></li>
<li><a href="#org9f75269">6.11.3. example plot grid</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgf3238bd">7. pygal</a>
<ul>
<li><a href="#orge145bc4">7.1. boxes</a></li>
<li><a href="#org5f444b7">7.2. several separate</a></li>
</ul>
</li>
<li><a href="#org704380c">8. seaborn</a></li>
<li><a href="#org6df51e4">9. SciPy</a>
<ul>
<li><a href="#org8d74293">9.1. hierarchical lustering</a>
<ul>
<li><a href="#org009ae83">9.1.1. distance and squareform</a></li>
<li><a href="#org2ab86e5">9.1.2. linkage</a></li>
<li><a href="#org22e1552">9.1.3. dendrogram</a></li>
<li><a href="#org98f101e">9.1.4. cophentic correlation</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgf19da48">10. Scikit-learn</a>
<ul>
<li><a href="#orga74b0d9">10.1. history</a></li>
<li><a href="#orgf28bc6a">10.2. fast feature selection</a></li>
<li><a href="#org3ce6637">10.3. sklearn.tree.DecisionTreeClassifier</a>
<ul>
<li><a href="#org45f8dc3">10.3.1. usage</a></li>
</ul>
</li>
<li><a href="#org7d3e4e6">10.4. Tuning the hyper-parameters https://scikit-learn.org/stable/modules/grid_search.html</a></li>
<li><a href="#org2f078ea">10.5. feature importance</a></li>
<li><a href="#org53e79d8">10.6. Encoders - sklearn.preprocessing.*</a></li>
<li><a href="#org936120e">10.7. suppress warnings</a></li>
</ul>
</li>
<li><a href="#org6e8d19f">11. <span class="todo TODO">TODO</span> statsmodels</a></li>
<li><a href="#orgc0f9c45">12. <span class="todo TODO">TODO</span> RAPIDS</a></li>
<li><a href="#orgbfe04a8">13. TensorFlow (TF)</a>
<ul>
<li><a href="#org0f86393">13.1. history</a></li>
<li><a href="#org26337b8">13.2. terms</a></li>
<li><a href="#org7e3aff5">13.3. Features:</a></li>
<li><a href="#org8ffb24a">13.4. hello world</a></li>
<li><a href="#org1d661a0">13.5. deployment</a></li>
<li><a href="#org56008bd">13.6. ecosystem</a></li>
<li><a href="#orgf6c3664">13.7. layours</a></li>
<li><a href="#org4e3ad9b">13.8. Eager vs Grapth execution</a>
<ul>
<li><a href="#org617e3c0">13.8.1. links</a></li>
</ul>
</li>
<li><a href="#orga9f23fa">13.9. TF 2.0</a>
<ul>
<li><a href="#orgdfcbe6b">13.9.1. tf.GradientTape API</a></li>
<li><a href="#orgbb38e5f">13.9.2. tf.function</a></li>
<li><a href="#org4dea415">13.9.3. migrate 1 to 2</a></li>
<li><a href="#orgbbebfa2">13.9.4. custome layer</a></li>
<li><a href="#org89b26ed">13.9.5. decayed learning rate</a></li>
<li><a href="#org9c3cf35">13.9.6. layer-wise learning rate in Tensorflow?</a></li>
</ul>
</li>
<li><a href="#orgfbc8a5f">13.10. Save a model</a>
<ul>
<li><a href="#orgc8d379b">13.10.1. v1 Saver loading:</a></li>
<li><a href="#orgb9e20e7">13.10.2. v2 saving loading</a></li>
</ul>
</li>
<li><a href="#org03ecb97">13.11. datasets</a>
<ul>
<li><a href="#org58cebae">13.11.1. install and use tfds</a></li>
<li><a href="#org6254fae">13.11.2. download</a></li>
<li><a href="#org9693fe4">13.11.3. landmark 2020</a></li>
<li><a href="#orgfa2e55e">13.11.4. mnist</a></li>
</ul>
</li>
<li><a href="#org58eb80b">13.12. tf.data.dataset</a>
<ul>
<li><a href="#orgff04a5b">13.12.1. test</a></li>
</ul>
</li>
<li><a href="#org27b9182">13.13. install</a></li>
<li><a href="#orga7a23e3">13.14. install from source</a></li>
<li><a href="#org598bdc2">13.15. APIs</a></li>
<li><a href="#org416fbe9">13.16. tf.placeholder</a></li>
<li><a href="#org7eef3bf">13.17. Logger = Disable</a></li>
<li><a href="#orgd9d9661">13.18. 4D tensor </a></li>
<li><a href="#org7bb9a94">13.19. install</a></li>
<li><a href="#org2652efe">13.20. Deploy</a></li>
<li><a href="#org6363e4e">13.21. tensor</a></li>
<li><a href="#org28b7416">13.22. hardware</a></li>
<li><a href="#orgdf7c940">13.23. hello world</a></li>
<li><a href="#org3371430">13.24. main objects</a></li>
<li><a href="#orgea07880">13.25. Переменные</a></li>
<li><a href="#orge0eead1">13.26. TensorBoard</a></li>
<li><a href="#orge524dd5">13.27. GPU</a></li>
<li><a href="#orgfa05aa6">13.28. keras</a></li>
<li><a href="#org2842634">13.29. CNN</a></li>
<li><a href="#org9d27e05">13.30. RNN and LSTM</a>
<ul>
<li><a href="#org764f9aa">13.30.1. CNN</a></li>
<li><a href="#org2624f19">13.30.2. batch</a></li>
</ul>
</li>
<li><a href="#org766ef6e">13.31. plot learning curve</a></li>
<li><a href="#orgf22c122">13.32. plot CNN layout</a></li>
<li><a href="#orgb34ab04">13.33. Optimizer</a></li>
<li><a href="#orge18ba36">13.34. models - tensorflow<sub>models</sub> as tfm</a>
<ul>
<li><a href="#orgc4c0bed">13.34.1. install</a></li>
<li><a href="#org9f3b30e">13.34.2. usage</a></li>
<li><a href="#org5441171">13.34.3. mnist</a></li>
<li><a href="#org802348c">13.34.4. dummy dataset for MNIST</a></li>
<li><a href="#org1289558">13.34.5. Mobilenet example</a></li>
<li><a href="#org9e77d49">13.34.6. RESNET example</a></li>
</ul>
</li>
<li><a href="#orgb2007f5">13.35. TensorFlow Serving</a>
<ul>
<li><a href="#orgdac3456">13.35.1. terms</a></li>
</ul>
</li>
<li><a href="#org7f95c0e">13.36. <span class="todo TODO">TODO</span> TFX pipeline - MLOps</a></li>
<li><a href="#org8a4a72b">13.37. loss</a></li>
<li><a href="#orgbeb7a9c">13.38. ctc<sub>loss</sub></a></li>
<li><a href="#orgb2b8851">13.39. custom metric</a>
<ul>
<li><a href="#org76afeca">13.39.1. function</a></li>
<li><a href="#orge2833be">13.39.2. class</a></li>
</ul>
</li>
<li><a href="#orgb581e38">13.40. distributed training</a>
<ul>
<li><a href="#orga6c540e">13.40.1. API</a></li>
<li><a href="#org49cf41d">13.40.2. terms</a></li>
<li><a href="#orge8ceab8">13.40.3. Synchronous vs asynchronous training</a></li>
<li><a href="#org442500a">13.40.4. strategies</a></li>
<li><a href="#org924aa92">13.40.5. TF<sub>CONFIG</sub></a></li>
<li><a href="#org581f4dd">13.40.6. data sharding</a></li>
<li><a href="#org28877cb">13.40.7. links</a></li>
<li><a href="#org931e299">13.40.8. monitor</a></li>
</ul>
</li>
<li><a href="#orgfaa94ab">13.41. toy model MNIST</a></li>
<li><a href="#org6fab8e5">13.42. logging</a>
<ul>
<li><a href="#orgcc8d148">13.42.1. standard way</a></li>
<li><a href="#org013b630">13.42.2. pipe</a></li>
<li><a href="#orgc5d0332">13.42.3. logging</a></li>
<li><a href="#orgb370170">13.42.4. links</a></li>
</ul>
</li>
<li><a href="#org521ea95">13.43. callbacks for model.fit</a></li>
<li><a href="#orgb0d82ec">13.44. USE CASES</a>
<ul>
<li><a href="#org2e84d9e">13.44.1. TF 2.0 convert mode h5 to weight and arch</a></li>
<li><a href="#orgb192f3b">13.44.2. imbalanced dataset</a></li>
</ul>
</li>
<li><a href="#org0d6f113">13.45. common errors:</a></li>
</ul>
</li>
<li><a href="#org2b60174">14. PyTorch</a>
<ul>
<li><a href="#org8fc5231">14.1. install</a></li>
<li><a href="#orga402dc2">14.2. history</a>
<ul>
<li><a href="#org88f82b8">14.2.1. PyTorch 2.0</a></li>
<li><a href="#org5114d8c">14.2.2. FlashAttention-2 - approximate attention method</a></li>
</ul>
</li>
<li><a href="#org7e36985">14.3. deployment</a></li>
<li><a href="#orgd7c393f">14.4. ecosystem</a></li>
<li><a href="#orge66cc07">14.5. PyTorch 2.0</a></li>
<li><a href="#org9fe7310">14.6. device</a>
<ul>
<li><a href="#org9e74a73">14.6.1. HIP</a></li>
<li><a href="#org5880c5a">14.6.2. cuda test</a></li>
<li><a href="#org5c036b1">14.6.3. TPU</a></li>
</ul>
</li>
<li><a href="#org7a966ab">14.7. models - torchvision.models</a></li>
<li><a href="#orga7e5224">14.8. nn.Module</a>
<ul>
<li><a href="#orga64eea5">14.8.1. nn.Linear</a></li>
<li><a href="#orgdadea5b">14.8.2. links</a></li>
</ul>
</li>
<li><a href="#org6e68f5f">14.9. Dataset and DataLoader, transform</a>
<ul>
<li><a href="#org9ed9628">14.9.1. code</a></li>
<li><a href="#org1bdcc1e">14.9.2. links</a></li>
</ul>
</li>
<li><a href="#org96f515e">14.10. Built-in datasets</a></li>
<li><a href="#org9344d2c">14.11. train</a>
<ul>
<li><a href="#orgd46e1d6">14.11.1. links</a></li>
</ul>
</li>
<li><a href="#orgc94d75e">14.12. train (old)</a></li>
<li><a href="#orgaf74263">14.13. loss, inference, accuracy</a></li>
<li><a href="#org97fbbdd">14.14. numpy</a></li>
<li><a href="#org295c39b">14.15. layers</a></li>
<li><a href="#org8dc1244">14.16. noise</a></li>
<li><a href="#org36d0014">14.17. basic nn and gradient</a>
<ul>
<li><a href="#org38a87f3">14.17.1. first</a></li>
<li><a href="#org28060d1">14.17.2. second</a></li>
</ul>
</li>
<li><a href="#orgea4f7fc">14.18. LSTM</a>
<ul>
<li><a href="#org6142a6c">14.18.1. nn.LSTM</a></li>
<li><a href="#org320bbe3">14.18.2. nn.LSTMCell</a></li>
<li><a href="#org22ce181">14.18.3. numbers of parameters</a></li>
<li><a href="#orgd95f61b">14.18.4. basic</a></li>
<li><a href="#org0494bf2">14.18.5. tagging model</a></li>
<li><a href="#org9c5b0e3">14.18.6. variable-sized mini-batches</a></li>
<li><a href="#org4b069a9">14.18.7. GPU CUDA</a></li>
<li><a href="#org17fb2c7">14.18.8. SGD</a></li>
</ul>
</li>
<li><a href="#org7f6369e">14.19. Distributed - torch.distributed</a>
<ul>
<li><a href="#org1796adc">14.19.1. overview</a></li>
<li><a href="#orga01dbea">14.19.2. torch.distributed.rpc</a></li>
<li><a href="#orgd9b7b28">14.19.3. FSDP</a></li>
<li><a href="#org27cc8c7">14.19.4. elastic (launch)</a></li>
<li><a href="#org2e67475">14.19.5. torch.distributed.launch</a></li>
<li><a href="#orgde523e1">14.19.6. KubeFlow PyTorchJob</a></li>
<li><a href="#org3203cfd">14.19.7. investiage</a></li>
<li><a href="#org031f06e">14.19.8. links</a></li>
</ul>
</li>
<li><a href="#org797d153">14.20. retain<sub>graph</sub></a></li>
<li><a href="#org5a7d733">14.21. memory management</a></li>
<li><a href="#orgfa97200">14.22. troubleshooting</a></li>
<li><a href="#orge5dcb63">14.23. plot learning curve</a></li>
<li><a href="#org479ddbc">14.24. Finetuning</a></li>
<li><a href="#orgb179cb2">14.25. links</a></li>
</ul>
</li>
<li><a href="#orgf89cc21">15. ONNX</a>
<ul>
<li><a href="#org138e30e">15.1. Terms</a></li>
<li><a href="#org2536c4a">15.2. CASE: Get version</a></li>
<li><a href="#orgb72eb77">15.3. Usage</a></li>
<li><a href="#org481f269">15.4. Visualization - netron</a></li>
<li><a href="#org8e1c1ce">15.5. ONNX format</a></li>
<li><a href="#orgba42f11">15.6. doc:</a></li>
</ul>
</li>
<li><a href="#org7c66337">16. LangChain</a>
<ul>
<li><a href="#orge1c99cc">16.1. terms</a></li>
<li><a href="#org4e633d5">16.2. GigaChat</a></li>
<li><a href="#org091b4db">16.3. Chat Models</a></li>
<li><a href="#orgb6d6197">16.4. messages and batch messages</a></li>
<li><a href="#org581c073">16.5. Prompt Templates</a></li>
<li><a href="#orgd8019b2">16.6. Memory Types in Langchain</a></li>
</ul>
</li>
<li><a href="#orgde4c615">17. MLFlow - experiment tracking</a>
<ul>
<li><a href="#orgc666b95">17.1. features</a></li>
<li><a href="#org4ba099d">17.2. terms</a></li>
<li><a href="#orgff90b4f">17.3. installation</a></li>
<li><a href="#orgc330bea">17.4. framework styles:</a></li>
<li><a href="#org8c71de9">17.5. Usage</a>
<ul>
<li><a href="#org3bcdf8b">17.5.1. monitor experiment locally</a></li>
<li><a href="#org0616019">17.5.2. store first locally</a></li>
</ul>
</li>
<li><a href="#org5d3e0ae">17.6. tracking URI</a></li>
<li><a href="#org74dc3ea">17.7. tracking API</a></li>
<li><a href="#orgdb47ccf">17.8. MlflowClient</a>
<ul>
<li><a href="#orge678669">17.8.1. model registry - list models, register model</a></li>
<li><a href="#orgf7cd8d4">17.8.2. model registry - search<sub>runs</sub></a></li>
<li><a href="#orgf881762">17.8.3. runs</a></li>
</ul>
</li>
<li><a href="#org4205961">17.9. MLflow Tracing - @mlflow.trace</a></li>
<li><a href="#orgd8c09f2">17.10. Not supported:</a></li>
</ul>
</li>
<li><a href="#orgede5daa">18. Perfect</a>
<ul>
<li><a href="#org0a941df">18.1. terms</a></li>
<li><a href="#orgf7b1bdd">18.2. links</a></li>
</ul>
</li>
<li><a href="#org26d32d2">19. <span class="todo TODO">TODO</span> PaddlePaddle 飞桨</a></li>
<li><a href="#orgb3a802f">20. huggingface.co</a>
<ul>
<li><a href="#org4270cee">20.1. Dateset</a>
<ul>
<li><a href="#org3ec71eb">20.1.1. load</a></li>
<li><a href="#orgde1b4da">20.1.2. explore</a></li>
</ul>
</li>
<li><a href="#org3fd7d8e">20.2. pip packages</a>
<ul>
<li><a href="#org24e2afd">20.2.1. huggingface-hub</a></li>
<li><a href="#orge8580d6">20.2.2. transformers </a></li>
<li><a href="#org060cd7a">20.2.3. pytorch-image-models</a></li>
<li><a href="#org9eb382f">20.2.4. diffusers</a></li>
<li><a href="#org8b8f49a">20.2.5. datasets</a></li>
<li><a href="#orgef61daf">20.2.6. peft - Parameter-Efficient Fine-Tuning</a></li>
<li><a href="#orgb0a1886">20.2.7. candle - ML framework for Rust</a></li>
<li><a href="#org5924789">20.2.8. trl - reinforcement learning for Transformers.</a></li>
<li><a href="#org5dbb56c">20.2.9. tokenizers</a></li>
<li><a href="#orgdce3c3a">20.2.10. text-generation-inference - LLMs</a></li>
<li><a href="#org48aba8c">20.2.11. accelerate</a></li>
<li><a href="#org89b8d63">20.2.12. lerobot - Learning for Real-World Robotics in Pytorch</a></li>
<li><a href="#org2112899">20.2.13. text-embeddings-inference</a></li>
</ul>
</li>
<li><a href="#org8a01b73">20.3. pages</a></li>
<li><a href="#orgc8a3541">20.4. reduce inference</a>
<ul>
<li><a href="#orga443010">20.4.1. quantization</a></li>
<li><a href="#org98e9bfa">20.4.2. <span class="todo TODO">TODO</span> pruning</a></li>
</ul>
</li>
<li><a href="#org9458abe">20.5. transformers</a>
<ul>
<li><a href="#orge2b3412">20.5.1. theory</a></li>
<li><a href="#org4bc44cc">20.5.2. base</a></li>
<li><a href="#org105d4da">20.5.3. scipts</a></li>
<li><a href="#orgc75aab6">20.5.4. installation log</a></li>
</ul>
</li>
<li><a href="#org63465e1">20.6. accelerate - DISTRIBUTED </a>
<ul>
<li><a href="#orgb91d464">20.6.1. hello world</a></li>
<li><a href="#org3222be8">20.6.2. links</a></li>
</ul>
</li>
<li><a href="#org45a63ee">20.7. PEFT - DISTRIBUTED</a>
<ul>
<li><a href="#org49c36f5">20.7.1. links</a></li>
</ul>
</li>
<li><a href="#org7c11d4d">20.8. TRL </a>
<ul>
<li><a href="#org6190699">20.8.1. links</a></li>
</ul>
</li>
<li><a href="#org5a04bb5">20.9. Spaces</a></li>
<li><a href="#org2bbda99">20.10. cache and offline mode</a>
<ul>
<li><a href="#org6eac56b">20.10.1. transformers</a></li>
</ul>
</li>
<li><a href="#orge8563c5">20.11. Main concepts</a></li>
<li><a href="#org4b48c56">20.12. problems:</a></li>
<li><a href="#orgfc91bde">20.13. pip install gradio<sub>client</sub></a></li>
<li><a href="#org78c7815">20.14. sci-libs/huggingface<sub>hub</sub></a>
<ul>
<li><a href="#org47842c2">20.14.1. links</a></li>
</ul>
</li>
<li><a href="#orgadad17b">20.15. autotrain</a></li>
<li><a href="#org5a21c40">20.16. AutoTokenizer.from<sub>pretrained</sub></a></li>
<li><a href="#org0034747">20.17. AutoModel.from<sub>pretrained</sub></a></li>
<li><a href="#org83914ae">20.18. gentoo transformers installation</a>
<ul>
<li><a href="#org1c24a91">20.18.1. setup.py and gentoo ebuild</a></li>
</ul>
</li>
<li><a href="#org73a93b3">20.19. troubleshooting</a>
<ul>
<li><a href="#org61d0476">20.19.1. TypeError: unhashable type: 'AddedToken' in transformers/tokenization<sub>utils.py</sub>", line 437</a></li>
<li><a href="#org765f496">20.19.2. AttributeError: 'AddedToken' object has no attribute '<span class="underline"><span class="underline">setstate</span></span>'. Did you mean: '<span class="underline"><span class="underline">getstate</span></span>'?</a></li>
</ul>
</li>
<li><a href="#orgd120938">20.20. distributed</a></li>
<li><a href="#org6c12ceb">20.21. Text embeddings models</a></li>
<li><a href="#orgd09095a">20.22. links</a></li>
</ul>
</li>
</ul>
</div>
</div>
<p>
-<b>- mode: Org; fill-column: 110; coding: utf-8; -</b>-
#+TITLE  Python for data science
</p>
<div id="outline-container-org0c2fd41" class="outline-2">
<h2 id="org0c2fd41"><span class="section-number-2">1.</span> NumPy</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li><a href="https://docs.scipy.org/doc/numpy/reference/">https://docs.scipy.org/doc/numpy/reference/</a></li>
<li><a href="https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html">https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html</a></li>
</ul>
</div>
<div id="outline-container-org35339a0" class="outline-3">
<h3 id="org35339a0"><span class="section-number-3">1.1.</span> frequent operations on shape</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-orgb65d992" class="outline-4">
<h4 id="orgb65d992"><span class="section-number-4">1.1.1.</span> reshape((-1, 1)</h4>
<div class="outline-text-4" id="text-1-1-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">x</span> = np.array([1,2,3,4,5])
<span style="color: #e5786d;">print</span>(np.concatenate((x, x)).reshape((-1, 1)))
</pre>
</div>

<pre class="example" id="orgb8b8f5d">
[[1]
 [2]
 [3]
 [4]
 [5]
 [1]
 [2]
 [3]
 [4]
 [5]]
</pre>
</div>
</div>
</div>
<div id="outline-container-orgeb6f66f" class="outline-3">
<h3 id="orgeb6f66f"><span class="section-number-3">1.2.</span> theory</h3>
<div class="outline-text-3" id="text-1-2">
<p>
[ˈnʌmpaɪ] large, multi-dimensional arrays and matrices.  BSD-new license.  multi-dimensional container of
generic data
</p>
<ul class="org-ul">
<li>a powerful N-dimensional array object</li>
<li>sophisticated (broadcasting) functions</li>
<li>useful linear algebra, Fourier transform, and random number capabilities</li>
</ul>

<p>
<b>ndarray</b> - n-dimensional array
</p>
<ul class="org-ul">
<li>homogeneously typed: all elements of a single array must be of the same type</li>
<li>np.pad(&#x2026;) routine to extend arrays actually creates new arrays of the desired shape and padding values,
copies the given array into the new one and returns it</li>
</ul>

<p>
Type hint
</p>
<pre class="example">
def f(x: np.ndarray) -&gt; np.ndarray
</pre>


<p>
&#x2026; = : - Ellipse ones[:,5] - пятый слобец
</p>
</div>
</div>
<div id="outline-container-orgc47da3a" class="outline-3">
<h3 id="orgc47da3a"><span class="section-number-3">1.3.</span> shape size dtype etc:</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li>ndarray.shape</li>
<li>ndarray.size - произведение чисел в shape</li>
<li>ndarray.dtype - bool_, character, int8, int16, int32, int64, float8, float16, float32, float64, complex64, object_</li>
<li>ndarray.itemsize - размер элемента в байтах</li>
<li>ndarray.data - обратно в python - не рекомендуется пользоваться</li>
</ul>
</div>
</div>
<div id="outline-container-org12cd3f8" class="outline-3">
<h3 id="org12cd3f8"><span class="section-number-3">1.4.</span> basic</h3>
<div class="outline-text-3" id="text-1-4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">a</span> = np.array([1, 2, 3])
a[[1,2]] <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">array([2, 3])</span>

&gt;&gt;&gt; np.arange(4).reshape((2,2))
array([[0, 1],
       [2, 3]])
&gt;&gt;&gt; <span style="color: #cae682;">a</span> = np.arange(4).reshape((2,2))
&gt;&gt;&gt; a
array([[0, 1],
       [2, 3]])
&gt;&gt;&gt; a.<span style="color: #e5786d;">sum</span>(axis=0)
array([2, 4])
&gt;&gt;&gt; a.<span style="color: #e5786d;">sum</span>(1)
array([1, 5])
&gt;&gt;&gt; a.<span style="color: #e5786d;">sum</span>(-1)
array([1, 5])

<span style="color: #cae682;">x</span> = np.array([[1,2],[3,4]])
x[:,0] <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">array([1, 3])</span>

np.zeros((3, 5), dtype=<span style="color: #e5786d;">float</span>) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dtype - &#1087;&#1086; &#1091;&#1084;&#1086;&#1083;&#1095;&#1072;&#1085;&#1080;&#1102; float</span>
np.ones((2, 2, 2)) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">all 1</span>
np.eye(5) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1077;&#1076;&#1080;&#1085;&#1080;&#1094;&#1099; &#1085;&#1072; &#1076;&#1080;&#1072;&#1075;&#1086;&#1085;&#1072;&#1083;&#1080;</span>
np.empty((3, 3)) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1089;&#1083;&#1091;&#1095;&#1072;&#1081;&#1085;&#1086;&#1077; &#1082;&#1072;&#1082;&#1072;&#1103; &#1073;&#1099;&#1083;&#1072; &#1087;&#1072;&#1084;&#1103;&#1090;&#1100; &#1090;&#1072;&#1082; &#1080; &#1079;&#1072;&#1087;&#1086;&#1083;&#1085;&#1080;&#1083;&#1072;&#1089;&#1100;</span>
np.arange(10, 30, 5) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">range</span>
np.linspace(0, 2, 9) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1086;&#1090; 0 &#1076;&#1086; 2 - &#1089;&#1086;&#1079;&#1076;&#1072;&#1090;&#1100; 9 &#1096;&#1090;&#1091;&#1082;</span>
np.logspace(start, stop, num=50, endpoint=<span style="color: #e5786d; font-weight: bold;">True</span>, base=10.0) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">base**start - base ** stop &#1089; &#1091;&#1089;&#1082;&#1086;&#1088;&#1077;&#1085;&#1080;&#1077;&#1084;</span>

np.amax(nparray) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">max element</span>
np.amin(nparray) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">min element</span>
np.nanmin(data[:, 1]) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">max element at column 1</span>

<span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">img</span>[:] = 255 <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">replace every element with single value</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">filter None elements:</span>
<span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">contours</span> = np.array(<span style="color: #e5786d;">list</span>(<span style="color: #e5786d;">filter</span>(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x:x <span style="color: #8ac6f2; font-weight: bold;">is</span> <span style="color: #8ac6f2; font-weight: bold;">not</span> <span style="color: #e5786d; font-weight: bold;">None</span>, <span style="color: #8ac6f2; font-weight: bold;">self</span>.contours)))

<span style="color: #fa8072;">#</span>
<span style="color: #cae682;">a</span> = np.linspace(-np.pi, np.pi, 100)
<span style="color: #cae682;">b</span> = np.sin(a)
<span style="color: #cae682;">c</span> = np.cos(a)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Linear algebra</span>
<span style="color: #8ac6f2; font-weight: bold;">from</span> numpy.random <span style="color: #8ac6f2; font-weight: bold;">import</span> rand
<span style="color: #8ac6f2; font-weight: bold;">from</span> numpy.linalg <span style="color: #8ac6f2; font-weight: bold;">import</span> solve, inv
<span style="color: #cae682;">a</span> = np.array([[1, 2, 3], [3, 4, 6.7], [5, 9.0, 5]])
a.transpose()
array([[ 1. ,  3. ,  5. ],
       [ 2. ,  4. ,  9. ],
       [ 3. ,  6.7,  5. ]])
inv(a)
array([[-2.27683616,  0.96045198,  0.07909605],
       [ 1.04519774, -0.56497175,  0.1299435 ],
       [ 0.39548023,  0.05649718, -0.11299435]])
<span style="color: #cae682;">b</span> =  np.array([3, 2, 1])
solve(a, b)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">solve the equation ax = b</span>
array([-4.83050847,  2.13559322,  1.18644068])

<span style="color: #cae682;">c</span> = rand(3, 3) * 20  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">create a 3x3 random matrix of values within [0,1] scaled by 20</span>
array([[  3.98732789,   2.47702609,   4.71167924],
       [  9.24410671,   5.5240412 ,  10.6468792 ],
       [ 10.38136661,   8.44968437,  15.17639591]])
np.dot(a, c)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">matrix multiplication</span>
a @ c <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Starting with Python 3.5 and NumPy 1.10</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">per column operations</span>
<span style="color: #cae682;">data</span>[:, 1] = (data[:, 1] - data_min)
<span style="color: #cae682;">data</span>[:,1] +=1

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Add dimension</span>
<span style="color: #cae682;">x</span> = np.expand_dims(x, axis=0)
<span style="color: #cae682;">x</span> = x[np.newaxis, :]

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">elemets at positons</span>
<span style="color: #cae682;">a</span> = a[np.array([1, 2, 10, 3])]
</pre>
</div>
</div>
</div>
<div id="outline-container-org4e18a72" class="outline-3">
<h3 id="org4e18a72"><span class="section-number-3">1.5.</span> masking and comparision</h3>
<div class="outline-text-3" id="text-1-5">
<ul class="org-ul">
<li>x&gt;1 - Boolean array indexing [True, False]</li>
<li>x[x&gt;1] - select elements with True</li>
<li>(a[1,:]!=2) &amp; (a[1,:]!=2) - and</li>
<li>cv2.bitwise<sub>not</sub>(gray)</li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">a</span> = array([1, 2, 3, 4, 4])
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">get elements where &gt;2</span>
a[np.where( a &gt; 2)]
&gt;&gt; array([1, 2, 3, 4, 4])
a[a &gt; 2]
&gt;&gt; array([1, 2, 3, 4, 4])
</pre>
</div>
</div>
</div>

<div id="outline-container-org44c6e56" class="outline-3">
<h3 id="org44c6e56"><span class="section-number-3">1.6.</span> LOOPING</h3>
<div class="outline-text-3" id="text-1-6">
<p>
substarct every [9,3,6] from [1,2,3,4,5,6] and find min of abs:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">c</span> = [1,2,3,4,5,6]
<span style="color: #cae682;">s</span> = [9,3,6]
<span style="color: #cae682;">su</span> = np.repeat([c],<span style="color: #e5786d;">len</span>(s),axis=0).T - s
<span style="color: #cae682;">m</span> = np.<span style="color: #e5786d;">min</span>(np.<span style="color: #e5786d;">abs</span>(su), axis=0)
<span style="color: #e5786d;">print</span>(m)
</pre>
</div>
</div>
</div>

<div id="outline-container-org00cf34e" class="outline-3">
<h3 id="org00cf34e"><span class="section-number-3">1.7.</span> replace</h3>
<div class="outline-text-3" id="text-1-7">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">my_array</span>[my_array == 8] = 20
<span style="color: #cae682;">my_array</span>[(my_array &gt; 8) | (my_array &lt; 6)] = 20
<span style="color: #cae682;">result</span>= np.where(new_array==np.inf, 0, new_array)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">inf</span>
<span style="color: #cae682;">result</span>=np.where(np.isinf(a), 999999, a)
<span style="color: #cae682;">result</span>=np.where(np.isnan(a), 0, a)
np.place(new_values, new_values&lt;0, [0])
</pre>
</div>
</div>
</div>

<div id="outline-container-orge5222e6" class="outline-3">
<h3 id="orge5222e6"><span class="section-number-3">1.8.</span> round округление</h3>
<div class="outline-text-3" id="text-1-8">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">a</span> = np.array([1.1, 1.5, 1.9], <span style="color: #e5786d;">float</span>)
&gt;&gt;&gt; np.floor(a)
array([ 1.,  1.,  1.])
&gt;&gt;&gt; np.ceil(a)
array([ 2.,  2.,  2.])
&gt;&gt;&gt; np.rint(a)
array([ 1.,  2.,  2.])
</pre>
</div>
</div>
</div>

<div id="outline-container-org3cff5aa" class="outline-3">
<h3 id="org3cff5aa"><span class="section-number-3">1.9.</span> keras.utils.to<sub>categorical</sub></h3>
<div class="outline-text-3" id="text-1-9">
</div>
<div id="outline-container-org2c23f00" class="outline-4">
<h4 id="org2c23f00"><span class="section-number-4">1.9.1.</span> basic</h4>
<div class="outline-text-4" id="text-1-9-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">y_classes</span> = keras.utils.to_categorical(<span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(paths))) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">classes array in one-hot</span>
train_y.append(y_classes[i]) <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">to set</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">back</span>
<span style="color: #cae682;">out</span> = model.predict
<span style="color: #cae682;">i</span> = np.argmax(out, axis=-1)[0] <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">id</span>
paths[i] <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">original</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org113b087" class="outline-4">
<h4 id="org113b087"><span class="section-number-4">1.9.2.</span> add sum category</h4>
<div class="outline-text-4" id="text-1-9-2">
<div class="org-src-container">
<pre class="src src-python">&gt;&gt;&gt; c
array([[1., 0.],
       [0., 1.]], dtype=float32)
np.append(c, [c[0]+c[1]], axis=0)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">result:</span>
array([[1., 0.],
       [0., 1.],
       [1., 1.]], dtype=float32)
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org51ceee0" class="outline-3">
<h3 id="org51ceee0"><span class="section-number-3">1.10.</span> save and saves</h3>
<div class="outline-text-3" id="text-1-10">
<pre class="example">
np.save('123', data) # 123.npy
data = np.load('../123.npy', mmap_mode=None)
</pre>
</div>
</div>

<div id="outline-container-orgeeac566" class="outline-3">
<h3 id="orgeeac566"><span class="section-number-3">1.11.</span> ignore items on diagonal</h3>
<div class="outline-text-3" id="text-1-11">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">not_diag</span> = np.where(~np.eye(dists.shape[0],dtype=<span style="color: #e5786d;">bool</span>))
<span style="color: #cae682;">cl_distance</span> = np.mean(dists[not_diag]) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">mean mey be replace with something close to median</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org5c55378" class="outline-3">
<h3 id="org5c55378"><span class="section-number-3">1.12.</span> get items below diagonal (triangleform from squareform)</h3>
<div class="outline-text-3" id="text-1-12">
<p>
get upper triangleform:
</p>
<pre class="example">
C3 = np.triu(C2)
</pre>


<p>
ge lower triangleform:
</p>
<pre class="example">
C3 = np.tril(C2)
</pre>


<p>
get elements:
</p>
<pre class="example">
arr2 = np.where(np.tri(arr.shape[0],arr.shape[1], k = -1) == 1)
</pre>
</div>
</div>

<div id="outline-container-org9c71c39" class="outline-3">
<h3 id="org9c71c39"><span class="section-number-3">1.13.</span> broadcasting and vectorization</h3>
<div class="outline-text-3" id="text-1-13">
<p>
Problem:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">a</span> = np.arange(4)
<span style="color: #cae682;">b</span> = np.ones(5)
<span style="color: #8ac6f2; font-weight: bold;">try</span>:
    a*b
<span style="color: #8ac6f2; font-weight: bold;">except</span> <span style="color: #92a65e; font-weight: bold;">Exception</span> <span style="color: #8ac6f2; font-weight: bold;">as</span> e:
    <span style="color: #e5786d;">print</span>(e)
</pre>
</div>

<pre class="example">
operands could not be broadcast together with shapes (4,) (5,)
</pre>


<p>
Solution:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">aa</span> = a.reshape(4,1)
<span style="color: #e5786d;">print</span>(aa * b)
</pre>
</div>

<pre class="example">
[[0. 0. 0. 0. 0.]
 [1. 1. 1. 1. 1.]
 [2. 2. 2. 2. 2.]
 [3. 3. 3. 3. 3.]]
</pre>


<p>
rules:
</p>
<pre class="example">
 256 x 256 x 3
             3
=256 x 256 x 3
</pre>


<pre class="example">
8 x 1 x 6 x 1
    7 x 1 x 5
8 x 7 x 6 x 5
</pre>


<pre class="example">
 4 x 3
     4
Fail
</pre>


<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">a</span> = np.arange([4,3])
<span style="color: #cae682;">b</span> = np.ones(3)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(a)</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">try:</span>
<span style="color: #fa8072;">#     </span><span style="color: #99968b; font-style: italic;">print(a+b)</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">except Exception as e:</span>
<span style="color: #fa8072;">#     </span><span style="color: #99968b; font-style: italic;">print(e)</span>
</pre>
</div>

<p>
links:
<a href="https://scipy.github.io/old-wiki/pages/EricsBroadcastingDoc.html">https://scipy.github.io/old-wiki/pages/EricsBroadcastingDoc.html</a>
</p>
</div>
</div>
</div>
<div id="outline-container-org7d00076" class="outline-2">
<h2 id="org7d00076"><span class="section-number-2">2.</span> pandas</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org52172c7" class="outline-3">
<h3 id="org52172c7"><span class="section-number-3">2.1.</span> read csv</h3>
<div class="outline-text-3" id="text-2-1">
<pre class="example">
pd.read_csv(p, index_col=0, sep='\t')
</pre>

<ul class="org-ul">
<li>sep='\t' иногда встречается разделение столбцов по \t. обычно запятой</li>
</ul>
</div>
</div>

<div id="outline-container-org455ceff" class="outline-3">
<h3 id="org455ceff"><span class="section-number-3">2.2.</span> sort</h3>
<div class="outline-text-3" id="text-2-2">
<pre class="example">
df.sort_values(by=df['Клиент'], axis=1) # 0 we gave columns, 1 we gave row indexes and sort columns
</pre>
</div>
</div>
<div id="outline-container-orga28ff35" class="outline-3">
<h3 id="orga28ff35"><span class="section-number-3">2.3.</span> replace value</h3>
<div class="outline-text-3" id="text-2-3">
<ol class="org-ol">
<li>new column must be created</li>
</ol>
<pre class="example">
df.loc[df.Followers == 'N/A', 'Followers'] = np.nan
</pre>

<ol class="org-ol">
<li>can use regex</li>
</ol>
<pre class="example">
df['Followers'].replace(to_replace='N/A', value=np.nan)
</pre>

<ol class="org-ol">
<li>can use any function</li>
</ol>
<p>
3.1) on series
</p>
<pre class="example">
df['holiday'] = df['holiday'].apply(lambda x: 1 if x != 0 else 0)
</pre>

<p>
3.2) raw=True gives big speed up
</p>
<pre class="example">
df.apply(lambda row: sum_square(row[0], row[1]), raw=True, axis=1 )
</pre>

<ol class="org-ol">
<li>convert DataFrame to numpy</li>
</ol>
</div>
</div>
<div id="outline-container-org7d58e53" class="outline-3">
<h3 id="org7d58e53"><span class="section-number-3">2.4.</span> <b>analysis</b></h3>
<div class="outline-text-3" id="text-2-4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #cae682;">AH</span> = pd.read_csv(<span style="color: #95e454;">'a.csv'</span>, header=0, index_col = <span style="color: #e5786d; font-weight: bold;">False</span>)
<span style="color: #e5786d;">print</span>(df.head()) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">first 5 lines</span>
<span style="color: #e5786d;">print</span>(df.shape)
<span style="color: #e5786d;">print</span>(df.dtypes.to_string()) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1090;&#1080;&#1087;&#1099; &#1074;&#1089;&#1077;&#1093;! &#1089;&#1090;&#1086;&#1083;&#1073;&#1094;&#1086;&#1074;</span>
<span style="color: #e5786d;">print</span>(df.columns) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1085;&#1072;&#1079;&#1074;&#1072;&#1085;&#1080;&#1103; &#1074;&#1089;&#1077;&#1093;! &#1089;&#1090;&#1086;&#1083;&#1073;&#1094;&#1086;&#1074;</span>
<span style="color: #e5786d;">print</span>(df.iloc[:]) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1085;&#1072;&#1079;&#1074;&#1072;&#1085;&#1080;&#1103; &#1074;&#1089;&#1077;&#1093;! &#1089;&#1090;&#1086;&#1083;&#1073;&#1094;&#1086;&#1074;</span>
<span style="color: #e5786d;">print</span>(df[<span style="color: #95e454;">'birth_date'</span>]) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">one column values</span>
<span style="color: #e5786d;">print</span>(df.isnull().values.<span style="color: #e5786d;">any</span>()) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">any NaN?</span>
<span style="color: #e5786d;">print</span>(df.describe(include=<span style="color: #95e454;">'all'</span>)) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">pre column: unique, mean, std, min, &#1082;&#1074;&#1072;&#1085;&#1090;&#1080;&#1083;&#1100;</span>
df.iloc[1, :].value_counts() <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">100    1  400    1  300    1  200    1</span>
df.iloc[1, :].value_counts(normalize=<span style="color: #e5786d; font-weight: bold;">True</span>) <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">100    0.25  400    0.25  300    0.25 200    0.25</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Categories and Uniques</span>
Categorial <span style="color: #8ac6f2; font-weight: bold;">or</span> <span style="color: #8ac6f2; font-weight: bold;">not</span>. Unique Values
<span style="color: #cae682;">categorial_columns</span> = [c <span style="color: #8ac6f2; font-weight: bold;">for</span> c <span style="color: #8ac6f2; font-weight: bold;">in</span> data.columns <span style="color: #8ac6f2; font-weight: bold;">if</span> data[c].dtype.name == <span style="color: #95e454;">'object'</span>]
<span style="color: #cae682;">categorial_columns</span> = df.select_dtypes(include=[<span style="color: #95e454;">"object"</span>]).columns <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">or</span>
<span style="color: #cae682;">numerical_columns</span> = [c <span style="color: #8ac6f2; font-weight: bold;">for</span> c <span style="color: #8ac6f2; font-weight: bold;">in</span> data.columns <span style="color: #8ac6f2; font-weight: bold;">if</span> data[c].dtype.name != <span style="color: #95e454;">'object'</span>]
<span style="color: #cae682;">numerical_columns</span> = df.select_dtypes(exclude=[<span style="color: #95e454;">"object"</span>]).columns <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">or</span>
<span style="color: #e5786d;">print</span>(data[categorial_columns].describe())
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">unique</span>
: <span style="color: #8ac6f2; font-weight: bold;">for</span> c <span style="color: #8ac6f2; font-weight: bold;">in</span> categorial_columns:
:    <span style="color: #e5786d;">print</span>(c, data[c].unique())

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">histogram</span>

<span style="color: #8ac6f2; font-weight: bold;">import</span> matplotlib
matplotlib.use(<span style="color: #95e454;">'TkAgg'</span>)
<span style="color: #8ac6f2; font-weight: bold;">from</span> matplotlib <span style="color: #8ac6f2; font-weight: bold;">import</span> pyplot <span style="color: #8ac6f2; font-weight: bold;">as</span> plt

AH[<span style="color: #95e454;">'SalePrice'</span>].hist(bins = 60, normed=1) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">calls matplotlib.pyplot.hist</span>
plt.show()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">plot &#1089;&#1090;&#1086;&#1083;&#1073;&#1077;&#1094;</span>

sales.iloc[:,1].plot()

</pre>
</div>
</div>
</div>

<div id="outline-container-org9048027" class="outline-3">
<h3 id="org9048027"><span class="section-number-3">2.5.</span> Series</h3>
<div class="outline-text-3" id="text-2-5">
<p>
One-dimensional ndarray with axis labels
</p>

<p>
combine along index
</p>
<ul class="org-ul">
<li>pd.concat([s1,s2], axis=1)</li>
</ul>

<p>
for dataframes merge:
</p>
<ul class="org-ul">
<li>df1.reset<sub>index</sub>()</li>
<li>df2.reset<sub>index</sub>()</li>
<li>df1.merge(df2)</li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">mydict</span> = [{<span style="color: #95e454;">'a'</span>: 1, <span style="color: #95e454;">'b'</span>: 2, <span style="color: #95e454;">'c'</span>: 3, <span style="color: #95e454;">'d'</span>: 4},
          {<span style="color: #95e454;">'a'</span>: 100, <span style="color: #95e454;">'b'</span>: 200, <span style="color: #95e454;">'c'</span>: 300, <span style="color: #95e454;">'d'</span>: 400},
          {<span style="color: #95e454;">'a'</span>: 1000, <span style="color: #95e454;">'b'</span>: 2000, <span style="color: #95e454;">'c'</span>: 3000, <span style="color: #95e454;">'d'</span>: 4000 }]
<span style="color: #cae682;">df</span> = pd.DataFrame(mydict)

df.iloc[0] <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">{'a': 1, 'b': 2, 'c': 3, 'd': 4}</span>
<span style="color: #e5786d;">type</span>(df.iloc[0]) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&lt;class 'pandas.core.series.Series'&gt;</span>
df.iloc[[0,1,2]] == df == df.iloc[:3]
df.iloc[0, 1] <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">2</span>
df.values <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">convert to numpy</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org29882cb" class="outline-3">
<h3 id="org29882cb"><span class="section-number-3">2.6.</span> DataFrame</h3>
<div class="outline-text-3" id="text-2-6">
<p>
Two-dimensional, size-mutable data. Container for Series objects
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">1) way</span>
<span style="color: #cae682;">d</span> = {<span style="color: #95e454;">'col1'</span>: [1, 2], <span style="color: #95e454;">'col2'</span>: [3, 4]}
<span style="color: #cae682;">s1</span> = pd.DataFrame(data=d)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">2) way</span>
<span style="color: #cae682;">staff</span> = [(col, melb_df[col].nunique(),melb_df[col].dtypes)]
<span style="color: #cae682;">unique_counts</span> = pd.DataFrame(
    staff,
    columns=[<span style="color: #95e454;">'Column_Name'</span>, <span style="color: #95e454;">'Num_Unique'</span>, <span style="color: #95e454;">'Type'</span>]
).sort_values(by=<span style="color: #95e454;">'Num_Unique'</span>,  ignore_index=<span style="color: #e5786d; font-weight: bold;">True</span>)
</pre>
</div>
</div>
</div>
<div id="outline-container-org973a995" class="outline-3">
<h3 id="org973a995"><span class="section-number-3">2.7.</span> index and levels</h3>
<div class="outline-text-3" id="text-2-7">
<ul class="org-ul">
<li>default - created autoincrement int</li>
<li>df.set<sub>index</sub>('c')</li>
<li>df.reset<sub>index</sub>(drop=True, inplace=True) - index to column, create new index, default: drop=False</li>
<li>df.index = Series - ad hoc index</li>
<li>df.index.name - index column name</li>
</ul>

<p>
index and columns may have multiple levels
</p>
<ul class="org-ul">
<li>multilevel index reated by groupby</li>
</ul>


<ul class="org-ul">
<li>df.loc[index, (column|:)] - get values at index</li>
<li>df.iloc[integer] - get values at position</li>
</ul>
</div>
</div>
<div id="outline-container-orgddde84b" class="outline-3">
<h3 id="orgddde84b"><span class="section-number-3">2.8.</span> WHERE AND FILTERS</h3>
<div class="outline-text-3" id="text-2-8">
<p>
<a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing">https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing</a>
methods
</p>
<div class="org-src-container">
<pre class="src src-python">- loc - df.loc[(df[<span style="color: #95e454;">'Salary_in_1000'</span>]&gt;=100) &amp; (df[<span style="color: #95e454;">'Age'</span>]&lt; 60) &amp; (df[<span style="color: #95e454;">'FT_Team'</span>].<span style="color: #e5786d;">str</span>.startswith(<span style="color: #95e454;">'S'</span>)),[<span style="color: #95e454;">'Name'</span>,<span style="color: #95e454;">'FT_Team'</span>]]
- df.index[(df[<span style="color: #95e454;">'Salary_in_1000'</span>]&gt;=100) &amp; (df[<span style="color: #95e454;">'Age'</span>]&lt; 60)]
- numpy where
  - <span style="color: #cae682;">idx</span> = np.where((df[<span style="color: #95e454;">'Salary_in_1000'</span>]&gt;=100) &amp; (df[<span style="color: #95e454;">'Age'</span>]&lt; 60) &amp; (df[<span style="color: #95e454;">'FT_Team'</span>].<span style="color: #e5786d;">str</span>.startswith(<span style="color: #95e454;">'S'</span>)))
  - df.loc[idx]
- Query - df.query(<span style="color: #95e454;">'Salary_in_1000 &gt;= 100 &amp; Age &lt; 60 &amp; FT_Team.str.startswith("S").values'</span>)
- Boolean Indexing - df[(df[<span style="color: #95e454;">'Salary_in_1000'</span>]&gt;=100) &amp; (df[<span style="color: #95e454;">'Age'</span>]&lt;60) &amp; df[<span style="color: #95e454;">'FT_Team'</span>].<span style="color: #e5786d;">str</span>.startswith(<span style="color: #95e454;">'S'</span>)][[<span style="color: #95e454;">'Name'</span>,<span style="color: #95e454;">'Age'</span>,<span style="color: #95e454;">'Salary_in_1000'</span>]]
- <span style="color: #e5786d;">eval</span> - df[df.<span style="color: #e5786d;">eval</span>(<span style="color: #95e454;">"Salary_in_1000&gt;=100 &amp; (Age &lt;60) &amp; FT_Team.str.startswith('S').values"</span>)]
</pre>
</div>

<p>
bool - | or, &amp; and, ~ not
</p>

<div class="org-src-container">
<pre class="src src-python">
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">DAT&#913;FRAME --------</span>
df.shop_id.nunique()

df[df&gt;100] <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">nan, nan, 101</span>
df[df.shop_id &gt; 20] <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">filter works!</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">making boolean series for a team name</span>
<span style="color: #cae682;">filter1</span> = data[<span style="color: #95e454;">"Team"</span>]==<span style="color: #95e454;">"Atlanta Hawks"</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">making boolean series for age</span>
<span style="color: #cae682;">filter2</span> = data[<span style="color: #95e454;">"Age"</span>]&gt;24
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">filtering data on basis of both filters</span>
data.where(filter1 &amp; filter2, inplace = <span style="color: #e5786d; font-weight: bold;">True</span>)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">SERIES -------------</span>
<span style="color: #cae682;">s</span> = pd.Series(<span style="color: #e5786d;">range</span>(5)) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">0,1,2,3,4</span>
s.where(s&gt;1,-1)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-1, -1, 2, 3, 4</span>
s.mask(s&gt;1, -1)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">0, 1, -1, -1, -1</span>

s[s&gt;2] <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">3, 4</span>

</pre>
</div>
</div>
<div id="outline-container-orgac1045a" class="outline-4">
<h4 id="orgac1045a"><span class="section-number-4">2.8.1.</span> filter by date</h4>
<div class="outline-text-4" id="text-2-8-1">
<div class="org-src-container">
<pre class="src src-python"> <span style="color: #cae682;">df</span> = df.dropna(subset=[<span style="color: #95e454;">'&#1044;&#1072;&#1090;&#1072;_&#1079;&#1072;&#1082;&#1083;&#1102;&#1095;&#1077;&#1085;&#1080;&#1103;_&#1082;&#1086;&#1085;&#1090;&#1088;&#1072;&#1082;&#1090;&#1072;_d'</span>])
 <span style="color: #cae682;">d0101</span> = pd.to_datetime(<span style="color: #95e454;">'20190101'</span>, <span style="color: #e5786d;">format</span>=<span style="color: #95e454;">'%Y%m%d'</span>, errors=<span style="color: #95e454;">'ignore'</span>)
 <span style="color: #cae682;">d0731</span> = pd.to_datetime(<span style="color: #95e454;">'20190731'</span>, <span style="color: #e5786d;">format</span>=<span style="color: #95e454;">'%Y%m%d'</span>, errors=<span style="color: #95e454;">'ignore'</span>)
 <span style="color: #cae682;">df</span> = df[d0101 &gt;= df[<span style="color: #95e454;">'&#1044;&#1072;&#1090;&#1072;_&#1079;&#1072;&#1082;&#1083;&#1102;&#1095;&#1077;&#1085;&#1080;&#1103;_&#1082;&#1086;&#1085;&#1090;&#1088;&#1072;&#1082;&#1090;&#1072;_d'</span>] &gt;= d0731]
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgacee716" class="outline-3">
<h3 id="orgacee716"><span class="section-number-3">2.9.</span> COUNT</h3>
<div class="outline-text-3" id="text-2-9">
</div>
<div id="outline-container-org28b2fe2" class="outline-4">
<h4 id="org28b2fe2"><span class="section-number-4">2.9.1.</span> get unique rows with count</h4>
<div class="outline-text-4" id="text-2-9-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">a</span> = pd.DataFrame(a.groupby([<span style="color: #95e454;">'&#1050;&#1086;&#1076;&#1099; &#1086;&#1090;&#1082;&#1072;&#1079;&#1072;'</span>, <span style="color: #95e454;">'&#1054;&#1087;&#1080;&#1089;&#1072;&#1085;&#1080;&#1077; &#1082;&#1086;&#1076;&#1086;&#1074; &#1086;&#1090;&#1082;&#1072;&#1079;&#1072;'</span>]).size().reset_index(name=<span style="color: #95e454;">"count"</span>))
<span style="color: #cae682;">a</span> = pd.DataFrame(a)
<span style="color: #cae682;">c_row</span> = a.pop(<span style="color: #95e454;">'count'</span>)
a.insert(0, <span style="color: #95e454;">'count'</span>, c_row)
a.sort_values(by=[<span style="color: #95e454;">'count'</span>], ascending=<span style="color: #e5786d; font-weight: bold;">False</span>).to_csv(<span style="color: #95e454;">'kod_otkaza.csv'</span>)
</pre>
</div>
</div>
</div>
<div id="outline-container-orgba8caeb" class="outline-4">
<h4 id="orgba8caeb"><span class="section-number-4">2.9.2.</span> count example</h4>
<div class="outline-text-4" id="text-2-9-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Person   Age  Single</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">0    John  24.0   False</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">1    Myla   NaN    True</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">2   Lewis  21.0    True</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">3    John  33.0    True</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">4    Myla  26.0   False</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">create multiindex and count</span>
df.set_index([<span style="color: #95e454;">"Person"</span>, <span style="color: #95e454;">"Single"</span>]).count(level=<span style="color: #95e454;">"Person"</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">John      2</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Lewis     1</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Myla      1</span>

df.set_index([<span style="color: #95e454;">"Person"</span>, <span style="color: #95e454;">"Single"</span>]).count(level=<span style="color: #95e454;">"Single"</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">False     2</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">True      2</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orgbac5ae4" class="outline-4">
<h4 id="orgbac5ae4"><span class="section-number-4">2.9.3.</span> most frequent</h4>
<div class="outline-text-4" id="text-2-9-3">
<pre class="example">
pd.Series([2,3,4,5,6].value_counts().idxmax()
</pre>
</div>
</div>
</div>
<div id="outline-container-org964248a" class="outline-3">
<h3 id="org964248a"><span class="section-number-3">2.10.</span> RESHAPINGS guide <a href="https://pandas.pydata.org/docs/user_guide/reshaping.html">https://pandas.pydata.org/docs/user_guide/reshaping.html</a></h3>
<div class="outline-text-3" id="text-2-10">
</div>
<div id="outline-container-org088ad54" class="outline-4">
<h4 id="org088ad54"><span class="section-number-4">2.10.1.</span> Resample for timeseries</h4>
<div class="outline-text-4" id="text-2-10-1">
<ul class="org-ul">
<li>'M' - month boundary</li>
<li>'A' - annual</li>
</ul>

<pre class="example">
loan_rev_data=data['Loan Amount']
loan_rev_data['date'] = pd.DatetimeIndex(data['Created Date'])
loan_rev_data = loan_rev_data.set_index('date')
monthly_loan_rev_data= loan_rev_data.resample('M').sum()
</pre>


<pre class="example">
            Loan Amount
date
2014-10-31  13039283.00
2014-11-30  16097733.00
2014-12-31  29077334.00
</pre>
</div>
</div>
<div id="outline-container-org78dabfd" class="outline-4">
<h4 id="org78dabfd"><span class="section-number-4">2.10.2.</span> pivot - rows to columns without aggregation</h4>
<div class="outline-text-4" id="text-2-10-2">
<p>
Uses unique values from specified index / columns to form axes of the resulting DataFrame
</p>

<p>
params: index, columns, values
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #cae682;">df</span> = pd.DataFrame({<span style="color: #95e454;">'foo'</span>: [<span style="color: #95e454;">'one'</span>, <span style="color: #95e454;">'one'</span>, <span style="color: #95e454;">'one'</span>, <span style="color: #95e454;">'two'</span>, <span style="color: #95e454;">'two'</span>,<span style="color: #95e454;">'two'</span>],
                   <span style="color: #95e454;">'bar'</span>: [<span style="color: #95e454;">'A'</span>, <span style="color: #95e454;">'B'</span>, <span style="color: #95e454;">'C'</span>, <span style="color: #95e454;">'A'</span>, <span style="color: #95e454;">'B'</span>, <span style="color: #95e454;">'C'</span>],
                   <span style="color: #95e454;">'baz'</span>: [1, 2, 3, 4, 5, 6],
                   <span style="color: #95e454;">'zoo'</span>: [<span style="color: #95e454;">'x'</span>, <span style="color: #95e454;">'y'</span>, <span style="color: #95e454;">'z'</span>, <span style="color: #95e454;">'q'</span>, <span style="color: #95e454;">'w'</span>, <span style="color: #95e454;">'t'</span>]})
<span style="color: #e5786d;">print</span>(df)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(df.pivot(index=<span style="color: #95e454;">'foo'</span>, columns=<span style="color: #95e454;">'bar'</span>, values=<span style="color: #95e454;">'baz'</span>))
</pre>
</div>

<pre class="example" id="orge2c89bf">
   foo bar  baz zoo
0  one   A    1   x
1  one   B    2   y
2  one   C    3   z
3  two   A    4   q
4  two   B    5   w
5  two   C    6   t

bar  A  B  C
foo
one  1  2  3
two  4  5  6
</pre>

<p>
Possible misstakes example:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #cae682;">df</span> = pd.DataFrame({<span style="color: #95e454;">"foo"</span>: [<span style="color: #95e454;">'one'</span>, <span style="color: #95e454;">'one'</span>, <span style="color: #95e454;">'two'</span>, <span style="color: #95e454;">'two'</span>],
                   <span style="color: #95e454;">"bar"</span>: [<span style="color: #95e454;">'A'</span>, <span style="color: #95e454;">'A2'</span>, <span style="color: #95e454;">'B'</span>, <span style="color: #95e454;">'C'</span>], <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">new columns should not have duplicates in one index</span>
                   <span style="color: #95e454;">"baz"</span>: [1, 2, 3, 4]})
<span style="color: #e5786d;">print</span>(df.pivot(index=<span style="color: #95e454;">'foo'</span>, columns=<span style="color: #95e454;">'bar'</span>, values=<span style="color: #95e454;">'baz'</span>))
</pre>
</div>

<pre class="example">
bar    A   A2    B    C
foo
one  1.0  2.0  NaN  NaN
two  NaN  NaN  3.0  4.0
</pre>


<ul class="org-ul">
<li><a href="https://pandas.pydata.org/docs/user_guide/reshaping.html#reshaping">https://pandas.pydata.org/docs/user_guide/reshaping.html#reshaping</a></li>
<li><a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html">https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html</a></li>
</ul>
</div>
</div>
<div id="outline-container-org5499d63" class="outline-4">
<h4 id="org5499d63"><span class="section-number-4">2.10.3.</span> stack (levels)</h4>
<div class="outline-text-4" id="text-2-10-3">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #cae682;">df_single_level_cols</span> = pd.DataFrame([[0, 1], [2, 3]],
                                    index=[<span style="color: #95e454;">'cat'</span>, <span style="color: #95e454;">'dog'</span>],
                                    columns=[<span style="color: #95e454;">'weight'</span>, <span style="color: #95e454;">'height'</span>])
<span style="color: #e5786d;">print</span>(df_single_level_cols)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(df_single_level_cols.stack())
</pre>
</div>

<pre class="example">
     weight  height
cat       0       1
dog       2       3

cat  weight    0
     height    1
dog  weight    2
     height    3
dtype: int64
</pre>
</div>
</div>

<div id="outline-container-org26d24e5" class="outline-4">
<h4 id="org26d24e5"><span class="section-number-4">2.10.4.</span> melt - columns to rows</h4>
<div class="outline-text-4" id="text-2-10-4">
</div>
<ol class="org-ol">
<li><a id="org3f82790"></a>ex1<br />
<div class="outline-text-5" id="text-2-10-4-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #cae682;">df</span> = pd.DataFrame(
    {
        <span style="color: #95e454;">"first"</span>: [<span style="color: #95e454;">"John"</span>, <span style="color: #95e454;">"Mary"</span>],
        <span style="color: #95e454;">"last"</span>: [<span style="color: #95e454;">"Doe"</span>, <span style="color: #95e454;">"Bo"</span>],
        <span style="color: #95e454;">"height"</span>: [5.5, 6.0],
        <span style="color: #95e454;">"weight"</span>: [130, 150],
    })
<span style="color: #e5786d;">print</span>(df)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(df.melt(id_vars=[<span style="color: #95e454;">"first"</span>, <span style="color: #95e454;">"last"</span>]))
</pre>
</div>

<pre class="example">
  first last  height  weight
0  John  Doe     5.5     130
1  Mary   Bo     6.0     150

  first last variable  value
0  John  Doe   height    5.5
1  Mary   Bo   height    6.0
2  John  Doe   weight  130.0
3  Mary   Bo   weight  150.0
</pre>
</div>
</li>

<li><a id="orgfad77f6"></a>ex2<br />
<div class="outline-text-5" id="text-2-10-4-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #cae682;">df</span> = pd.DataFrame({<span style="color: #95e454;">'A'</span>: {0: <span style="color: #95e454;">'a'</span>, 1: <span style="color: #95e454;">'b'</span>, 2: <span style="color: #95e454;">'c'</span>},
                   <span style="color: #95e454;">'B'</span>: {0: 1, 1: 3, 2: 5},
                   <span style="color: #95e454;">'C'</span>: {0: 2, 1: 4, 2: 6}})
<span style="color: #e5786d;">print</span>(df)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(pd.melt(df, id_vars=[<span style="color: #95e454;">'A'</span>], value_vars=[<span style="color: #95e454;">'B'</span>]))
</pre>
</div>

<pre class="example">
   A  B  C
0  a  1  2
1  b  3  4
2  c  5  6

   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
</pre>
</div>
</li>
</ol>
</div>

<div id="outline-container-org11d6725" class="outline-4">
<h4 id="org11d6725"><span class="section-number-4">2.10.5.</span> pivot<sub>table</sub> - allow aggs</h4>
<div class="outline-text-4" id="text-2-10-5">
</div>
<ol class="org-ol">
<li><a id="orgeb5e30f"></a>ex1<br />
<div class="outline-text-5" id="text-2-10-5-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #8ac6f2; font-weight: bold;">import</span> datetime
<span style="color: #cae682;">df</span> = pd.DataFrame(
    {
        <span style="color: #95e454;">"A"</span>: [<span style="color: #95e454;">"one"</span>, <span style="color: #95e454;">"one"</span>, <span style="color: #95e454;">"two"</span>, <span style="color: #95e454;">"three"</span>] * 6,
        <span style="color: #95e454;">"B"</span>: [<span style="color: #95e454;">"A"</span>, <span style="color: #95e454;">"B"</span>, <span style="color: #95e454;">"C"</span>] * 8,
        <span style="color: #95e454;">"C"</span>: [<span style="color: #95e454;">"foo"</span>, <span style="color: #95e454;">"foo"</span>, <span style="color: #95e454;">"foo"</span>, <span style="color: #95e454;">"bar"</span>, <span style="color: #95e454;">"bar"</span>, <span style="color: #95e454;">"bar"</span>] * 4,
        <span style="color: #95e454;">"D"</span>: np.random.randn(24),
        <span style="color: #95e454;">"E"</span>: np.random.randn(24),
        <span style="color: #95e454;">"F"</span>: [datetime.datetime(2013, i, 1) <span style="color: #8ac6f2; font-weight: bold;">for</span> i <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(1, 13)]
        + [datetime.datetime(2013, i, 15) <span style="color: #8ac6f2; font-weight: bold;">for</span> i <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(1, 13)],
    })
<span style="color: #e5786d;">print</span>(df)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(pd.pivot_table(df, values=<span style="color: #95e454;">"D"</span>, index=[<span style="color: #95e454;">"A"</span>, <span style="color: #95e454;">"B"</span>], columns=[<span style="color: #95e454;">"C"</span>]))
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(pd.pivot_table(df, values=<span style="color: #95e454;">"D"</span>, index=[<span style="color: #95e454;">"B"</span>], columns=[<span style="color: #95e454;">"A"</span>, <span style="color: #95e454;">"C"</span>], aggfunc=np.<span style="color: #e5786d;">sum</span>))
</pre>
</div>

<pre class="example" id="orgeb61ca6">
        A  B    C         D         E          F
0     one  A  foo  0.834789 -0.268575 2013-01-01
1     one  B  foo -0.332062 -0.324379 2013-02-01
2     two  C  foo -2.095669 -2.186134 2013-03-01
3   three  A  bar -0.793498  0.126653 2013-04-01
4     one  B  bar  0.117796 -0.845898 2013-05-01
5     one  C  bar  1.016105 -0.369420 2013-06-01
6     two  A  foo  1.151064 -0.698485 2013-07-01
7   three  B  foo -0.487159  0.123010 2013-08-01
8     one  C  foo -1.456931  1.230448 2013-09-01
9     one  A  bar -0.591074 -0.851506 2013-10-01
10    two  B  bar  1.332696  0.161591 2013-11-01
11  three  C  bar  0.033348 -0.187387 2013-12-01
12    one  A  foo -1.159041  0.321096 2013-01-15
13    one  B  foo  0.353786  0.724629 2013-02-15
14    two  C  foo -1.765572 -0.708540 2013-03-15
15  three  A  bar  0.805330 -0.652539 2013-04-15
16    one  B  bar -0.124616  0.014006 2013-05-15
17    one  C  bar -0.052215 -0.168125 2013-06-15
18    two  A  foo  0.921741  0.280954 2013-07-15
19  three  B  foo -0.584663  0.727251 2013-08-15
20    one  C  foo -1.740931  1.516952 2013-09-15
21    one  A  bar -0.189743 -0.515618 2013-10-15
22    two  B  bar -0.099166  0.002090 2013-11-15
23  three  C  bar -0.487092 -0.996470 2013-12-15

C             bar       foo
A     B
one   A -0.390408 -0.162126
      B -0.003410  0.010862
      C  0.481945 -1.598931
three A  0.005916       NaN
      B       NaN -0.535911
      C -0.226872       NaN
two   A       NaN  1.036402
      B  0.616765       NaN
      C       NaN -1.930620

A       one               three                two
C       bar       foo       bar       foo      bar       foo
B
A -0.780817 -0.324252  0.011831       NaN      NaN  2.072805
B -0.006820  0.021724       NaN -1.071822  1.23353       NaN
C  0.963890 -3.197862 -0.453743       NaN      NaN -3.861240
</pre>
</div>
</li>

<li><a id="orgb34f986"></a>ex2<br />
<div class="outline-text-5" id="text-2-10-5-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #e5786d;">print</span>(pd.pivot_table(df[[<span style="color: #95e454;">"A"</span>, <span style="color: #95e454;">"B"</span>, <span style="color: #95e454;">"C"</span>, <span style="color: #95e454;">"D"</span>, <span style="color: #95e454;">"E"</span>]], index=[<span style="color: #95e454;">"A"</span>, <span style="color: #95e454;">"B"</span>], columns=[<span style="color: #95e454;">"C"</span>]))
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(pd.pivot_table(df, values=<span style="color: #95e454;">"D"</span>, index=pd.Grouper(freq=<span style="color: #95e454;">"M"</span>, key=<span style="color: #95e454;">"F"</span>), columns=<span style="color: #95e454;">"C"</span>))
<span style="color: #e5786d;">print</span>()
<span style="color: #cae682;">table</span> = pd.pivot_table(df, index=[<span style="color: #95e454;">"A"</span>, <span style="color: #95e454;">"B"</span>], columns=[<span style="color: #95e454;">"C"</span>], values=[<span style="color: #95e454;">"D"</span>, <span style="color: #95e454;">"E"</span>])
<span style="color: #e5786d;">print</span>(table.to_string(na_rep=<span style="color: #95e454;">""</span>))
<span style="color: #e5786d;">print</span>()
<span style="color: #cae682;">table</span> = df.pivot_table(
    index=[<span style="color: #95e454;">"A"</span>, <span style="color: #95e454;">"B"</span>],
    columns=<span style="color: #95e454;">"C"</span>,
    values=[<span style="color: #95e454;">"D"</span>, <span style="color: #95e454;">"E"</span>],
    margins=<span style="color: #e5786d; font-weight: bold;">True</span>,
    aggfunc=np.std)
<span style="color: #e5786d;">print</span>(table)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(table.stack())
</pre>
</div>

<pre class="example" id="org3e086f2">
                D                   E
C             bar       foo       bar       foo
A     B
one   A -0.390408 -0.162126 -0.683562  0.026260
      B -0.003410  0.010862 -0.415946  0.200125
      C  0.481945 -1.598931 -0.268773  1.373700
three A  0.005916       NaN -0.262943       NaN
      B       NaN -0.535911       NaN  0.425131
      C -0.226872       NaN -0.591928       NaN
two   A       NaN  1.036402       NaN -0.208765
      B  0.616765       NaN  0.081840       NaN
      C       NaN -1.930620       NaN -1.447337

C                bar       foo
F
2013-01-31       NaN -0.162126
2013-02-28       NaN  0.010862
2013-03-31       NaN -1.930620
2013-04-30  0.005916       NaN
2013-05-31 -0.003410       NaN
2013-06-30  0.481945       NaN
2013-07-31       NaN  1.036402
2013-08-31       NaN -0.535911
2013-09-30       NaN -1.598931
2013-10-31 -0.390408       NaN
2013-11-30  0.616765       NaN
2013-12-31 -0.226872       NaN

                D                   E
C             bar       foo       bar       foo
A     B
one   A -0.390408 -0.162126 -0.683562  0.026260
      B -0.003410  0.010862 -0.415946  0.200125
      C  0.481945 -1.598931 -0.268773  1.373700
three A  0.005916           -0.262943
      B           -0.535911            0.425131
      C -0.226872           -0.591928
two   A            1.036402           -0.208765
      B  0.616765            0.081840
      C           -1.930620           -1.447337

                D                             E
C             bar       foo       All       bar       foo       All
A     B
one   A  0.283784  1.409851  0.840699  0.237509  0.416961  0.494677
      B  0.171411  0.484967  0.297085  0.608044  0.741761  0.658146
      C  0.755417  0.200819  1.283359  0.142337  0.202589  0.958996
three A  1.130542       NaN  1.130542  0.550971       NaN  0.550971
      B       NaN  0.068946  0.068946       NaN  0.427263  0.427263
      C  0.368006       NaN  0.368006  0.572108       NaN  0.572108
two   A       NaN  0.162156  0.162156       NaN  0.692568  0.692568
      B  1.012479       NaN  1.012479  0.112784       NaN  0.112784
      C       NaN  0.233414  0.233414       NaN  1.044817  1.044817
All      0.651877  1.140991  0.940582  0.408882  0.998514  0.759845

                    D         E
A     B C
one   A All  0.840699  0.494677
        bar  0.283784  0.237509
        foo  1.409851  0.416961
      B All  0.297085  0.658146
        bar  0.171411  0.608044
        foo  0.484967  0.741761
      C All  1.283359  0.958996
        bar  0.755417  0.142337
        foo  0.200819  0.202589
three A All  1.130542  0.550971
        bar  1.130542  0.550971
      B All  0.068946  0.427263
        foo  0.068946  0.427263
      C All  0.368006  0.572108
        bar  0.368006  0.572108
two   A All  0.162156  0.692568
        foo  0.162156  0.692568
      B All  1.012479  0.112784
        bar  1.012479  0.112784
      C All  0.233414  1.044817
        foo  0.233414  1.044817
All     All  0.940582  0.759845
        bar  0.651877  0.408882
        foo  1.140991  0.998514
</pre>
</div>
</li>
</ol>
</div>

<div id="outline-container-orge4593b6" class="outline-4">
<h4 id="orge4593b6"><span class="section-number-4">2.10.6.</span> pivot tables(old)</h4>
<div class="outline-text-4" id="text-2-10-6">
<div class="org-src-container">
<pre class="src src-python">melb_df.groupby([<span style="color: #95e454;">'Rooms'</span>, <span style="color: #95e454;">'Type'</span>])[<span style="color: #95e454;">'Price'</span>].mean() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1080;&#1077;&#1088;&#1072;&#1088;&#1093;&#1080;&#1095;&#1077;&#1089;&#1082;&#1080;&#1077; &#1080;&#1085;&#1076;&#1077;&#1082;&#1089;&#1099;</span>
melb_df.groupby([<span style="color: #95e454;">'Rooms'</span>, <span style="color: #95e454;">'Type'</span>])[<span style="color: #95e454;">'Price'</span>].mean().unstack() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1088;&#1072;&#1089;&#1082;&#1083;&#1072;&#1076;&#1099;&#1074;&#1072;&#1077;&#1090; &#1090;&#1072;&#1073;&#1083;&#1080;&#1094;&#1091; &#1074; &#1089;&#1090;&#1086;&#1083;&#1073;&#1094;&#1099;</span>
melb_df.pivot_table(
    values=<span style="color: #95e454;">'Price'</span>,
    index=<span style="color: #95e454;">'Rooms'</span>,
    columns=<span style="color: #95e454;">'Type'</span>,
    fill_value=0
).<span style="color: #e5786d;">round</span>() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1072;&#1085;&#1072;&#1083;&#1086;&#1075;&#1080;&#1095;&#1085;&#1086; &#1074;&#1090;&#1086;&#1088;&#1086;&#1084;&#1091;</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org96b3601" class="outline-4">
<h4 id="org96b3601"><span class="section-number-4">2.10.7.</span> crosstab - frequencies</h4>
<div class="outline-text-4" id="text-2-10-7">
<p>
frequency table of the factors unless an array of values and an aggregation function are passed.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">foo</span>, <span style="color: #cae682;">bar</span>, <span style="color: #cae682;">dull</span>, <span style="color: #cae682;">shiny</span>, <span style="color: #cae682;">one</span>, <span style="color: #cae682;">two</span> = <span style="color: #95e454;">"foo"</span>, <span style="color: #95e454;">"bar"</span>, <span style="color: #95e454;">"dull"</span>, <span style="color: #95e454;">"shiny"</span>, <span style="color: #95e454;">"one"</span>, <span style="color: #95e454;">"two"</span>
<span style="color: #cae682;">a</span> = np.array([foo, foo, bar, bar, foo, foo], dtype=<span style="color: #e5786d;">object</span>)
<span style="color: #cae682;">b</span> = np.array([one, one, two, one, two, one], dtype=<span style="color: #e5786d;">object</span>)
<span style="color: #cae682;">c</span> = np.array([dull, dull, shiny, dull, dull, shiny], dtype=<span style="color: #e5786d;">object</span>)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"frequencies:"</span>)
<span style="color: #e5786d;">print</span>(pd.crosstab(a, b))
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(pd.crosstab(a, [b, c], rownames=[<span style="color: #95e454;">"a"</span>], colnames=[<span style="color: #95e454;">"b"</span>, <span style="color: #95e454;">"c"</span>]))
</pre>
</div>

<pre class="example" id="orgf7887ee">
frequencies:
col_0  one  two
row_0
bar      1    1
foo      3    1

b    one        two
c   dull shiny dull shiny
a
bar    1     0    0     1
foo    2     1    1     0
</pre>
</div>
</div>

<div id="outline-container-org58cb77e" class="outline-4">
<h4 id="org58cb77e"><span class="section-number-4">2.10.8.</span> cut - transform continuous variables to discrete or categorical variables</h4>
<div class="outline-text-4" id="text-2-10-8">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">ages</span> = np.array([10, 15, 13, 12, 23, 25, 28, 59, 60])
<span style="color: #e5786d;">print</span>(pd.cut(ages, bins=3))
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(pd.cut(ages, bins=[0, 18, 35, 70]))
</pre>
</div>

<pre class="example">
[(9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (9.95, 26.667], (26.667, 43.333], (43.333, 60.0], (43.333, 60.0]]
Categories (3, interval[float64, right]): [(9.95, 26.667] &lt; (26.667, 43.333] &lt; (43.333, 60.0]]

[(0, 18], (0, 18], (0, 18], (0, 18], (18, 35], (18, 35], (18, 35], (35, 70], (35, 70]]
Categories (3, interval[int64, right]): [(0, 18] &lt; (18, 35] &lt; (35, 70]]
</pre>
</div>
</div>

<div id="outline-container-orge4f3f80" class="outline-4">
<h4 id="orge4f3f80"><span class="section-number-4">2.10.9.</span> dummies</h4>
<div class="outline-text-4" id="text-2-10-9">
<ul class="org-ul">
<li>pd.get<sub>dummies</sub>(df, prefix="new<sub>prefix</sub>")</li>
<li>pd.from<sub>dummies</sub>(df, sep="_")</li>
</ul>
</div>
</div>
<div id="outline-container-org0adb62e" class="outline-4">
<h4 id="org0adb62e"><span class="section-number-4">2.10.10.</span> factorize - categories to numbers</h4>
<div class="outline-text-4" id="text-2-10-10">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">x</span> = pd.Series([<span style="color: #95e454;">"A"</span>, <span style="color: #95e454;">"A"</span>, np.nan, <span style="color: #95e454;">"B"</span>, 3.14, np.inf])
<span style="color: #cae682;">labels</span>, <span style="color: #cae682;">uniques</span> = pd.factorize(x)
<span style="color: #e5786d;">print</span>(labels)
<span style="color: #e5786d;">print</span>(uniques)
</pre>
</div>

<pre class="example">
[ 0  0 -1  1  2  3]
Index(['A', 'B', 3.14, inf], dtype='object')
</pre>
</div>
</div>

<div id="outline-container-orgfe9cdcd" class="outline-4">
<h4 id="orgfe9cdcd"><span class="section-number-4">2.10.11.</span> explode</h4>
<div class="outline-text-4" id="text-2-10-11">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">keys</span> = [<span style="color: #95e454;">"panda1"</span>, <span style="color: #95e454;">"panda2"</span>, <span style="color: #95e454;">"panda3"</span>]
<span style="color: #cae682;">values</span> = [[<span style="color: #95e454;">"eats"</span>, <span style="color: #95e454;">"shoots"</span>], [<span style="color: #95e454;">"shoots"</span>, <span style="color: #95e454;">"leaves"</span>], [<span style="color: #95e454;">"eats"</span>, <span style="color: #95e454;">"leaves"</span>]]
<span style="color: #cae682;">df</span> = pd.DataFrame({<span style="color: #95e454;">"keys"</span>: keys, <span style="color: #95e454;">"values"</span>: values})
<span style="color: #e5786d;">print</span>(df)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(df[<span style="color: #95e454;">"values"</span>].explode())
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(df.explode(<span style="color: #95e454;">"values"</span>))
</pre>
</div>

<pre class="example" id="org6d3d2e7">
     keys            values
0  panda1    [eats, shoots]
1  panda2  [shoots, leaves]
2  panda3    [eats, leaves]

0      eats
0    shoots
1    shoots
1    leaves
2      eats
2    leaves
Name: values, dtype: object

     keys  values
0  panda1    eats
0  panda1  shoots
1  panda2  shoots
1  panda2  leaves
2  panda3    eats
2  panda3  leaves
</pre>
</div>
</div>

<div id="outline-container-org174ea6c" class="outline-4">
<h4 id="org174ea6c"><span class="section-number-4">2.10.12.</span> assign and explode - split values to rows</h4>
<div class="outline-text-4" id="text-2-10-12">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">df</span> = pd.DataFrame([{<span style="color: #95e454;">"var1"</span>: <span style="color: #95e454;">"a,b,c,d"</span>, <span style="color: #95e454;">"var2"</span>: 1}, {<span style="color: #95e454;">"var1"</span>: <span style="color: #95e454;">"d,e,f"</span>, <span style="color: #95e454;">"var2"</span>: 2}])
<span style="color: #e5786d;">print</span>(df)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(df.assign(var1=df.var1.<span style="color: #e5786d;">str</span>.split(<span style="color: #95e454;">","</span>)).explode(<span style="color: #95e454;">"var1"</span>))
</pre>
</div>

<pre class="example" id="orga26b528">
      var1  var2
0  a,b,c,d     1
1    d,e,f     2

  var1  var2
0    a     1
0    b     1
0    c     1
0    d     1
1    d     2
1    e     2
1    f     2
</pre>
</div>
</div>
</div>

<div id="outline-container-org17bbc3c" class="outline-3">
<h3 id="org17bbc3c"><span class="section-number-3">2.11.</span> Merge, join, and concatenate</h3>
<div class="outline-text-3" id="text-2-11">
<p>
<a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html">https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html</a>
</p>

<p>
Одну таблицу разделенную на две части:
</p>
<ul class="org-ul">
<li>верх и низ: pd.concat([s1, s2], ignore<sub>index</sub>=True)</li>
<li>лево и право ?</li>
</ul>


<ul class="org-ul">
<li>concatenate - по умолчанию добавляются строки, default: axis=0, join='outer', ignore<sub>index</sub> = False
<ul class="org-ul">
<li>pd.concat([df1, df4], axis=1, sort=False)  - подбираются столбцы с одинаковым значением, добавляются NaN-s</li>
<li>join='outer' -  NaN-s не добавляются</li>
</ul></li>
</ul>

<p>
SQL style
</p>
<ol class="org-ol">
<li>merge - ignore index, uses specified column
<ul class="org-ul">
<li>pd.merge(playdata, genetic<sub>train</sub>, on="SK<sub>ID</sub><sub>CURR</sub>",how="left" ) - если есть дупликаты справа, то они все
войдут даже справа</li>
<li>"on" must be found in both DataFrames</li>
<li>indicator=True - adds _merge field with ['left<sub>only</sub>', 'right<sub>only</sub>', 'both']</li>
</ul></li>
<li>join - uses index column
<ul class="org-ul">
<li>first you should set index to joined columns</li>
<li>table1.join(table2, lsuffix='<sub>table1</sub>', rsuffix='<sub>table2</sub>',how="left")</li>
</ul></li>
</ol>


<p>
new column:
</p>
<pre class="example">
df['asd'] = list
</pre>
</div>
<div id="outline-container-org89fc0fe" class="outline-4">
<h4 id="org89fc0fe"><span class="section-number-4">2.11.1.</span> concat series</h4>
<div class="outline-text-4" id="text-2-11-1">
<div class="org-src-container">
<pre class="src src-python">&gt;&gt;&gt; df
   0
0  1
2  3
&gt;&gt;&gt; df2
   0
0  1
1  2
&gt;&gt;&gt; pd.concat([df,df2], axis=1)
     0    0
0  1.0  1.0
2  3.0  NaN
1  NaN  2.0

</pre>
</div>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #cae682;">s1</span> = pd.Series([<span style="color: #95e454;">'a'</span>, <span style="color: #95e454;">'b'</span>])
<span style="color: #cae682;">s2</span> = pd.Series([<span style="color: #95e454;">'c'</span>, <span style="color: #95e454;">'d'</span>])
<span style="color: #e5786d;">print</span>(pd.concat([s1, s2], ignore_index=<span style="color: #e5786d; font-weight: bold;">True</span>))
</pre>
</div>

<pre class="example">
0    a
1    b
2    c
3    d
dtype: object
</pre>
</div>
</div>

<div id="outline-container-orgca9fec4" class="outline-4">
<h4 id="orgca9fec4"><span class="section-number-4">2.11.2.</span> concat datafremes vertically</h4>
<div class="outline-text-4" id="text-2-11-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #cae682;">df1</span> = pd.DataFrame({<span style="color: #95e454;">'lkey'</span>: [<span style="color: #95e454;">'foo'</span>, <span style="color: #95e454;">'bar'</span>, <span style="color: #95e454;">'baz'</span>, <span style="color: #95e454;">'foo'</span>],

                    <span style="color: #95e454;">'value'</span>: [1, 2, 3, 5]})

<span style="color: #cae682;">df2</span> = pd.DataFrame({<span style="color: #95e454;">'rkey'</span>: [<span style="color: #95e454;">'foo'</span>, <span style="color: #95e454;">'bar'</span>, <span style="color: #95e454;">'baz'</span>, <span style="color: #95e454;">'foo'</span>],

                    <span style="color: #95e454;">'value'</span>: [5, 6, 7, 8]})
<span style="color: #e5786d;">print</span>(df2)
<span style="color: #e5786d;">print</span>(pd.concat([df1, df2], ignore_index=<span style="color: #e5786d; font-weight: bold;">True</span>))
</pre>
</div>

<pre class="example" id="org9d65387">
  rkey  value
0  foo      5
1  bar      6
2  baz      7
3  foo      8
  lkey  value rkey
0  foo      1  NaN
1  bar      2  NaN
2  baz      3  NaN
3  foo      5  NaN
4  NaN      5  foo
5  NaN      6  bar
6  NaN      7  baz
7  NaN      8  foo
</pre>
</div>
</div>

<div id="outline-container-org084860a" class="outline-4">
<h4 id="org084860a"><span class="section-number-4">2.11.3.</span> merge</h4>
<div class="outline-text-4" id="text-2-11-3">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #cae682;">left</span> = pd.DataFrame(
    {
        <span style="color: #95e454;">"key"</span>: [<span style="color: #95e454;">"K0"</span>, <span style="color: #95e454;">"K1"</span>, <span style="color: #95e454;">"K2"</span>, <span style="color: #95e454;">"K3"</span>],
        <span style="color: #95e454;">"A"</span>: [<span style="color: #95e454;">"A0"</span>, <span style="color: #95e454;">"A1"</span>, <span style="color: #95e454;">"A2"</span>, <span style="color: #95e454;">"A3"</span>],
        <span style="color: #95e454;">"B"</span>: [<span style="color: #95e454;">"B0"</span>, <span style="color: #95e454;">"B1"</span>, <span style="color: #95e454;">"B2"</span>, <span style="color: #95e454;">"B3"</span>],
    }
)

<span style="color: #cae682;">right</span> = pd.DataFrame(
    {
        <span style="color: #95e454;">"key"</span>: [<span style="color: #95e454;">"K0"</span>, <span style="color: #95e454;">"K1"</span>, <span style="color: #95e454;">"K2"</span>, <span style="color: #95e454;">"K3"</span>, <span style="color: #95e454;">"K0"</span>], <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">K0 duplicate</span>
        <span style="color: #95e454;">"C"</span>: [<span style="color: #95e454;">"C0"</span>, <span style="color: #95e454;">"C1"</span>, <span style="color: #95e454;">"C2"</span>, <span style="color: #95e454;">"C3"</span>, <span style="color: #95e454;">"C3"</span>],
        <span style="color: #95e454;">"D"</span>: [<span style="color: #95e454;">"D0"</span>, <span style="color: #95e454;">"D1"</span>, <span style="color: #95e454;">"D2"</span>, <span style="color: #95e454;">"D3"</span>, <span style="color: #95e454;">"D3"</span>],
    }
)

<span style="color: #cae682;">result</span> = pd.merge(left, right, on=<span style="color: #95e454;">"key"</span>, how=<span style="color: #95e454;">'left'</span>)
<span style="color: #e5786d;">print</span>(result)
</pre>
</div>

<pre class="example">
  key   A   B   C   D
0  K0  A0  B0  C0  D0
1  K0  A0  B0  C3  D3
2  K1  A1  B1  C1  D1
3  K2  A2  B2  C2  D2
4  K3  A3  B3  C3  D3
</pre>
</div>
</div>

<div id="outline-container-orgdbcfe57" class="outline-4">
<h4 id="orgdbcfe57"><span class="section-number-4">2.11.4.</span> add by date</h4>
<div class="outline-text-4" id="text-2-11-4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">add_holiday_features</span>(df, dfh):
    <span style="color: #cae682;">df</span>[<span style="color: #95e454;">'date'</span>] = df[<span style="color: #95e454;">'pickup_datetime'</span>].dt.date
    <span style="color: #cae682;">df</span>[<span style="color: #95e454;">'date'</span>] = df[<span style="color: #95e454;">'date'</span>].astype(<span style="color: #e5786d;">str</span>)
    <span style="color: #cae682;">df</span> = df.merge(dfh, <span style="color: #95e454;">'left'</span>, on=<span style="color: #95e454;">'date'</span>)
    df[<span style="color: #95e454;">'holiday'</span>].fillna(0, inplace=<span style="color: #e5786d; font-weight: bold;">True</span>)
    <span style="color: #cae682;">df</span>[<span style="color: #95e454;">'holiday'</span>] = df[<span style="color: #95e454;">'holiday'</span>].<span style="color: #e5786d;">apply</span>(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x: 1 <span style="color: #8ac6f2; font-weight: bold;">if</span> x != 0 <span style="color: #8ac6f2; font-weight: bold;">else</span> 0)
    df.drop(columns=[<span style="color: #95e454;">'date'</span>], inplace=<span style="color: #e5786d; font-weight: bold;">True</span>)
    <span style="color: #8ac6f2; font-weight: bold;">return</span> df
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org5253f24" class="outline-3">
<h3 id="org5253f24"><span class="section-number-3">2.12.</span> DISTICT groupby</h3>
<div class="outline-text-3" id="text-2-12">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e5786d;">print</span>(df.groupby(<span style="color: #95e454;">'shop_id'</span>).item_id.value_counts())
<span style="color: #e5786d;">print</span>(df.groupby(<span style="color: #95e454;">'shop_id'</span>).item_id.nunique())

<span style="color: #cae682;">dfg</span> = df[[<span style="color: #95e454;">'shop_id'</span>, <span style="color: #95e454;">'item_id'</span>] ].groupby(<span style="color: #95e454;">'shop_id'</span>)
<span style="color: #e5786d;">print</span>(dfg.agg([<span style="color: #95e454;">'mean'</span>, <span style="color: #95e454;">'count'</span>, <span style="color: #95e454;">'min'</span>]))
</pre>
</div>
</div>
<div id="outline-container-org447f718" class="outline-4">
<h4 id="org447f718"><span class="section-number-4">2.12.1.</span> row number by group - добавить сложную номерацию по группам</h4>
<div class="outline-text-4" id="text-2-12-1">
<pre class="example">
df['Номер_контракта'] = df.groupby(['Клиент'])['Дата_заключения_контракта'].cumcount()+1
</pre>
</div>
</div>
</div>

<div id="outline-container-orge5a401f" class="outline-3">
<h3 id="orge5a401f"><span class="section-number-3">2.13.</span> two dataframes</h3>
<div class="outline-text-3" id="text-2-13">
<ul class="org-ul">
<li>df1['prices<sub>match</sub>'] = np.where(df1['price<sub>1</sub>'] == df2['price<sub>2</sub>'], 'True', 'False')</li>
<li>turn values to sets and compare  <a href="https://numpy.org/doc/stable/reference/routines.set.html">https://numpy.org/doc/stable/reference/routines.set.html</a></li>
<li>dfa[dfa['users<sub>id</sub>'].isin(dft['users<sub>id</sub>'])]</li>
</ul>
</div>

<div id="outline-container-orge2d723b" class="outline-4">
<h4 id="orge2d723b"><span class="section-number-4">2.13.1.</span> sets comparision</h4>
<div class="outline-text-4" id="text-2-13-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">count_fkey</span>(key1, key2):
    <span style="color: #cae682;">un1</span> = np.unique(key1)
    <span style="color: #cae682;">un2</span> = np.unique(key2)
    <span style="color: #cae682;">cm</span> = np.in1d(un1, un2, assume_unique=<span style="color: #e5786d; font-weight: bold;">True</span>)
    <span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #95e454;">'name'</span> <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">dir</span>(key1):
        <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"Unique [</span>{key1.name}<span style="color: #95e454;">]: </span>{ un1.size}<span style="color: #95e454;">"</span>)
        <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"Unique [</span>{key2.name}<span style="color: #95e454;">]: </span>{ un2.size}<span style="color: #95e454;">"</span>)
    <span style="color: #8ac6f2; font-weight: bold;">else</span>:
        <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"key1: </span>{ un1.size}<span style="color: #95e454;">"</span>)
        <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"key2: </span>{ un2.size}<span style="color: #95e454;">"</span>)
    <span style="color: #cae682;">c</span> = np.unique(cm, return_counts=<span style="color: #e5786d; font-weight: bold;">True</span>)
    <span style="color: #e5786d;">print</span>(pd.DataFrame({<span style="color: #95e454;">'values'</span>:c[0], <span style="color: #95e454;">'count'</span>:c[1]}))
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org892588d" class="outline-3">
<h3 id="org892588d"><span class="section-number-3">2.14.</span> Map, Apply, Applymap</h3>
<div class="outline-text-3" id="text-2-14">
<ul class="org-ul">
<li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html</a></li>
<li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html</a></li>
<li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.applymap.html">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.applymap.html</a></li>
</ul>
</div>
<div id="outline-container-org80b16ac" class="outline-4">
<h4 id="org80b16ac"><span class="section-number-4">2.14.1.</span> Comparing map, applymap and apply: Context Matters</h4>
<div class="outline-text-4" id="text-2-14-1">
<p>
First major difference: DEFINITION
</p>
<ul class="org-ul">
<li>map is defined on Series ONLY</li>
<li>applymap is defined on DataFrames ONLY</li>
<li>apply is defined on BOTH</li>
</ul>

<p>
Second major difference: INPUT ARGUMENT
</p>
<ul class="org-ul">
<li>map accepts dicts, Series, or callable</li>
<li>applymap and apply accept callables only</li>
</ul>

<p>
Third major difference: BEHAVIOR
</p>
<ul class="org-ul">
<li>map is elementwise for Series</li>
<li>applymap is elementwise for DataFrames</li>
<li>apply also works elementwise but is suited to more complex operations and aggregation. The behaviour and return value depends on the function.</li>
</ul>

<p>
Fourth major difference (the most important one): USE CASE
</p>
<pre class="example">
map is meant for mapping values from one domain to another, so is optimised for performance (e.g., df['A'].map({1:'a', 2:'b', 3:'c'}))
applymap is good for elementwise transformations across multiple rows/columns (e.g., df[['A', 'B', 'C']].applymap(str.strip))
apply is for applying any function that cannot be vectorised (e.g., df['sentences'].apply(nltk.sent_tokenize))
</pre>


<p>
Footnotes
</p>
<ul class="org-ul">
<li><b>map</b> when passed a dictionary/Series will map elements based on the keys in that
dictionary/Series. Missing values will be recorded as NaN in the output.</li>
<li><b>applymap</b> in more recent versions has been optimised for some operations. You will find applymap
slightly faster than apply in some cases. My suggestion is to test them both and use whatever
works better. (deprecated)</li>
<li><b>map</b> is optimised for elementwise mappings and transformation. Operations that involve
dictionaries or Series will enable pandas to use faster code paths for better performance.</li>
<li><b>Series.apply</b> returns a scalar for aggregating operations, Series otherwise. Similarly for
DataFrame.apply. Note that apply also has fastpaths when called with certain NumPy functions such
as mean, sum, etc.</li>
</ul>
</div>
</div>

<div id="outline-container-org67c38fe" class="outline-4">
<h4 id="org67c38fe"><span class="section-number-4">2.14.2.</span> apply to column</h4>
<div class="outline-text-4" id="text-2-14-2">
<pre class="example">
df['A'] = df['A'].apply(lambda x: str.strip(x) if pd.notna(x) else x)
</pre>
</div>
</div>
<div id="outline-container-org71052c2" class="outline-4">
<h4 id="org71052c2"><span class="section-number-4">2.14.3.</span> return multiple rows</h4>
<div class="outline-text-4" id="text-2-14-3">
<ol class="org-ol">
<li></li>
</ol>
<pre class="example">
return pd.Series([1,2,3]) ; df['a'].apply(f).to_numpy()[:,1] - time 13 sec
</pre>

<ol class="org-ol">
<li></li>
</ol>
<pre class="example">
return [1,2,3] ; list(zip(*df['a'].apply(f).to_list()) - time 28.6 sec
</pre>
</div>
</div>
<div id="outline-container-orgdec5c9d" class="outline-4">
<h4 id="orgdec5c9d"><span class="section-number-4">2.14.4.</span> example</h4>
<div class="outline-text-4" id="text-2-14-4">
<div class="org-src-container">
<pre class="src src-python">s.<span style="color: #e5786d;">map</span>(<span style="color: #95e454;">'I am a {}'</span>.<span style="color: #e5786d;">format</span>)
s.<span style="color: #e5786d;">map</span>({<span style="color: #95e454;">' &lt;=50K.'</span>: 0, <span style="color: #95e454;">' &gt;50K.'</span>: 1})
s.<span style="color: #e5786d;">map</span>({<span style="color: #95e454;">'fox'</span>: <span style="color: #95e454;">'cub'</span>, <span style="color: #95e454;">'cow'</span>: <span style="color: #95e454;">'calf'</span>})
<span style="color: #cae682;">df</span>[<span style="color: #95e454;">'result'</span>] = df[<span style="color: #95e454;">'result'</span>].<span style="color: #e5786d;">map</span>({b<span style="color: #95e454;">'OK'</span>: 1, b<span style="color: #95e454;">'STOP'</span>: 0})
df.<span style="color: #cae682;">iloc</span>[:, 0] = df.iloc[:, 0].<span style="color: #e5786d;">map</span>({b<span style="color: #95e454;">'OK'</span>: 1, b<span style="color: #95e454;">'STOP'</span>: 0})

DataFrame.applymap(<span style="color: #8ac6f2; font-weight: bold;">self</span>, func) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">to whole dataFrame</span>

DataFrame.<span style="color: #e5786d;">apply</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, func, axis=0, raw=<span style="color: #e5786d; font-weight: bold;">False</span>, result_type=<span style="color: #e5786d; font-weight: bold;">None</span>, args=(), **kwds)

Series.<span style="color: #e5786d;">map</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, arg, na_action=<span style="color: #e5786d; font-weight: bold;">None</span>) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">argfunction, collections.abc.Mapping subclass or Series</span>

df.iloc[:, 2].<span style="color: #e5786d;">map</span>(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x: x*x) == df.iloc[:, 2].<span style="color: #e5786d;">apply</span>(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x: x*x)

</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org07ea1c9" class="outline-3">
<h3 id="org07ea1c9"><span class="section-number-3">2.15.</span> save and load</h3>
<div class="outline-text-3" id="text-2-15">
<pre class="example">
df.to_pickle('b')
df: pandas.DataFrame = pandas.read_pickle('b')
</pre>
</div>
<div id="outline-container-org3eb4108" class="outline-4">
<h4 id="org3eb4108"><span class="section-number-4">2.15.1.</span> read<sub>csv</sub></h4>
<div class="outline-text-4" id="text-2-15-1">
<div class="org-src-container">
<pre class="src src-python"> <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1048;&#1084;&#1077;&#1085;&#1072; &#1087;&#1077;&#1088;&#1077;&#1084;&#1077;&#1085;&#1085;&#1099;&#1093;</span>
 <span style="color: #cae682;">columns</span> = [<span style="color: #95e454;">'age'</span>, <span style="color: #95e454;">'workclass'</span>, <span style="color: #95e454;">'fnlwgt'</span>, <span style="color: #95e454;">'education'</span>, <span style="color: #95e454;">'education-num'</span>,
            <span style="color: #95e454;">'marital-status'</span>, <span style="color: #95e454;">'occupation'</span>, <span style="color: #95e454;">'relationship'</span>, <span style="color: #95e454;">'race'</span>, <span style="color: #95e454;">'sex'</span>,
            <span style="color: #95e454;">'capital-gain'</span>, <span style="color: #95e454;">'capital-loss'</span>, <span style="color: #95e454;">'hours-per-week'</span>, <span style="color: #95e454;">'native-country'</span>, <span style="color: #95e454;">'income'</span>]
 <span style="color: #cae682;">df</span> = pd.read_csv(<span style="color: #95e454;">'adult.data'</span>, header=<span style="color: #e5786d; font-weight: bold;">None</span>, names=columns, na_values=<span style="color: #95e454;">' ?'</span>)
</pre>
</div>
</div>
</div>
<div id="outline-container-org46f5dbd" class="outline-4">
<h4 id="org46f5dbd"><span class="section-number-4">2.15.2.</span> json</h4>
<div class="outline-text-4" id="text-2-15-2">
<pre class="example">
pd.read_json('test_data.txt') - {"Клиент":"customer_3567","Дата_заключения_контракта":"2018-05-12","Дата_закрытия_контракта":"2018-06-13","Плановая_дата_закрытия_контракта":"2018-06-13","Сумма_выдачи_по_контракту":21891},{"Клиент":"customer_39200","Дата_заключения_контракта":"2019-03-29","Дата_закрытия_контракта":"2019-04-05","Плановая_дата_закрытия_контракта":"2019-04-05","Сумма_выдачи_по_контракту":11480},{"Клиент":"customer_26509","Дата_заключения_контракта":"2019-03-29","Дата_закрытия_контракта":"2019-04-30","Плановая_дата_закрытия_контракта":"2019-04-28","Сумма_выдачи_по_контракту":2640},{"Клиент":"customer_26623","Дата_заключения_контракта":"2019-03-06","Дата_закрытия_контракта":"2019-03-29","Плановая_дата_закрытия_контракта":"2019-04-06","Сумма_выдачи_по_контракту":25038},{"Клиент":"customer_14647","Дата_заключения_контракта":"2019-03-29","Дата_закрытия_контракта":"2019-04-15","Плановая_дата_закрытия_контракта":"2019-04-15","Сумма_выдачи_по_контракту":6369},{"Клиент":"customer_29658","Дата_заключения_контракта":"2019-12-05","Плановая_дата_закрытия_контракта":"2019-12-27","Сумма_выдачи_по_контракту":24172},{"Клиент":"customer_37798","Дата_заключения_контракта":"2019-11-18","Дата_закрытия_контракта":"2019-12-05","Плановая_дата_закрытия_контракта":"2019-12-18","Сумма_выдачи_по_контракту":9867},
</pre>
</div>
</div>
</div>
<div id="outline-container-org2ff07a5" class="outline-3">
<h3 id="org2ff07a5"><span class="section-number-3">2.16.</span> NaN</h3>
<div class="outline-text-3" id="text-2-16">
<p>
выбрать
</p>
<ul class="org-ul">
<li>df.loc[df.index.isnull()]</li>
</ul>
</div>
<div id="outline-container-orgc7194cd" class="outline-4">
<h4 id="orgc7194cd"><span class="section-number-4">2.16.1.</span> check</h4>
<div class="outline-text-4" id="text-2-16-1">
<ul class="org-ul">
<li>df.isnull().values.any() # true or false</li>
<li>df.isnull().sum() # кол-во по столбцам</li>
<li>df.hasna - # true or false</li>
</ul>
</div>
</div>
<div id="outline-container-org7fa863b" class="outline-4">
<h4 id="org7fa863b"><span class="section-number-4">2.16.2.</span> replace</h4>
<div class="outline-text-4" id="text-2-16-2">
<ul class="org-ul">
<li>df.dropna(subset=['column<sub>name</sub>'], inplace=True)</li>
<li>df['col'].fillna(0, inplace=True)</li>
</ul>
</div>
</div>
<div id="outline-container-org0965f58" class="outline-4">
<h4 id="org0965f58"><span class="section-number-4">2.16.3.</span> drop</h4>
<div class="outline-text-4" id="text-2-16-3">
<pre class="example">
df.dropna(subset=['col1', 'col2'],inplace=True) # remove rows if NaN in col1 or col2 column
</pre>
</div>
</div>
<div id="outline-container-orgc700f32" class="outline-4">
<h4 id="orgc700f32"><span class="section-number-4">2.16.4.</span> get not na</h4>
<div class="outline-text-4" id="text-2-16-4">
<pre class="example">
df = df[~df['col'].isna()]
</pre>
</div>
</div>
<div id="outline-container-org89d50ec" class="outline-4">
<h4 id="org89d50ec"><span class="section-number-4">2.16.5.</span> other</h4>
<div class="outline-text-4" id="text-2-16-5">
<div class="org-src-container">
<pre class="src src-python">
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">MEAN</span>
<span style="color: #8ac6f2; font-weight: bold;">from</span> sklearn.preprocessing <span style="color: #8ac6f2; font-weight: bold;">import</span> Imputer
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Define the values to replce and the strategy of choosing the replacement value</span>
<span style="color: #cae682;">imp</span> = Imputer(missing_values=<span style="color: #95e454;">"NaN"</span>, strategy=<span style="color: #95e454;">"mean"</span>)
<span style="color: #cae682;">cols</span> = [1, 13]
<span style="color: #cae682;">df</span>[cols] = imp.fit_transform(applicants[cols])

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">REMOVE string -&gt; NaN</span>
<span style="color: #cae682;">applicants</span>[cols] = applicants[cols].<span style="color: #e5786d;">apply</span>(pd.to_numeric, errors=<span style="color: #95e454;">'coerce'</span>)
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org4ec4d7c" class="outline-3">
<h3 id="org4ec4d7c"><span class="section-number-3">2.17.</span> Categorical encoding</h3>
<div class="outline-text-3" id="text-2-17">
</div>
<div id="outline-container-org85b1cd5" class="outline-4">
<h4 id="org85b1cd5"><span class="section-number-4">2.17.1.</span> replace values</h4>
<div class="outline-text-4" id="text-2-17-1">
<pre class="example">
df['a'] = df['a'].map({b'OK': 1, b'STOP': 0})
</pre>


<p>
replace date:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">repl_date</span>(df_in: DataFrame):
    <span style="color: #cae682;">df</span> = df_in.copy()  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">no side effect</span>
    <span style="color: #8ac6f2; font-weight: bold;">for</span> i, x <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">enumerate</span>(df.iloc[0, :]):
        <span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #e5786d;">isinstance</span>(x, date):
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(i, type(x))</span>
            <span style="color: #cae682;">cname</span> = df.columns[i]
            <span style="color: #cae682;">df</span>[cname] = df[cname].<span style="color: #e5786d;">map</span>(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x: x.year)
    <span style="color: #8ac6f2; font-weight: bold;">return</span> df
</pre>
</div>
</div>
</div>

<div id="outline-container-orge7c4754" class="outline-4">
<h4 id="orge7c4754"><span class="section-number-4">2.17.2.</span> label encoding</h4>
<div class="outline-text-4" id="text-2-17-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">for</span> c <span style="color: #8ac6f2; font-weight: bold;">in</span> label_e_columns:
    <span style="color: #cae682;">df</span>[c] = df[c].astype(<span style="color: #95e454;">'category'</span>).cat.codes

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">get  velues before encoding</span>
<span style="color: #e5786d;">print</span>(<span style="color: #e5786d;">dict</span>(<span style="color: #e5786d;">enumerate</span>(df[c].astype(<span style="color: #95e454;">'category'</span>).cat.categories)))
</pre>
</div>
</div>
</div>
<div id="outline-container-org1f0eea3" class="outline-4">
<h4 id="org1f0eea3"><span class="section-number-4">2.17.3.</span> encode binary</h4>
<div class="outline-text-4" id="text-2-17-3">
<pre class="example">
df['income'] = df['income'].map({' &lt;=50K': 0, ' &gt;50K': 1})
df['income'] = df['income'].notnull().astype(int)
</pre>
</div>
</div>
<div id="outline-container-org3e7a773" class="outline-4">
<h4 id="org3e7a773"><span class="section-number-4">2.17.4.</span> onehot encode</h4>
<div class="outline-text-4" id="text-2-17-4">
<div class="org-src-container">
<pre class="src src-python">
<span style="color: #cae682;">df</span> = pd.get_dummies(df, dummy_na=<span style="color: #e5786d; font-weight: bold;">False</span>)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dummy_na=True for debug</span>

<span style="color: #cae682;">s</span> = pd.Series(<span style="color: #e5786d;">list</span>(<span style="color: #95e454;">'abca'</span>))
pd.get_dummies(s)
   a  b  c
0  1  0  0
1  0  1  0
2  0  0  1
3  1  0  0
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgf818c0f" class="outline-3">
<h3 id="orgf818c0f"><span class="section-number-3">2.18.</span> mem usage</h3>
<div class="outline-text-3" id="text-2-18">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">Great snippet from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage</span>
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">reduce_mem_usage</span>(df):
    <span style="color: #f08080; font-style: italic;">""" iterate through all the columns of a dataframe and modify the data type</span>
<span style="color: #f08080; font-style: italic;">        to reduce memory usage.</span>
<span style="color: #f08080; font-style: italic;">    """</span>
    <span style="color: #cae682;">start_mem</span> = df.memory_usage().<span style="color: #e5786d;">sum</span>() / 1024**2
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">'Memory usage of dataframe is {:.2f} MB'</span>.<span style="color: #e5786d;">format</span>(start_mem))

    <span style="color: #8ac6f2; font-weight: bold;">for</span> col <span style="color: #8ac6f2; font-weight: bold;">in</span> df.columns:
        <span style="color: #cae682;">col_type</span> = df[col].dtype

        <span style="color: #8ac6f2; font-weight: bold;">if</span> col_type != <span style="color: #e5786d;">object</span>:
            <span style="color: #cae682;">c_min</span> = df[col].<span style="color: #e5786d;">min</span>()
            <span style="color: #cae682;">c_max</span> = df[col].<span style="color: #e5786d;">max</span>()
            <span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #e5786d;">str</span>(col_type)[:3] == <span style="color: #95e454;">'int'</span>:
                <span style="color: #8ac6f2; font-weight: bold;">if</span> c_min &gt; np.iinfo(np.int8).<span style="color: #e5786d;">min</span> <span style="color: #8ac6f2; font-weight: bold;">and</span> c_max &lt; np.iinfo(np.int8).<span style="color: #e5786d;">max</span>:
                    <span style="color: #cae682;">df</span>[col] = df[col].astype(np.int8)
                <span style="color: #8ac6f2; font-weight: bold;">elif</span> c_min &gt; np.iinfo(np.int16).<span style="color: #e5786d;">min</span> <span style="color: #8ac6f2; font-weight: bold;">and</span> c_max &lt; np.iinfo(np.int16).<span style="color: #e5786d;">max</span>:
                    <span style="color: #cae682;">df</span>[col] = df[col].astype(np.int16)
                <span style="color: #8ac6f2; font-weight: bold;">elif</span> c_min &gt; np.iinfo(np.int32).<span style="color: #e5786d;">min</span> <span style="color: #8ac6f2; font-weight: bold;">and</span> c_max &lt; np.iinfo(np.int32).<span style="color: #e5786d;">max</span>:
                    <span style="color: #cae682;">df</span>[col] = df[col].astype(np.int32)
                <span style="color: #8ac6f2; font-weight: bold;">elif</span> c_min &gt; np.iinfo(np.int64).<span style="color: #e5786d;">min</span> <span style="color: #8ac6f2; font-weight: bold;">and</span> c_max &lt; np.iinfo(np.int64).<span style="color: #e5786d;">max</span>:
                    <span style="color: #cae682;">df</span>[col] = df[col].astype(np.int64)
            <span style="color: #8ac6f2; font-weight: bold;">else</span>:
                <span style="color: #8ac6f2; font-weight: bold;">if</span> c_min &gt; np.finfo(np.float16).<span style="color: #e5786d;">min</span> <span style="color: #8ac6f2; font-weight: bold;">and</span> c_max &lt; np.finfo(np.float16).<span style="color: #e5786d;">max</span>:
                    <span style="color: #cae682;">df</span>[col] = df[col].astype(np.float16)
                <span style="color: #8ac6f2; font-weight: bold;">elif</span> c_min &gt; np.finfo(np.float32).<span style="color: #e5786d;">min</span> <span style="color: #8ac6f2; font-weight: bold;">and</span> c_max &lt; np.finfo(np.float32).<span style="color: #e5786d;">max</span>:
                    <span style="color: #cae682;">df</span>[col] = df[col].astype(np.float32)
                <span style="color: #8ac6f2; font-weight: bold;">else</span>:
                    <span style="color: #cae682;">df</span>[col] = df[col].astype(np.float64)
        <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">else:</span>
        <span style="color: #fa8072;">#    </span><span style="color: #99968b; font-style: italic;">df[col] = df[col].astype('category')</span>

    <span style="color: #cae682;">end_mem</span> = df.memory_usage().<span style="color: #e5786d;">sum</span>() / 1024**2
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">'Memory usage after optimization is: {:.2f} MB'</span>.<span style="color: #e5786d;">format</span>(end_mem))
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">'Decreased by {:.1f}%'</span>.<span style="color: #e5786d;">format</span>(100 * (start_mem - end_mem) / start_mem))

    <span style="color: #8ac6f2; font-weight: bold;">return</span> df
</pre>
</div>
</div>
</div>
<div id="outline-container-org7f05dbc" class="outline-3">
<h3 id="org7f05dbc"><span class="section-number-3">2.19.</span> rename column</h3>
<div class="outline-text-3" id="text-2-19">
<pre class="example">
df.columns.str.replace("original_column", "APP_SRC_REF")
</pre>

<p>
may rename several columns!
</p>
<ul class="org-ul">
<li>('doggod', 'god')</li>
<li>df.columns.str.replace("god", "war")</li>
<li>('dogwar', 'war')</li>
</ul>

<pre class="example">
df.rename(columns={"0":"0col", "1": "1col", 2:"2col", 3:"3col"}, inplace=True)
</pre>
</div>
</div>
<div id="outline-container-org24c3b13" class="outline-3">
<h3 id="org24c3b13"><span class="section-number-3">2.20.</span> delete column</h3>
<div class="outline-text-3" id="text-2-20">
<ol class="org-ol">
<li></li>

<li>df.drop('education', axis=1, inplace=True)</li>
<li>df.drop(['education', 'fabrication'], axis=1, inplace=True)</li>
</ol>
<p>
or
</p>
<ul class="org-ul">
<li>df.drop(columns=['education', 'fabrication'], inplace=True)</li>
<li>df.drop(df.iloc[:,1:3], axis=1)</li>
<li></li>

<li>del df['education']</li>
</ul>
</div>
</div>


<div id="outline-container-org3165b56" class="outline-3">
<h3 id="org3165b56"><span class="section-number-3">2.21.</span> delete row</h3>
<div class="outline-text-3" id="text-2-21">
</div>
<div id="outline-container-orgc8d7de1" class="outline-4">
<h4 id="orgc8d7de1"><span class="section-number-4">2.21.1.</span> delete NA</h4>
<div class="outline-text-4" id="text-2-21-1">
<pre class="example">
df.dropna(axis='index', subset=['column1'])
</pre>


<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">for</span> x <span style="color: #8ac6f2; font-weight: bold;">in</span> [<span style="color: #95e454;">'sd'</span>, <span style="color: #95e454;">'a2'</span>]:
  <span style="color: #cae682;">ids</span> = df.index[(df[<span style="color: #95e454;">"code"</span>] == x) &amp; (df[<span style="color: #95e454;">"something"</span>] == 1)]
  <span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #e5786d;">len</span>(ids) != 0:
     df.drop(ids, inplace=<span style="color: #e5786d; font-weight: bold;">True</span>)
</pre>
</div>
</div>
</div>
<div id="outline-container-org79309aa" class="outline-4">
<h4 id="org79309aa"><span class="section-number-4">2.21.2.</span> delete values that is in other df column</h4>
<div class="outline-text-4" id="text-2-21-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #cae682;">df1</span> = pd.DataFrame(data = {<span style="color: #95e454;">'col1'</span> : [1, 2, 3, 4, 5, 3],
                           <span style="color: #95e454;">'col2'</span> : [10, 11, 12, 13, 14, 10]})
<span style="color: #cae682;">df2</span> = pd.DataFrame(data = {<span style="color: #95e454;">'col1'</span> : [1, 2, 3],
                           <span style="color: #95e454;">'col2'</span> : [10, 11, 12]})
<span style="color: #e5786d;">print</span>(df1)
<span style="color: #e5786d;">print</span>(df2)
<span style="color: #cae682;">df_all</span> = df1.merge(df2.drop_duplicates(), on=[<span style="color: #95e454;">'col1'</span>,<span style="color: #95e454;">'col2'</span>],
                   how=<span style="color: #95e454;">'left'</span>, indicator=<span style="color: #e5786d; font-weight: bold;">True</span>)
<span style="color: #e5786d;">print</span>(df_all)
<span style="color: #e5786d;">print</span>(df_all[df_all[<span style="color: #95e454;">'_merge'</span>] == <span style="color: #95e454;">'left_only'</span>])
</pre>
</div>

<pre class="example" id="org15e95d1">
   col1  col2
0     1    10
1     2    11
2     3    12
3     4    13
4     5    14
5     3    10
   col1  col2
0     1    10
1     2    11
2     3    12
   col1  col2     _merge
0     1    10       both
1     2    11       both
2     3    12       both
3     4    13  left_only
4     5    14  left_only
5     3    10  left_only
   col1  col2     _merge
3     4    13  left_only
4     5    14  left_only
5     3    10  left_only
</pre>
</div>
</div>
</div>

<div id="outline-container-org4dd10fe" class="outline-3">
<h3 id="org4dd10fe"><span class="section-number-3">2.22.</span> type</h3>
<div class="outline-text-3" id="text-2-22">
<p>
automatic types
</p>

<p>
error= {‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’
</p>
<ul class="org-ul">
<li>ignore - invalid parsing will return the input</li>
<li>coerce - invalid parsing will be set as NaN.</li>
</ul>
</div>

<div id="outline-container-org13516b7" class="outline-4">
<h4 id="org13516b7"><span class="section-number-4">2.22.1.</span> types <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html">https://numpy.org/doc/stable/reference/arrays.scalars.html</a></h4>
<div class="outline-text-4" id="text-2-22-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Pandas dtype</th>
<th scope="col" class="org-left">Python type</th>
<th scope="col" class="org-left">NumPy type</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">object</td>
<td class="org-left">str or mixed</td>
<td class="org-left">string_, unicode_, mixed types</td>
</tr>

<tr>
<td class="org-left">Int64/Int32</td>
<td class="org-left">int</td>
<td class="org-left">int_, int8, int16, int32, int64, uint8, uint16, uint32, uint64</td>
</tr>

<tr>
<td class="org-left">float64</td>
<td class="org-left">float</td>
<td class="org-left">float_, float16, float32, float64</td>
</tr>

<tr>
<td class="org-left">bool</td>
<td class="org-left">bool</td>
<td class="org-left">bool_</td>
</tr>

<tr>
<td class="org-left">boolean</td>
<td class="org-left">allow NaN</td>
<td class="org-left">?</td>
</tr>

<tr>
<td class="org-left">datetime64</td>
<td class="org-left">NA</td>
<td class="org-left">datetime64[ns]</td>
</tr>

<tr>
<td class="org-left">timedelta[ns]</td>
<td class="org-left">NA</td>
<td class="org-left">NA</td>
</tr>

<tr>
<td class="org-left">category</td>
<td class="org-left">NA</td>
<td class="org-left">NA</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-org7be2ee3" class="outline-4">
<h4 id="org7be2ee3"><span class="section-number-4">2.22.2.</span> Display types</h4>
<div class="outline-text-4" id="text-2-22-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e5786d;">print</span>(df1.dtypes)
<span style="color: #cae682;">categorial_columns</span> = df.select_dtypes(include=[<span style="color: #95e454;">"object"</span>]).columns
<span style="color: #cae682;">numerical_columns</span> = df.select_dtypes(exclude=[<span style="color: #95e454;">"object"</span>]).columns
<span style="color: #e5786d;">print</span>(data[categorial_columns].describe())
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">unique</span>
<span style="color: #8ac6f2; font-weight: bold;">for</span> c <span style="color: #8ac6f2; font-weight: bold;">in</span> categorial_columns:
   <span style="color: #e5786d;">print</span>(c, data[c].unique())
</pre>
</div>
</div>
</div>

<div id="outline-container-org61677d4" class="outline-4">
<h4 id="org61677d4"><span class="section-number-4">2.22.3.</span> float to int</h4>
<div class="outline-text-4" id="text-2-22-3">
<p>
with NaN
</p>
<pre class="example">
df['col'] = df['col'].round().astype('Int32')
</pre>


<p>
without NaN
</p>
<ol class="org-ol">
<li>drop or fill NaN</li>
<li>df['col'] = df['col'].round().astype(int)</li>
</ol>
</div>
</div>

<div id="outline-container-org48ebf09" class="outline-4">
<h4 id="org48ebf09"><span class="section-number-4">2.22.4.</span> string to date</h4>
<div class="outline-text-4" id="text-2-22-4">
<pre class="example">
df['col1'] = pd.to_datetime(df['col1'])
df['Дата рождения клиента'] = pd.to_numeric(2021 - pd.to_datetime(df['Дата рождения клиента']).dt.year).astype('Int32')
</pre>
</div>
</div>
<div id="outline-container-org3b00f96" class="outline-4">
<h4 id="org3b00f96"><span class="section-number-4">2.22.5.</span> Category type</h4>
<div class="outline-text-4" id="text-2-22-5">
<p>
object string to category:
</p>
<ul class="org-ul">
<li>.astype("category")</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd1246da" class="outline-3">
<h3 id="orgd1246da"><span class="section-number-3">2.23.</span> if a&gt;5 c = True else False</h3>
<div class="outline-text-3" id="text-2-23">
<p>
<a href="https://datatofish.com/if-condition-in-pandas-dataframe/">https://datatofish.com/if-condition-in-pandas-dataframe/</a>
</p>
<pre class="example">
df.loc[df['set_of_numbers'] &lt;= 4, 'flag'] = 'True'
df['flag'].fillna(False,inplace=True)
</pre>
</div>
</div>
<div id="outline-container-org8b7c5cb" class="outline-3">
<h3 id="org8b7c5cb"><span class="section-number-3">2.24.</span> OTHER USE CASES</h3>
<div class="outline-text-3" id="text-2-24">
</div>
<div id="outline-container-org5b0560a" class="outline-4">
<h4 id="org5b0560a"><span class="section-number-4">2.24.1.</span> dictionary for panda</h4>
<div class="outline-text-4" id="text-2-24-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">list_to_dict</span>(dicts: <span style="color: #e5786d;">list</span>) -&gt; <span style="color: #e5786d;">dict</span>:
    <span style="color: #f08080; font-style: italic;">"""</span>
<span style="color: #f08080; font-style: italic;">    from [{col1':1, col2':3},</span>
<span style="color: #f08080; font-style: italic;">            {col1':2, col2':4}]</span>
<span style="color: #f08080; font-style: italic;">    to {'col1': [1, 2], 'col2': [3, 4]}</span>

<span style="color: #f08080; font-style: italic;">    :param dicts: list of dicts</span>
<span style="color: #f08080; font-style: italic;">    :return: dictionary for pandas</span>
<span style="color: #f08080; font-style: italic;">    """</span>

    <span style="color: #cae682;">d</span> = {}  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">target {'col1': [1, 2], 'col2': [3, 4]}</span>
    <span style="color: #8ac6f2; font-weight: bold;">for</span> k <span style="color: #8ac6f2; font-weight: bold;">in</span> dicts[0].keys():
        <span style="color: #cae682;">d</span>[k] = []

    <span style="color: #8ac6f2; font-weight: bold;">for</span> x <span style="color: #8ac6f2; font-weight: bold;">in</span> dicts:
        <span style="color: #8ac6f2; font-weight: bold;">for</span> k <span style="color: #8ac6f2; font-weight: bold;">in</span> dicts[0].keys():
            d[k].append(x[k])
    <span style="color: #8ac6f2; font-weight: bold;">return</span> d
</pre>
</div>
</div>
</div>

<div id="outline-container-org31a34cd" class="outline-4">
<h4 id="org31a34cd"><span class="section-number-4">2.24.2.</span> Example from dictionary to onehot</h4>
<div class="outline-text-4" id="text-2-24-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">list_to_dict</span>(dicts: <span style="color: #e5786d;">list</span>) -&gt; <span style="color: #e5786d;">dict</span>:
    <span style="color: #f08080; font-style: italic;">"""</span>
<span style="color: #f08080; font-style: italic;">    from [{col1':1, col2':3},</span>
<span style="color: #f08080; font-style: italic;">            {col1':2, col2':4}]</span>
<span style="color: #f08080; font-style: italic;">    to {'col1': [1, 2], 'col2': [3, 4]}</span>

<span style="color: #f08080; font-style: italic;">    :param dicts: list of dicts</span>
<span style="color: #f08080; font-style: italic;">    :return: dictionary for pandas</span>
<span style="color: #f08080; font-style: italic;">    """</span>

    <span style="color: #cae682;">d</span> = {}  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">target {'col1': [1, 2], 'col2': [3, 4]}</span>
    <span style="color: #8ac6f2; font-weight: bold;">for</span> k <span style="color: #8ac6f2; font-weight: bold;">in</span> dicts[0].keys():
        <span style="color: #cae682;">d</span>[k] = []

    <span style="color: #8ac6f2; font-weight: bold;">for</span> x <span style="color: #8ac6f2; font-weight: bold;">in</span> dicts:
        <span style="color: #8ac6f2; font-weight: bold;">for</span> k <span style="color: #8ac6f2; font-weight: bold;">in</span> dicts[0].keys():
            d[k].append(x[k])
    <span style="color: #8ac6f2; font-weight: bold;">return</span> d


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">repl_date</span>(df_in: DataFrame):
    <span style="color: #cae682;">df</span> = df_in.copy()  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">no side effect</span>
    <span style="color: #8ac6f2; font-weight: bold;">for</span> i, x <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">enumerate</span>(df.iloc[0, :]):
        <span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #e5786d;">isinstance</span>(x, date):
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(i, type(x))</span>
            <span style="color: #cae682;">cname</span> = df.columns[i]
            <span style="color: #cae682;">df</span>[cname] = df[cname].<span style="color: #e5786d;">map</span>(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x: x.year)
    <span style="color: #8ac6f2; font-weight: bold;">return</span> df


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">one_hot_p</span>(dicts: <span style="color: #e5786d;">list</span>):
    <span style="color: #cae682;">d</span> = list_to_dict(dicts)
    <span style="color: #cae682;">df</span> = pd.DataFrame(d)
    df.<span style="color: #cae682;">iloc</span>[:, 0] = df.iloc[:, 0].<span style="color: #e5786d;">map</span>({b<span style="color: #95e454;">'OK'</span>: 1, b<span style="color: #95e454;">'STOP'</span>: 0})
    <span style="color: #cae682;">df</span> = repl_date(df)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(df.to_string())</span>
    <span style="color: #cae682;">df2</span> = pd.get_dummies(df)
    <span style="color: #8ac6f2; font-weight: bold;">return</span> df2
</pre>
</div>
</div>
</div>
<div id="outline-container-org59094f3" class="outline-4">
<h4 id="org59094f3"><span class="section-number-4">2.24.3.</span> remove meanless columns</h4>
<div class="outline-text-4" id="text-2-24-3">
<div class="org-src-container">
<pre class="src src-python">df.fillna(0)
<span style="color: #8ac6f2; font-weight: bold;">for</span> x <span style="color: #8ac6f2; font-weight: bold;">in</span> df.iloc[:]:
    <span style="color: #8ac6f2; font-weight: bold;">if</span> df[x].<span style="color: #e5786d;">min</span>() == df[x].<span style="color: #e5786d;">max</span>():
        <span style="color: #8ac6f2; font-weight: bold;">del</span> df[x]
</pre>
</div>
</div>
</div>

<div id="outline-container-org119db94" class="outline-4">
<h4 id="org119db94"><span class="section-number-4">2.24.4.</span> Sum two columns containing NaN values</h4>
<div class="outline-text-4" id="text-2-24-4">
<pre class="example">
total = df['Jan'] + df['Feb'].fillna(0)
</pre>
</div>
</div>
<div id="outline-container-orgffd60f9" class="outline-4">
<h4 id="orgffd60f9"><span class="section-number-4">2.24.5.</span> reorder columns</h4>
<div class="outline-text-4" id="text-2-24-5">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">firest</span>
<span style="color: #cae682;">target</span> = df.pop(<span style="color: #95e454;">'first_decision_state'</span>)
df.insert(1, <span style="color: #95e454;">'first_decision_state'</span>, target)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">second</span>
<span style="color: #cae682;">cols</span> = df.columns.tolist()
<span style="color: #cae682;">cols</span> = cols[-1:] + cols[:-1] <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">last to first</span>
<span style="color: #cae682;">df</span> = df[cols]
</pre>
</div>
</div>
</div>
<div id="outline-container-org893ba78" class="outline-4">
<h4 id="org893ba78"><span class="section-number-4">2.24.6.</span> <span class="todo TODO">TODO</span> remove duplicates</h4>
<div class="outline-text-4" id="text-2-24-6">
<ul class="org-ul">
<li>df.sort<sub>values</sub>(by=['id', 'completed<sub>at</sub>'], na<sub>position</sub>='first')</li>
<li>df.drop<sub>duplicates</sub>('id', keep='last')</li>
</ul>
</div>
</div>
<div id="outline-container-org1f8d14e" class="outline-4">
<h4 id="org1f8d14e"><span class="section-number-4">2.24.7.</span> replace missing values by groups</h4>
<div class="outline-text-4" id="text-2-24-7">
<pre class="example">
df["value"] = df.groupby("name").transform(lambda x: x.fillna(x.mean()))
</pre>


<div class="org-src-container">
<pre class="src src-python">df.reset_index(inplace=<span style="color: #e5786d; font-weight: bold;">True</span>, drop=<span style="color: #e5786d; font-weight: bold;">True</span>)
<span style="color: #cae682;">shit_cols</span> = [<span style="color: #95e454;">'pickup_day_of_week'</span>, <span style="color: #95e454;">'geo_cluster'</span>, <span style="color: #95e454;">'events'</span>]
<span style="color: #cae682;">shits</span> = []
<span style="color: #8ac6f2; font-weight: bold;">for</span> shit <span style="color: #8ac6f2; font-weight: bold;">in</span> shit_cols:
    shits.append(pd.get_dummies(df[shit], prefix=shit, drop_first=<span style="color: #e5786d; font-weight: bold;">True</span>))
    <span style="color: #e5786d;">print</span>(pd.get_dummies(df[shit], prefix=shit))

<span style="color: #cae682;">shits</span> = pd.concat(shits, axis=1)
<span style="color: #e5786d;">print</span>(shits.head())
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"&#1057;&#1082;&#1086;&#1083;&#1100;&#1082;&#1086; &#1073;&#1080;&#1085;&#1072;&#1088;&#1085;&#1099;&#1093; &#1089;&#1090;&#1086;&#1083;&#1073;&#1094;&#1086;&#1074; &#1091; &#1074;&#1072;&#1089; &#1087;&#1086;&#1083;&#1091;&#1095;&#1080;&#1083;&#1086;&#1089;&#1100; &#1089;&#1075;&#1077;&#1085;&#1077;&#1088;&#1080;&#1088;&#1086;&#1074;&#1072;&#1090;&#1100; &#1089; &#1087;&#1086;&#1084;&#1086;&#1097;&#1100;&#1102; &#1086;&#1076;&#1085;&#1086;&#1082;&#1088;&#1072;&#1090;&#1085;&#1086;&#1075;&#1086; &#1082;&#1086;&#1076;&#1080;&#1088;&#1086;&#1074;&#1072;&#1085;&#1080;&#1103;?</span><span style="color: #e5786d; font-weight: bold;">\n</span><span style="color: #95e454;">"</span>,
      <span style="color: #e5786d;">len</span>(shits.columns))
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">['pickup_day_of_week_1', 'pickup_day_of_week_2', 'pickup_day_of_week_3', 'pickup_day_of_week_4', 'pickup_day_of_week_5', 'pickup_day_of_week_6', 'geo_cluster_1', 'geo_cluster_2', 'geo_cluster_3', 'geo_cluster_4', 'geo_cluster_5', 'geo_cluster_6', 'geo_cluster_7', 'geo_cluster_8', 'geo_cluster_9', 'events_None', 'events_Rain', 'events_Snow']</span>
<span style="color: #cae682;">df</span> = pd.concat([df.drop(columns=shit_cols), shits], axis=1)
</pre>
</div>
</div>
</div>
<div id="outline-container-org55791aa" class="outline-4">
<h4 id="org55791aa"><span class="section-number-4">2.24.8.</span> add count of occurences column</h4>
<div class="outline-text-4" id="text-2-24-8">
<pre class="example">
df['count'] = df.groupby('Col1')['Col1'].transform('size')
</pre>
</div>
</div>
</div>
<div id="outline-container-orgba4b3a2" class="outline-3">
<h3 id="orgba4b3a2"><span class="section-number-3">2.25.</span> troubleshooting</h3>
<div class="outline-text-3" id="text-2-25">
<pre class="example">
df['binary'][0] = 23
</pre>

<p>
SettingWithCopyWarning: rewrite:
</p>
<pre class="example">
df.loc[0, 'binary'] = 23
df.loc[:, c] = pd.Series([2,3,4,])
</pre>
</div>
</div>
<div id="outline-container-orgf949752" class="outline-3">
<h3 id="orgf949752"><span class="section-number-3">2.26.</span> pandas vs SQL</h3>
<div class="outline-text-3" id="text-2-26">
<pre class="example">
df[(df.col1 &gt; 5 ) &amp; (df.col2 &lt; 10)]
SELECT * FROM table WHERE col1 &gt; 5 AND col2 &lt; 10;
</pre>


<pre class="example">
df.groupby('col1').size()
SELECT col1, COUNT(*) FROM table GROUP BY col1;
</pre>


<pre class="example">
df.groupby('col1')['col2'].sum()
SELECT col1, SUM(col2) FROM table GROUP BY col1;
</pre>


<pre class="example">
df.sort_values(by='col1', ascending=False)
SELECT * FROM table ORDER BY col1 DESC;
</pre>


<p>
inner:
</p>
<pre class="example">
pd.merge(df1, df2, on='id')
SELECT * FROM table1 JOIN table2 ON table1.id=table2.id;
</pre>


<pre class="example">
pd.merge(df, df2, on='id', how='left')
SELECT * FROM table1 LEFT JOIN table2 ON table1.id=table2.id;
</pre>


<pre class="example">
df['col1'].nunique()
SELECT COUNT(DISTINCT col1) FROM table;
</pre>


<pre class="example">
df.rename(columns={'old_name': 'new_name'})
ALTER TABLE table RENAME COLUMN old_name TO new_name;
</pre>


<pre class="example">
df['new_column'] = value
ALTER TABLE table ADD COLUMN new_col INT;
</pre>


<pre class="example">
df['col1'].fillna(0)
SELECT COALESCE(col1, 0) FROM table;
</pre>


<pre class="example">
df['col1'] - df['col2']
SELECT col1 - col2 FROM table
</pre>


<pre class="example">
df['col1'] + df['col2']
SELECT CONCAT(col1, col2) FROM table;
</pre>


<pre class="example">
df['date_col'].dt.year
SELECT YEAR(date_col) FROM table;
</pre>


<pre class="example">
df[df['date_col'].str.contains('pattern')]
SELECT * FROM table WHERE col1 LIKE '%pattern%';
</pre>


<p>
moving average
</p>
<pre class="example">
df['col2'].rolling(window=3).mean()
SELECT col1, AVG(col2) OVER ( ORDER BY col1 ROWS BETWEEN 2 PRECEDING AND CURRENT ROW ) FROM table;
</pre>


<p>
row with max value in a column
</p>
<pre class="example">
df.col[df['col1'].idmax()]
SELECT * FROM table ORDER BY col1 DESC LIMIT 1;
</pre>


<pre class="example">
df.drop_duplicates()
DELETE FROM table WHERE rowid NOT IN ( SELECT MIN(rowid) FROM table GROUP BY col1, col2);
</pre>


<pre class="example">
df[df['col1'].isnull()]
SELECT * FROM table WHERE col1 IS NULL;
</pre>


<pre class="example">
df.dropna()
DELETE FROM table WHERE col1 IS NULL;
</pre>


<pre class="example">
df['col3'] = df['col2'].apply(lambda x:'High' if x &gt; 10 else 'Low')
SELECT col1, CASE WHEN col2 &gt; 10 THEN 'High' ELSE 'Low' END AS col3 FROM table;
</pre>


<pre class="example">
df.loc[len(df)] = [val1, val2]
INSERT INTO table (col1, col2) VALUES (val1, val2);
</pre>


<pre class="example">
df.loc[df['col2'] == val2, 'col1'] = val1
UPDATE table SET col1 = val1 WHERE col2 = val2;
</pre>
</div>
</div>
<div id="outline-container-org9a30cfa" class="outline-3">
<h3 id="org9a30cfa"><span class="section-number-3">2.27.</span> gentoo extensions</h3>
<div class="outline-text-3" id="text-2-27">
<div class="org-src-container">
<pre class="src src-text"> * Install additional packages for optional runtime features:
 *   dev-python/bottleneck for accelerating certain types of NaN evaluations, using specialized cython routines to achieve large speedups.
 *   &gt;=dev-python/numexpr-2.1 for accelerating certain numerical operations, using multiple cores as well as smart chunking and caching to achieve large speedups
 *   dev-python/blosc for for msgpack compression using blosc
 *   dev-python/matplotlib for Plotting support
 *   &gt;=dev-python/openpyxl-3.0.10 for Needed for Excel I/O
 *   dev-python/xlsxwriter for Needed for Excel I/O
 *   dev-python/xlrd for Needed for Excel I/O
 *   dev-python/xlwt for Needed for Excel I/O
 *   &gt;=dev-python/tables-3.7.0 for necessary for HDF5-based storage
 *   dev-python/rpy2 for R I/O support
 *   dev-python/statsmodels for Needed for parts of pandas.stats
 *   dev-python/scipy for miscellaneous statistical functions
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgde66e1f" class="outline-2">
<h2 id="orgde66e1f"><span class="section-number-2">3.</span> xlsx Excel file loading</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li>openpyxl <a href="https://openpyxl.readthedocs.io/en/stable/usage.html">https://openpyxl.readthedocs.io/en/stable/usage.html</a></li>
</ul>
</div>
<div id="outline-container-org2d822c5" class="outline-3">
<h3 id="org2d822c5"><span class="section-number-3">3.1.</span> partially loading - no solution</h3>
<div class="outline-text-3" id="text-3-1">
<p>
<a href="https://openpyxl.readthedocs.io/en/latest/optimized.html">https://openpyxl.readthedocs.io/en/latest/optimized.html</a>
</p>
</div>
</div>
</div>


<div id="outline-container-org5521d94" class="outline-2">
<h2 id="org5521d94"><span class="section-number-2">4.</span> h5py</h2>
<div class="outline-text-2" id="text-4">
<p>
emerge dev-python/h5py
</p>

<p>
<b>Groups</b> work like dictionaries, and <b>datasets</b> work like NumPy arrays.
</p>
</div>

<div id="outline-container-orgd88c386" class="outline-3">
<h3 id="orgd88c386"><span class="section-number-3">4.1.</span> Dataset object</h3>
<div class="outline-text-3" id="text-4-1">
<p>
<b>datasets</b> support operations:
</p>
<ul class="org-ul">
<li>compression</li>
<li>error-detection</li>
<li>chunked I/O</li>
</ul>

<p>
attributes:
</p>
<ul class="org-ul">
<li>shape</li>
<li>size</li>
<li>ndim</li>
<li>dtype</li>
<li>nbytes</li>
</ul>
</div>
</div>


<div id="outline-container-orgc20f53c" class="outline-3">
<h3 id="orgc20f53c"><span class="section-number-3">4.2.</span> terms</h3>
<div class="outline-text-3" id="text-4-2">
<dl class="org-dl">
<dt>datasets</dt><dd>array-like collections of data</dd>
<dt>groups</dt><dd>folder-like containers that hold datasets and other groups</dd>
</dl>
</div>
</div>
<div id="outline-container-org586ba49" class="outline-3">
<h3 id="org586ba49"><span class="section-number-3">4.3.</span> open</h3>
<div class="outline-text-3" id="text-4-3">
<ul class="org-ul">
<li>h5py.File() - acts like a Python dictionary</li>
</ul>
</div>
</div>
<div id="outline-container-orgfcbbfbf" class="outline-3">
<h3 id="orgfcbbfbf"><span class="section-number-3">4.4.</span> usage</h3>
<div class="outline-text-3" id="text-4-4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> h5py

<span style="color: #cae682;">f</span> = h5py.File(<span style="color: #95e454;">'mytestfile.hdf5'</span>, <span style="color: #95e454;">'r'</span>)
</pre>
</div>
</div>
</div>
<div id="outline-container-orgb99e276" class="outline-3">
<h3 id="orgb99e276"><span class="section-number-3">4.5.</span> links</h3>
<div class="outline-text-3" id="text-4-5">
<p>
<a href="https://docs.h5py.org/en/stable/">https://docs.h5py.org/en/stable/</a>
</p>
</div>
</div>
</div>
<div id="outline-container-org3e87dfc" class="outline-2">
<h2 id="org3e87dfc"><span class="section-number-2">5.</span> DVC</h2>
<div class="outline-text-2" id="text-5">
<p>
fetch data from external, codify data/models and reproducible pipelines.
</p>
</div>

<div id="outline-container-orga6f1ec7" class="outline-3">
<h3 id="orga6f1ec7"><span class="section-number-3">5.1.</span> features:</h3>
<div class="outline-text-3" id="text-5-1">
<ul class="org-ul">
<li>allow to download data from supported sources and keep hash of files.</li>
<li>versioning through codification - metafiles describing: datasets, ML artifacts, etc. to track.</li>
<li>allow to create pipiline, fix input and outputs, allow to avoid reruns.</li>
<li>DVCLive tool for experiment tracking</li>
<li>allow to create development server with shared and cached data, chached data may be shared between projects.</li>
</ul>

<p>
allow
</p>
<ul class="org-ul">
<li>Data validation: for example, validation against a schema or verifying pipeline consistency — correct
shapes, data types, etc.</li>
<li>Model validation: for example, input/output and performance validation — all dependencies present for
inference to run, and model scores within thresholds.</li>
</ul>
</div>
</div>
<div id="outline-container-org0e0abb7" class="outline-3">
<h3 id="org0e0abb7"><span class="section-number-3">5.2.</span> problem</h3>
<div class="outline-text-3" id="text-5-2">
<p>
to track and storing it in Git
</p>
<ul class="org-ul">
<li>large datasets</li>
<li>machine learning models - binary</li>
</ul>
</div>
</div>
<div id="outline-container-orgf114e77" class="outline-3">
<h3 id="orgf114e77"><span class="section-number-3">5.3.</span> terms</h3>
<div class="outline-text-3" id="text-5-3">
<dl class="org-dl">
<dt>data registry</dt><dd>git + dvc repository - for versioning of data and model files. The data itself is stored in
one or more <i>DVC remotes</i></dd>
<dt>DVC remotes</dt><dd>similar to Git remotes, used with <i>dvc push</i> and <i>dvc pull</i> commands. To add: <i>dvc remote</i> to .dvc/config.</dd>
<dt>stage</dt><dd>processing step of pipeline.  allow connecting code to its corresponding data input/dependencies and output.</dd>
<dt>dependencies</dt><dd>input for a stage. specified as paths in the dev field of ".dvc". Stages are invalidated
(considered outdated) when any of their dependencies change.
<ul class="org-ul">
<li><a href="https://dvc.org/doc/user-guide/data-management/remote-storage#supported-storage-types">https://dvc.org/doc/user-guide/data-management/remote-storage#supported-storage-types</a></li>
</ul></dd>
<dt>output</dt><dd>result of stage, tracked by DVC.</dd>
<dt>parameters</dt><dd>granular dependencies of stage, such as "batch size", DVC can track any key/value pair in a supported
parameters file (params.yaml by default)</dd>
<dt>metrics</dt><dd>feature of "experiments" - allow compare results.</dd>
<dt>cache</dt><dd>hidden storage .dvc/cache</dd>
</dl>
</div>
</div>
<div id="outline-container-org9c66d72" class="outline-3">
<h3 id="org9c66d72"><span class="section-number-3">5.4.</span> steps</h3>
<div class="outline-text-3" id="text-5-4">
<ul class="org-ul">
<li><b>dvc init</b> # running  inside a Git project</li>
<li><b>git commit -m "dvc init"</b></li>
</ul>
</div>
<div id="outline-container-org64f0e71" class="outline-4">
<h4 id="org64f0e71"><span class="section-number-4">5.4.1.</span> data:</h4>
<div class="outline-text-4" id="text-5-4-1">
<p>
way 1) git source
</p>
<ul class="org-ul">
<li>looks like it download file: dvc get <a href="https://github.com/iterative/dataset-registry">https://github.com/iterative/dataset-registry</a> get-started/data.xml -o data/data.xml</li>
<li><b>dvc add</b> to start tracking the dataset file. create: data/data.xml.dvc. Same to git add.</li>
<li><b>git add data/data.xml.dvc data/.gitignore</b></li>
<li>git commit -m "Add raw data"</li>
</ul>

<p>
way 2) local directory
</p>
<ul class="org-ul">
<li>mkdir /tmp/dvcstore</li>
<li>dvc remote add -d myremote /tmp/dvcstore</li>
</ul>

<p>
Now we have
</p>
<ol class="org-ol">
<li>file data/data.xml</li>
<li>in .gitignore record for this file</li>
<li>data/data.xml.dvc - hash</li>
</ol>

<p>
<b>dvc checkout</b> to sync data into your workspace
</p>
</div>
</div>
<div id="outline-container-orgaa1b1c1" class="outline-4">
<h4 id="orgaa1b1c1"><span class="section-number-4">5.4.2.</span> pipelines</h4>
<div class="outline-text-4" id="text-5-4-2">
<p>
abstract:
</p>
<ol class="org-ol">
<li>virtualenv venv &amp;&amp; echo "venv" &gt; .gitignore</li>
<li>source venv/bin/activate</li>
<li>pip install -r src/requirements.txt</li>
</ol>
<p>
actual:
.4) Create stage:
</p>
<pre class="example">
dvc stage add -n prepare \
                -p prepare.seed,prepare.split \
                -d src/prepare.py -d data/data.xml \
                -o data/prepared \
                python src/prepare.py data/data.xml
</pre>

<p>
generate <b>dvc.yaml</b> file, it have:
</p>
<ul class="org-ul">
<li>command that will be run: python src/prepare.py data/data.xml</li>
<li>-d - for dependencies</li>
<li>-o - output</li>
<li>-p - parameter, such as "batch size"</li>
</ul>
<p>
.5) <b>dvc repro</b> - run the pipeline. <b>dvc.lock</b> (a "state file") was created to capture the reproduction's
 results, that should be added to git.
</p>
<ul class="org-ul">
<li>automatically determines which parts of a project need to be run</li>
</ul>

<p>
.6) we can use <b>dvc stage add -d data/prepared</b> - to create chain.
</p>

<p>
.7) <b>dvc dag</b> - visualize chain of stages
.8) <b>dvc params diff</b> - show differences between iterations of pipeline. also there is <b>metrcis diff</b> and <b>ptots diff</b>
</p>
</div>
</div>
</div>
<div id="outline-container-orge8041f8" class="outline-3">
<h3 id="orge8041f8"><span class="section-number-3">5.5.</span> CML - Continuous Machine Learning</h3>
<div class="outline-text-3" id="text-5-5">
<p>
orchestration, testing and monitoring.
</p>
<ul class="org-ul">
<li>manage ML experiments, track who trained ML models or modified data and when.</li>
<li>Auto-generate reports with metrics and plots</li>
<li>Build your own ML platform using just GitHub or GitLab and your favorite cloud services: AWS, Azure, GCP, or
Kubernetes. No databases, services or complex setup needed.</li>
</ul>
<p>
links
</p>
<ul class="org-ul">
<li><a href="https://github.com/iterative/cml">https://github.com/iterative/cml</a></li>
<li><a href="https://cml.dev/doc">https://cml.dev/doc</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgc1f1692" class="outline-3">
<h3 id="orgc1f1692"><span class="section-number-3">5.6.</span> links</h3>
<div class="outline-text-3" id="text-5-6">
<ul class="org-ul">
<li><a href="https://github.com/iterative/dvc">https://github.com/iterative/dvc</a></li>
<li><a href="https://dvc.org/doc">https://dvc.org/doc</a></li>
<li><a href="https://dvc.org/doc/get-started">https://dvc.org/doc/get-started</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd766312" class="outline-2">
<h2 id="orgd766312"><span class="section-number-2">6.</span> matplotlib</h2>
<div class="outline-text-2" id="text-6">
<ul class="org-ul">
<li><a href="https://matplotlib.org/3.1.0/tutorials/introductory/pyplot.html">https://matplotlib.org/3.1.0/tutorials/introductory/pyplot.html</a></li>
</ul>
</div>
<div id="outline-container-org50fe13a" class="outline-3">
<h3 id="org50fe13a"><span class="section-number-3">6.1.</span> base</h3>
<div class="outline-text-3" id="text-6-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">ax</span>: Axes = <span style="color: #e5786d; font-weight: bold;">None</span>
<span style="color: #cae682;">fig</span>, <span style="color: #cae682;">ax</span> = plt.subplots(1,1, figsize=(19,10))
plt.subplots_adjust(left=0.076, right=0.96, bottom=0.04, top=0.96, wspace=0.30, hspace=0.7) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">if more than one</span>
plt.plot(.., legend=<span style="color: #95e454;">'line1'</span>)
<span style="color: #cae682;">title</span>=<span style="color: #95e454;">"graph"</span>
fig.suptitle(<span style="color: #95e454;">'test title'</span>, fontsize=20)
plt.suptitle(<span style="color: #95e454;">'test title'</span>, fontsize=20) <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">?</span>
plt.title(<span style="color: #95e454;">'Title!'</span>, {<span style="color: #95e454;">'fontsize'</span>:20})
plt.rc(<span style="color: #95e454;">'font'</span>, size=6) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">set font size</span>
plt.legend() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">add line descriptions</span>
fig.subplots_adjust(left=0.4, bottom=0.4)
plt.tight_layout() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">corret top, left, bottom, right automatic</span>
plt.show() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">or plt.savefig('name')</span>
plt.savefig(title)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">horizontal line</span>
plt.axhline(y = 2, color = <span style="color: #95e454;">'r'</span>, linestyle = <span style="color: #95e454;">'dashed'</span>, label = <span style="color: #95e454;">"red line"</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">vertical line</span>
plt.axvline(x = 7, color = <span style="color: #95e454;">'b'</span>, label = <span style="color: #95e454;">'axvline - full height'</span>)

plt.close()

plt.yticks(<span style="color: #e5786d;">range</span>(1,10)) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1096;&#1082;&#1072;&#1083;&#1072; &#1089;&#1083;&#1077;&#1074;&#1072;</span>
<span style="color: #8ac6f2; font-weight: bold;">as</span>.set_xlim(left=3) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1096;&#1082;&#1072;&#1083;&#1080;&#1088;&#1086;&#1074;&#1072;&#1090;&#1100; &#1086;&#1090; 3</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org5ff218d" class="outline-3">
<h3 id="org5ff218d"><span class="section-number-3">6.2.</span> subplot or multiple diagram in one window</h3>
<div class="outline-text-3" id="text-6-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> matplotlib.pyplot <span style="color: #8ac6f2; font-weight: bold;">as</span> plt
<span style="color: #cae682;">fig</span> = plt.figure(figsize=(2,2))
<span style="color: #cae682;">d1</span>: AxesSubplot = fig.add_subplot(1, 2, 1)   <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">1 row 2 columns - left</span>
<span style="color: #cae682;">d2</span>: AxesSubplot = fig.add_subplot(2, 2, 2)   <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">2x2 - top right</span>
<span style="color: #cae682;">d3</span>: AxesSubplot = fig.add_subplot(2, 2, 4)   <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">2x2 - bottom right</span>
plt.show()

<span style="color: #cae682;">d</span>: AxesSubplot = fig.add_subplot(121)   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">equal to 1, 2, 1</span>

fig.tight_layout() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">create spaces to allow set_title for graphics</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- define grid more precisely with rations</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">gs = fig.add_gridspec(nrows=2, ncols=2,</span>
<span style="color: #fa8072;">#                       </span><span style="color: #99968b; font-style: italic;">width_ratios=((1,)), # ncols length</span>
<span style="color: #fa8072;">#                       </span><span style="color: #99968b; font-style: italic;">height_ratios=(1,1), # nrows</span>
<span style="color: #fa8072;">#                       </span><span style="color: #99968b; font-style: italic;">left=0.1, right=0.1, bottom=0.1, top=0.9,</span>
<span style="color: #fa8072;">#                       </span><span style="color: #99968b; font-style: italic;">wspace=0.1, hspace=0.1)</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">ax = fig.add_subplot(gs[1, 0])</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">ax.hist(x, bins=bins1)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orgca3a3f9" class="outline-3">
<h3 id="orgca3a3f9"><span class="section-number-3">6.3.</span> x axis labels range</h3>
<div class="outline-text-3" id="text-6-3">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> matplotlib.ticker <span style="color: #8ac6f2; font-weight: bold;">as</span> plticker
<span style="color: #cae682;">loc</span> = plticker.MultipleLocator(base=50)
ax.xaxis.set_major_locator(loc)

</pre>
</div>
</div>
</div>
<div id="outline-container-org7c37f00" class="outline-3">
<h3 id="org7c37f00"><span class="section-number-3">6.4.</span> Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.</h3>
<div class="outline-text-3" id="text-6-4">
<p>
matplotlib.use
</p>
</div>
<div id="outline-container-org7573b97" class="outline-4">
<h4 id="org7573b97"><span class="section-number-4">6.4.1.</span> TkAgg</h4>
<div class="outline-text-4" id="text-6-4-1">
<pre class="example">
import matplotlib
matplotlib.use('TkAgg')
</pre>


<p>
Tkinter is a Python binding to the Tk GUI toolkit. It is the standard Python interface to the Tk GUI
toolkit, and is Python's de facto standard GUI.
</p>

<p>
Gentoo: included with standard Linux
</p>

<p>
Gentoo: USE="tk"
</p>
</div>
</div>
<div id="outline-container-org51366cf" class="outline-4">
<h4 id="org51366cf"><span class="section-number-4">6.4.2.</span> GTK3Agg</h4>
<div class="outline-text-4" id="text-6-4-2">
<p>
Xfce4 - GTK-based
</p>
<ul class="org-ul">
<li>find out GTK version: dpkg -l libgtk* | grep -e '<sup>i</sup>' | grep -e 'libgtk-*[0-9]'</li>
<li>find out glib version: ldd &#x2013;version</li>
<li>apt install libglib2.0-dev</li>
<li>apt install libgirepository1.0-dev</li>
<li>apt install libcairo2-dev</li>
<li>apt install python3-dev</li>
<li>pip install pycairo</li>
<li>apt-get install libgtk-3-dev</li>
<li>pip3 install PyGObject &#x2013;user</li>
</ul>

<pre class="example">
import matplotlib
matplotlib.use('GTK3Agg')
</pre>
</div>
</div>
</div>

<div id="outline-container-org45a0e3d" class="outline-3">
<h3 id="org45a0e3d"><span class="section-number-3">6.5.</span> usage</h3>
<div class="outline-text-3" id="text-6-5">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> matplotlib <span style="color: #8ac6f2; font-weight: bold;">import</span> pyplot <span style="color: #8ac6f2; font-weight: bold;">as</span> plt

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">time sequence</span>
plt.plot(<span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(a)), a)
plt.show()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">time sequence - &#1075;&#1086;&#1083;&#1091;&#1073;&#1099;&#1084;&#1080; &#1058;&#1086;&#1095;&#1082;&#1072;&#1084;&#1080;</span>
plt.plot(<span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(a)), a, <span style="color: #95e454;">'bo'</span>)
plt.show()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Histogram - distribution of numerical data</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1073;&#1072;&#1082;&#1077;&#1090; - &#1076;&#1080;&#1089;&#1082;&#1088;&#1077;&#1090;&#1085;&#1099;&#1081; &#1080;&#1085;&#1090;&#1077;&#1088;&#1074;&#1072;&#1083; &#1088;&#1072;&#1079;&#1073;&#1080;&#1077;&#1085;&#1080;&#1103;</span>
<span style="color: #cae682;">N</span> = 100
<span style="color: #cae682;">noise</span> = np.random.normal(loc=0.0, scale=1.0, size=(N, 1))
plt.hist(noise, bins=<span style="color: #95e454;">'auto'</span>, density=<span style="color: #e5786d; font-weight: bold;">True</span>)
plt.show()


<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Scatter - y=f(x) &#1074; &#1074;&#1080;&#1076;&#1077; &#1090;&#1086;&#1095;&#1077;&#1082;, &#1075;&#1076;&#1077; x &#1085;&#1077; &#1087;&#1086; &#1087;&#1086;&#1088;&#1103;&#1076;&#1082;&#1091;.</span>
plt.scatter(x_np, y_rows)
plt.show()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1042; &#1074;&#1080;&#1076;&#1077; &#1083;&#1080;&#1085;&#1080;&#1080;</span>
<span style="color: #cae682;">res</span> = <span style="color: #e5786d;">sorted</span>(<span style="color: #e5786d;">zip</span>(x_np,y_rows) , key=<span style="color: #8ac6f2; font-weight: bold;">lambda</span> k: k[0]) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1089;&#1086;&#1088;&#1090;&#1080;&#1088;&#1091;&#1077;&#1084; &#1087;&#1086; x</span>
<span style="color: #cae682;">x</span>, <span style="color: #cae682;">y</span> = <span style="color: #e5786d;">zip</span>(*res) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">unzip</span>
plt.plot(x, y)
plt.show()


<span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">matr_my - shape=(50,512) - value=[0;1] &#1074; &#1074;&#1080;&#1076;&#1077; &#1089;&#1087;&#1077;&#1082;&#1090;&#1088;&#1072;.</span>

plt.pcolormesh(matr_my, cmap=<span style="color: #95e454;">'RdBu'</span>)
plt.xlabel(<span style="color: #95e454;">'Depth'</span>)
plt.xlim((0, 512))
plt.ylabel(<span style="color: #95e454;">'Position'</span>)
plt.colorbar()
plt.show()

</pre>
</div>
</div>
</div>
<div id="outline-container-orge9857c4" class="outline-3">
<h3 id="orge9857c4"><span class="section-number-3">6.6.</span> do not close</h3>
<div class="outline-text-3" id="text-6-6">
<div class="org-src-container">
<pre class="src src-python">plt.close()
plt.plot()
plt.draw()
plt.pause(0.0001)
</pre>
</div>
</div>
</div>
<div id="outline-container-org08d3fd5" class="outline-3">
<h3 id="org08d3fd5"><span class="section-number-3">6.7.</span> Multiple Curves</h3>
<div class="outline-text-3" id="text-6-7">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> matplotlib.pyplot <span style="color: #8ac6f2; font-weight: bold;">as</span> plt
<span style="color: #cae682;">x</span> = [0,1,2,3,4]
<span style="color: #cae682;">y1</span> = [2,3,5,7,8]
<span style="color: #cae682;">y2</span> = [2, 3, 7, 7, 8]
plt.plot(x, y1, label = <span style="color: #95e454;">"1"</span>)
plt.plot(x, y2, label = <span style="color: #95e454;">"2"</span>)
plt.show()
</pre>
</div>
</div>
</div>
<div id="outline-container-orgfcaa070" class="outline-3">
<h3 id="orgfcaa070"><span class="section-number-3">6.8.</span> two windows with separate legend</h3>
<div class="outline-text-3" id="text-6-8">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">x</span> = [0, 1, 2, 3, 4]
<span style="color: #cae682;">y1</span> = [2, 3, 5, 7, 5]
<span style="color: #cae682;">y2</span> = [2, 3, 7, 7, 8]

<span style="color: #8ac6f2; font-weight: bold;">import</span> matplotlib.pyplot <span style="color: #8ac6f2; font-weight: bold;">as</span> plt
plt.figure()
<span style="color: #cae682;">ax</span> = plt.gca()
plt.plot(x, y1, label=<span style="color: #95e454;">"1"</span>)
plt.plot(x, y2, label=<span style="color: #95e454;">"2"</span>)

plt.figure()
plt.plot(x)
plt.figlegend(*ax.get_legend_handles_labels(), loc=<span style="color: #95e454;">'upper left'</span>)
plt.show()
</pre>
</div>
</div>
</div>

<div id="outline-container-org6b7e44a" class="outline-3">
<h3 id="org6b7e44a"><span class="section-number-3">6.9.</span> custom histogram</h3>
<div class="outline-text-3" id="text-6-9">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">get hist</span>
<span style="color: #cae682;">counts</span>, <span style="color: #cae682;">edges</span> = np.histogram(A, bins=10, <span style="color: #e5786d;">range</span>=(0,10))

<span style="color: #cae682;">bincenters</span> = 0.5 * (edges[1:] + edges[:-1])
<span style="color: #cae682;">spline</span> = make_interp_spline(bincenters, counts, k=k)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">that is how to loop edges</span>
<span style="color: #8ac6f2; font-weight: bold;">for</span> pair <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">zip</span>(binEdges[:-1], binEdges[1:]):
        <span style="color: #cae682;">low</span>, <span style="color: #cae682;">high</span> = pair

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">back to data</span>
<span style="color: #cae682;">A</span> = np.repeat(edges[:-1], counts)
</pre>
</div>
</div>
</div>
<div id="outline-container-orgcaff2f6" class="outline-3">
<h3 id="orgcaff2f6"><span class="section-number-3">6.10.</span> rotate x ticks</h3>
<div class="outline-text-3" id="text-6-10">
<pre class="example">
plt.xticks(rotation=10)
</pre>
</div>
</div>
<div id="outline-container-org516d08b" class="outline-3">
<h3 id="org516d08b"><span class="section-number-3">6.11.</span> CASES</h3>
<div class="outline-text-3" id="text-6-11">
</div>
<div id="outline-container-orgf8aab3c" class="outline-4">
<h4 id="orgf8aab3c"><span class="section-number-4">6.11.1.</span> <span class="todo TODO">TODO</span> bar plot with two y axes</h4>
</div>
<div id="outline-container-org32c03d8" class="outline-4">
<h4 id="org32c03d8"><span class="section-number-4">6.11.2.</span> varible in time</h4>
<div class="outline-text-4" id="text-6-11-2">
<pre class="example">
plt.plot_date(df['date'],df['x])
plt.show
</pre>
</div>
</div>
<div id="outline-container-org9f75269" class="outline-4">
<h4 id="org9f75269"><span class="section-number-4">6.11.3.</span> example plot grid</h4>
<div class="outline-text-4" id="text-6-11-3">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">_</span>, <span style="color: #cae682;">axs</span> = plt.subplots(10, <span style="color: #e5786d;">len</span>(reflectivity), figsize=(20, 20))
<span style="color: #8ac6f2; font-weight: bold;">for</span> index <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(reflectivity)):
    <span style="color: #8ac6f2; font-weight: bold;">for</span> row <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(10):
        <span style="color: #8ac6f2; font-weight: bold;">if</span> index == 0:
            axs[row, index].set_ylabel(f<span style="color: #95e454;">'</span>{row + 1}<span style="color: #95e454;"> &#1082;&#1084;'</span>)
        axs[row, index].imshow(reflectivity[index, row])
    axs[0, index].set_title(timestamps[index])
</pre>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-orgf3238bd" class="outline-2">
<h2 id="orgf3238bd"><span class="section-number-2">7.</span> pygal</h2>
<div class="outline-text-2" id="text-7">
<p>
installation:
</p>
<ul class="org-ul">
<li>media-gfx/cairosvg - for PNG output</li>
<li>dev-python/pygal</li>
</ul>
</div>
<div id="outline-container-orge145bc4" class="outline-3">
<h3 id="orge145bc4"><span class="section-number-3">7.1.</span> boxes</h3>
<div class="outline-text-3" id="text-7-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> pygal
<span style="color: #cae682;">box_plot</span> = pygal.Box()
box_plot.<span style="color: #cae682;">title</span> = <span style="color: #95e454;">'V8 benchmark results'</span>
box_plot.add(<span style="color: #95e454;">'Chrome'</span>, [6395, 8212, 7520, 7218, 12464, 1660, 2123, 8607])
box_plot.add(<span style="color: #95e454;">'Firefox'</span>, [7473, 8099, 11700, 2651, 6361, 1044, 3797, 9450])
box_plot.add(<span style="color: #95e454;">'Opera'</span>, [3472, 2933, 4203, 5229, 5810, 1828, 9013, 4669])
box_plot.add(<span style="color: #95e454;">'IE'</span>, [43, 41, 59, 79, 144, 136, 34, 102])
box_plot.render_to_png(<span style="color: #95e454;">'./autoimgs/python-ds-pygal-hello.png'</span>)
</pre>
</div>


<div id="org4d375fe" class="figure">
<p><img src="./autoimgs/python-ds-pygal-hello.png" alt="python-ds-pygal-hello.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org5f444b7" class="outline-3">
<h3 id="org5f444b7"><span class="section-number-3">7.2.</span> several separate</h3>
<div class="outline-text-3" id="text-7-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> PIL <span style="color: #8ac6f2; font-weight: bold;">import</span> Image
<span style="color: #8ac6f2; font-weight: bold;">import</span> pygal

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Create your plots</span>
<span style="color: #cae682;">line_chart</span> = pygal.Line()
line_chart.<span style="color: #cae682;">title</span> = <span style="color: #95e454;">'Line Chart'</span>
line_chart.<span style="color: #cae682;">x_labels</span> = [<span style="color: #95e454;">'A'</span>, <span style="color: #95e454;">'B'</span>, <span style="color: #95e454;">'C'</span>]
line_chart.add(<span style="color: #95e454;">'Series 1'</span>, [1, 2, 3])
line_chart.add(<span style="color: #95e454;">'Series 2'</span>, [4, 5, 6])
line_chart.render_to_png(<span style="color: #95e454;">'/tmp/line_chart.png'</span>)

<span style="color: #cae682;">bar_chart</span> = pygal.Bar()
bar_chart.<span style="color: #cae682;">title</span> = <span style="color: #95e454;">'Bar Chart'</span>
bar_chart.<span style="color: #cae682;">x_labels</span> = [<span style="color: #95e454;">'A'</span>, <span style="color: #95e454;">'B'</span>, <span style="color: #95e454;">'C'</span>]
bar_chart.add(<span style="color: #95e454;">'Series 1'</span>, [1, 2, 3])
bar_chart.add(<span style="color: #95e454;">'Series 2'</span>, [4, 5, 6])
bar_chart.render_to_png(<span style="color: #95e454;">'/tmp/bar_chart.png'</span>)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Open the images</span>
<span style="color: #cae682;">img1</span> = Image.<span style="color: #e5786d;">open</span>(<span style="color: #95e454;">'/tmp/line_chart.png'</span>)
<span style="color: #cae682;">img2</span> = Image.<span style="color: #e5786d;">open</span>(<span style="color: #95e454;">'/tmp/bar_chart.png'</span>)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Combine the images horizontally</span>
<span style="color: #cae682;">combined_img</span> = Image.new(<span style="color: #95e454;">'RGB'</span>, (img1.width + img2.width, <span style="color: #e5786d;">max</span>(img1.height, img2.height)))
combined_img.paste(img1, (0, 0))
combined_img.paste(img2, (img1.width, 0))

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Save the combined image</span>
combined_img.save(<span style="color: #95e454;">'./autoimgs/python-ds-pygal-sevaral.png'</span>, <span style="color: #95e454;">'PNG'</span>)
</pre>
</div>


<div id="orgb1f33cf" class="figure">
<p><img src="./autoimgs/python-ds-pygal-sevaral.png" alt="python-ds-pygal-sevaral.png" />
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org704380c" class="outline-2">
<h2 id="org704380c"><span class="section-number-2">8.</span> seaborn</h2>
<div class="outline-text-2" id="text-8">
<p>
<a href="https://images.datacamp.com/image/upload/v1676302629/Marketing/Blog/Seaborn_Cheat_Sheet.pdf">https://images.datacamp.com/image/upload/v1676302629/Marketing/Blog/Seaborn_Cheat_Sheet.pdf</a>
</p>
</div>
</div>
<div id="outline-container-org6df51e4" class="outline-2">
<h2 id="org6df51e4"><span class="section-number-2">9.</span> SciPy</h2>
<div class="outline-text-2" id="text-9">
<p>
adds more MATLAB-like functionality and Matplotlib is a plotting package that provides MATLAB-like plotting functionality
</p>
</div>

<div id="outline-container-org8d74293" class="outline-3">
<h3 id="org8d74293"><span class="section-number-3">9.1.</span> hierarchical lustering</h3>
<div class="outline-text-3" id="text-9-1">
</div>
<div id="outline-container-org009ae83" class="outline-4">
<h4 id="org009ae83"><span class="section-number-4">9.1.1.</span> distance and squareform</h4>
<div class="outline-text-4" id="text-9-1-1">
<p>
pdist - Pairwise distances between observations
</p>

<pre class="example">
&gt;&gt; array([0., 2., 2.])
</pre>


<p>
squarefor - returns a symmetric matrix where Z(i,j) corresponds to the pairwise distance between observations i and j
</p>


<p>
dist:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> scipy.spatial.distance <span style="color: #8ac6f2; font-weight: bold;">import</span> squareform
<span style="color: #8ac6f2; font-weight: bold;">from</span> scipy.spatial.distance <span style="color: #8ac6f2; font-weight: bold;">import</span> pdist
<span style="color: #cae682;">d</span> = pdist([[1,2],[1,2], [3,2]])
<span style="color: #e5786d;">print</span>(d)
<span style="color: #e5786d;">print</span>()
<span style="color: #cae682;">sq</span> = squareform(d)
<span style="color: #e5786d;">print</span>(sq)
</pre>
</div>

<p>
here:  [0. 0. 2.] (1) - distances between first observation and first, second, third observation
</p>
</div>
</div>

<div id="outline-container-org2ab86e5" class="outline-4">
<h4 id="org2ab86e5"><span class="section-number-4">9.1.2.</span> linkage</h4>
<div class="outline-text-4" id="text-9-1-2">
<ul class="org-ul">
<li>hierarchical/agglomerative <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage">https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage</a></li>
<li>very similar to the MATLAB linkage function <a href="https://www.mathworks.com/help/stats/linkage.html">https://www.mathworks.com/help/stats/linkage.html</a></li>
<li>better to print with:</li>
</ul>
<pre class="example">
[print(i+len(df), x) for i, x in enumerate(l)]
</pre>


<p>
At the i-th iteration, clusters with indices Z[i, 0] and Z[i, 1] are combined to form cluster n + i.
</p>
<ul class="org-ul">
<li>i-th row - iteration</li>
<li>0 and 1 - cluster numbers or observation number if x&lt;n</li>
<li>2 - is a distance between 0 and 1</li>
<li>Z[i, 3] represents the number of original observations in the newly formed cluster</li>
</ul>

<p>
format:
</p>
</div>
</div>
<div id="outline-container-org22e1552" class="outline-4">
<h4 id="org22e1552"><span class="section-number-4">9.1.3.</span> dendrogram</h4>
<div class="outline-text-4" id="text-9-1-3">
<p>
to see <b>count of observatins in clusters</b> - set truncate<sub>mode</sub>='level' and p=1.1 to level.
</p>
<pre class="example">
from matplotlib import pyplot as plt
dendrogram(Z=l, p=1.1, truncate_mode='level', labels=df.index, count_sort=False, distance_sort=False, orientation='right', leaf_font_size=15)
plt.show()
</pre>
</div>
</div>

<div id="outline-container-org98f101e" class="outline-4">
<h4 id="org98f101e"><span class="section-number-4">9.1.4.</span> cophentic correlation</h4>
<div class="outline-text-4" id="text-9-1-4">
<p>
pearson correlation
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgf19da48" class="outline-2">
<h2 id="orgf19da48"><span class="section-number-2">10.</span> Scikit-learn</h2>
<div class="outline-text-2" id="text-10">
<ul class="org-ul">
<li>based on numpy and SciPy</li>
<li>scikit-learn can be classified as a tool in the "Machine Learning Tools" category, while SciPy is grouped
under "Data Science Tools".</li>
</ul>
</div>
<div id="outline-container-orga74b0d9" class="outline-3">
<h3 id="orga74b0d9"><span class="section-number-3">10.1.</span> history</h3>
<div class="outline-text-3" id="text-10-1">
<ul class="org-ul">
<li>2007 begin</li>
<li>2010 first release</li>
</ul>
</div>
</div>
<div id="outline-container-orgf28bc6a" class="outline-3">
<h3 id="orgf28bc6a"><span class="section-number-3">10.2.</span> fast feature selection</h3>
<div class="outline-text-3" id="text-10-2">
<ul class="org-ul">
<li><a href="https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection">https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection</a></li>
<li>For regression: f<sub>regression</sub>, mutual<sub>info</sub><sub>regression</sub></li>
<li>For classification: chi2, f<sub>classif</sub>, mutual<sub>info</sub><sub>classif</sub></li>
<li>sparse data: chi2, mutual<sub>info</sub><sub>regression</sub>, mutual<sub>info</sub><sub>classif</sub> will deal with the data without making it dense.</li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> sklearn.feature_selection <span style="color: #8ac6f2; font-weight: bold;">import</span> SelectKBest
<span style="color: #8ac6f2; font-weight: bold;">from</span> sklearn.feature_selection <span style="color: #8ac6f2; font-weight: bold;">import</span> f_regression <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">or chi</span>
<span style="color: #cae682;">selector</span> = SelectKBest(f_regression, k=25)
<span style="color: #cae682;">X_new</span> = selector.fit_transform(X, y)
<span style="color: #cae682;">names</span> = X.columns.values[selector.get_support()]
<span style="color: #cae682;">scores</span> = selector.scores_[selector.get_support()]
<span style="color: #cae682;">names_scores</span> = <span style="color: #e5786d;">list</span>(<span style="color: #e5786d;">zip</span>(names, scores))
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"&#1059;&#1082;&#1072;&#1078;&#1080;&#1090;&#1077; &#1087;&#1088;&#1080;&#1079;&#1085;&#1072;&#1082;&#1080;, &#1082;&#1086;&#1090;&#1086;&#1088;&#1099;&#1077; &#1074;&#1086;&#1096;&#1083;&#1080; &#1074; &#1089;&#1087;&#1080;&#1089;&#1086;&#1082; &#1086;&#1090;&#1086;&#1073;&#1088;&#1072;&#1085;&#1085;&#1099;&#1093;:"</span>)
[<span style="color: #e5786d;">print</span>(x) <span style="color: #8ac6f2; font-weight: bold;">for</span> x <span style="color: #8ac6f2; font-weight: bold;">in</span> names_scores]

</pre>
</div>
</div>
</div>
<div id="outline-container-org3ce6637" class="outline-3">
<h3 id="org3ce6637"><span class="section-number-3">10.3.</span> sklearn.tree.DecisionTreeClassifier</h3>
<div class="outline-text-3" id="text-10-3">
<ol class="org-ol">
<li>the algorithm chooses a feature and makes a split</li>
<li>looks at the subsets and measures their impurity using the (gini,entropy) score (impurity)</li>
<li>for multiple thresholds and determines that the best split for the given feature</li>
<li>repeat for all features and nodes</li>
<li>from root to leaves</li>
</ol>
</div>
<div id="outline-container-org45f8dc3" class="outline-4">
<h4 id="org45f8dc3"><span class="section-number-4">10.3.1.</span> usage</h4>
<div class="outline-text-4" id="text-10-3-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">test</span> = 0  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">matrix.shape[0] // 3</span>
<span style="color: #cae682;">train</span> = <span style="color: #e5786d;">int</span>(matrix.shape[0] - test)

<span style="color: #cae682;">data_train</span> = matrix[:train, 1:].copy()  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">11 column - labels</span>
<span style="color: #cae682;">labels_train</span> = matrix[:train, 0].copy()  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">11 column - labels</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(labels_train)</span>
<span style="color: #cae682;">data_test</span> = matrix[train:, 1:].copy()  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">11 column - labels</span>
<span style="color: #cae682;">labels_test</span> = matrix[train:, 0].copy()  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">11 column - labels</span>

<span style="color: #e5786d;">print</span>(data_train.shape)
<span style="color: #e5786d;">print</span>(data_test.shape)
<span style="color: #e5786d;">print</span>(labels_train.shape)

<span style="color: #cae682;">models</span> = []
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">DecisionTreeClassifier ------------------------------</span>
<span style="color: #8ac6f2; font-weight: bold;">from</span> sklearn.tree <span style="color: #8ac6f2; font-weight: bold;">import</span> DecisionTreeClassifier

<span style="color: #cae682;">data_train</span>[np.isnan(data_train)] = -1  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">replace nan</span>
<span style="color: #cae682;">data_train_orig</span> = data_train.copy()

<span style="color: #cae682;">model</span> = DecisionTreeClassifier(random_state=42,
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1092;&#1091;&#1085;&#1082;&#1094;&#1080;&#1103; &#1076;&#1083;&#1103; impurity ('gini' &#1080;&#1083;&#1080; 'entropy')</span>
                                   criterion=<span style="color: #95e454;">'gini'</span>,
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1084;&#1072;&#1082;&#1089;&#1080;&#1084;&#1072;&#1083;&#1100;&#1085;&#1072;&#1103; &#1075;&#1083;&#1091;&#1073;&#1080;&#1085;&#1072; &#1076;&#1077;&#1088;&#1077;&#1074;&#1072;</span>
                                   max_depth=3,
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1084;&#1080;&#1085;&#1080;&#1084;&#1072;&#1083;&#1100;&#1085;&#1086;&#1077; &#1095;&#1080;&#1089;&#1083;&#1086; &#1101;&#1083;&#1077;&#1084;&#1077;&#1085;&#1090;&#1086;&#1074; &#1074; &#1091;&#1079;&#1083;&#1077; &#1076;&#1083;&#1103; &#1088;&#1072;&#1079;&#1073;&#1080;&#1077;&#1085;&#1080;&#1103; (&#1084;&#1086;&#1078;&#1077;&#1090; &#1073;&#1099;&#1090;&#1100; &#1076;&#1086;&#1083;&#1077;&#1081;)</span>
                                   min_samples_split=5,
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1084;&#1080;&#1085;&#1080;&#1084;&#1072;&#1083;&#1100;&#1085;&#1086;&#1077; &#1095;&#1080;&#1089;&#1083;&#1086; &#1101;&#1083;&#1077;&#1084;&#1077;&#1085;&#1090;&#1086;&#1074; &#1074; &#1083;&#1080;&#1089;&#1090;&#1077; (&#1084;&#1086;&#1078;&#1077;&#1090; &#1073;&#1099;&#1090;&#1100; &#1076;&#1086;&#1083;&#1077;&#1081;)</span>
                                   min_samples_leaf=2,
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1084;&#1080;&#1085;&#1080;&#1084;&#1072;&#1083;&#1100;&#1085;&#1086;&#1077; &#1079;&#1085;&#1072;&#1095;&#1077;&#1085;&#1080;&#1077; &#1076;&#1077;&#1083;&#1100;&#1090;&#1099; impurity</span>
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">min_impurity_decrease=0,</span>
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1074;&#1077;&#1089;&#1072; &#1076;&#1083;&#1103; &#1082;&#1083;&#1072;&#1089;&#1089;&#1086;&#1074; (&#1084;&#1086;&#1078;&#1085;&#1086; &#1076;&#1086;&#1087;&#1086;&#1083;&#1085;&#1080;&#1090;&#1077;&#1083;&#1100;&#1085;&#1086; &#1096;&#1090;&#1088;&#1072;&#1092;&#1086;&#1074;&#1072;&#1090;&#1100; &#1079;&#1072; &#1086;&#1096;&#1080;&#1073;&#1082;&#1091; &#1074; &#1085;&#1091;&#1078;&#1085;&#1099;&#1093; &#1082;&#1083;&#1072;&#1089;&#1089;&#1072;&#1093;).</span>
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1087;&#1086;&#1076;&#1076;&#1077;&#1088;&#1078;&#1080;&#1074;&#1072;&#1077;&#1090; &#1086;&#1087;&#1094;&#1080;&#1102; 'balanced'.</span>
                                   class_weight=<span style="color: #e5786d; font-weight: bold;">None</span>,
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1087;&#1088;&#1077;&#1076;&#1074;&#1072;&#1088;&#1080;&#1090;&#1077;&#1083;&#1100;&#1085;&#1072;&#1103; &#1089;&#1086;&#1088;&#1090;&#1080;&#1088;&#1086;&#1074;&#1082;&#1072;.</span>
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1091;&#1089;&#1082;&#1086;&#1088;&#1103;&#1077;&#1090; &#1086;&#1073;&#1091;&#1095;&#1077;&#1085;&#1080;&#1077; &#1085;&#1072; &#1076;&#1072;&#1085;&#1085;&#1099;&#1093; &#1085;&#1077;&#1073;&#1086;&#1083;&#1100;&#1096;&#1086;&#1075;&#1086; &#1088;&#1072;&#1079;&#1084;&#1077;&#1088;&#1072; &#1080;&#1083;&#1080; &#1089; &#1086;&#1075;&#1088;&#1072;&#1085;&#1080;&#1095;&#1077;&#1085;&#1085;&#1086;&#1081; &#1075;&#1083;&#1091;&#1073;&#1080;&#1085;&#1086;&#1081; &#1076;&#1077;&#1088;&#1077;&#1074;&#1072;.</span>
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1080;&#1085;&#1072;&#1095;&#1077; &#1079;&#1072;&#1084;&#1077;&#1076;&#1083;&#1103;&#1077;&#1090; &#1086;&#1073;&#1091;&#1095;&#1077;&#1085;&#1080;&#1077;.</span>
                                   presort=<span style="color: #e5786d; font-weight: bold;">False</span>
                                   )

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1054;&#1073;&#1091;&#1095;&#1072;&#1077;&#1084; &#1084;&#1086;&#1076;&#1077;&#1083;&#1100;</span>
    <span style="color: #cae682;">data_train</span>[np.isnan(data_train)] = -1
    model.fit(data_train, labels_train)

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">delete feature</span>
    <span style="color: #cae682;">parent_feature</span> = model.feature_importances_.argmax()  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">0...</span>
    <span style="color: #e5786d;">print</span>(parent_feature)
    <span style="color: #cae682;">data_train</span>[:, parent_feature] = np.zeros(data_train.shape[0])  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">(0...</span>

    <span style="color: #8ac6f2; font-weight: bold;">from</span> IPython.display <span style="color: #8ac6f2; font-weight: bold;">import</span> Image
    <span style="color: #8ac6f2; font-weight: bold;">from</span> sklearn.tree <span style="color: #8ac6f2; font-weight: bold;">import</span> export_graphviz
    <span style="color: #8ac6f2; font-weight: bold;">from</span> subprocess <span style="color: #8ac6f2; font-weight: bold;">import</span> call

    export_graphviz(model,
                    out_file=<span style="color: #95e454;">'tree.dot'</span>,
                    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1079;&#1072;&#1076;&#1072;&#1090;&#1100; &#1085;&#1072;&#1079;&#1074;&#1072;&#1085;&#1080;&#1103; &#1092;&#1080;&#1095;</span>
                    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">feature_names=X.columns,</span>
                    class_names=<span style="color: #e5786d; font-weight: bold;">None</span>,
                    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1087;&#1086;&#1082;&#1072;&#1079;&#1099;&#1074;&#1072;&#1090;&#1100; &#1085;&#1072;&#1079;&#1074;&#1072;&#1085;&#1080;&#1103; &#1087;&#1086;&#1083;&#1077;&#1081; &#1091; &#1095;&#1080;&#1089;&#1083;&#1077;&#1085;&#1085;&#1099;&#1093; &#1079;&#1085;&#1072;&#1095;&#1077;&#1085;&#1080;&#1081; &#1074;&#1085;&#1091;&#1090;&#1088;&#1080; &#1091;&#1079;&#1083;&#1072;</span>
                    label=<span style="color: #95e454;">'all'</span>,
                    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1088;&#1072;&#1089;&#1082;&#1088;&#1072;&#1096;&#1080;&#1074;&#1072;&#1090;&#1100; &#1091;&#1079;&#1083;&#1099; &#1074; &#1094;&#1074;&#1077;&#1090; &#1087;&#1088;&#1077;&#1086;&#1073;&#1083;&#1072;&#1076;&#1072;&#1102;&#1097;&#1077;&#1075;&#1086; &#1082;&#1083;&#1072;&#1089;&#1089;&#1072;</span>
                    filled=<span style="color: #e5786d; font-weight: bold;">True</span>,
                    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1087;&#1086;&#1082;&#1072;&#1079;&#1099;&#1074;&#1072;&#1090;&#1100; &#1079;&#1085;&#1072;&#1095;&#1077;&#1085;&#1080;&#1077; impurity &#1076;&#1083;&#1103; &#1082;&#1072;&#1078;&#1076;&#1086;&#1075;&#1086; &#1091;&#1079;&#1083;&#1072;</span>
                    impurity=<span style="color: #e5786d; font-weight: bold;">True</span>,
                    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1087;&#1086;&#1082;&#1072;&#1079;&#1099;&#1074;&#1072;&#1090;&#1100; &#1085;&#1086;&#1084;&#1077;&#1088;&#1072; &#1091;&#1079;&#1083;&#1086;&#1074;</span>
                    node_ids=<span style="color: #e5786d; font-weight: bold;">True</span>,
                    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1055;&#1086;&#1082;&#1072;&#1079;&#1099;&#1074;&#1072;&#1090;&#1100; &#1076;&#1086;&#1083;&#1080; &#1082;&#1072;&#1078;&#1076;&#1086;&#1075;&#1086; &#1082;&#1083;&#1072;&#1089;&#1089;&#1072; &#1074; &#1091;&#1079;&#1083;&#1072;&#1093; (&#1072; &#1085;&#1077; &#1082;&#1086;&#1083;&#1080;&#1095;&#1077;&#1089;&#1090;&#1074;&#1086;)</span>
                    proportion=<span style="color: #e5786d; font-weight: bold;">True</span>,
                    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1055;&#1086;&#1074;&#1077;&#1088;&#1085;&#1091;&#1090;&#1100; &#1076;&#1077;&#1088;&#1077;&#1074;&#1086; &#1085;&#1072; 90 &#1075;&#1088;&#1072;&#1076;&#1091;&#1089;&#1086;&#1074; (&#1074;&#1077;&#1088;&#1090;&#1080;&#1082;&#1072;&#1083;&#1100;&#1085;&#1072;&#1103; &#1086;&#1088;&#1080;&#1077;&#1085;&#1090;&#1072;&#1094;&#1080;&#1103;)</span>
                    rotate=<span style="color: #e5786d; font-weight: bold;">False</span>,
                    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1063;&#1080;&#1089;&#1083;&#1086; &#1090;&#1086;&#1095;&#1077;&#1082; &#1087;&#1086;&#1089;&#1083;&#1077; &#1079;&#1072;&#1087;&#1103;&#1090;&#1086;&#1081; &#1076;&#1083;&#1103; &#1086;&#1090;&#1086;&#1073;&#1088;&#1072;&#1078;&#1072;&#1077;&#1084;&#1099;&#1093; &#1076;&#1088;&#1086;&#1073;&#1077;&#1081;</span>
                    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">precision=3</span>
                    )

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1055;&#1088;&#1077;&#1086;&#1073;&#1088;&#1072;&#1079;&#1091;&#1077;&#1084; &#1092;&#1072;&#1081;&#1083; tree.dot &#1074; tree.png</span>
    call([<span style="color: #95e454;">'dot'</span>, <span style="color: #95e454;">'-Tpng'</span>, <span style="color: #95e454;">'tree.dot'</span>, <span style="color: #95e454;">'-o'</span>, <span style="color: #95e454;">'tree.png'</span>])
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1042;&#1089;&#1090;&#1072;&#1074;&#1083;&#1103;&#1077;&#1084; &#1082;&#1072;&#1088;&#1090;&#1080;&#1085;&#1082;&#1091; &#1074; &#1073;&#1083;&#1086;&#1082;&#1085;&#1086;&#1090;</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Image("tree.png")</span>

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">data_test[np.isnan(data_test)] = -1</span>
    <span style="color: #cae682;">test_result</span> = model.predict(data_train_orig)

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">RESULT</span>
    <span style="color: #cae682;">auc</span> = sklearn.metrics.roc_auc_score(labels_test, test_result)

    <span style="color: #cae682;">gini</span> = 2 * auc - 1
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org7d3e4e6" class="outline-3">
<h3 id="org7d3e4e6"><span class="section-number-3">10.4.</span> Tuning the hyper-parameters <a href="https://scikit-learn.org/stable/modules/grid_search.html">https://scikit-learn.org/stable/modules/grid_search.html</a></h3>
<div class="outline-text-3" id="text-10-4">
<ul class="org-ul">
<li>GridSearchCV - Exhaustive Grid Search,  all parameter combinations
<ul class="org-ul">
<li>HalvingGridSearchCV - evaluating all the candidates with a small amount of resources and iteratively selects the best candidates, using more and more resources.</li>
</ul></li>
<li>RandomizedSearchCV - given number of candidates
<ul class="org-ul">
<li>HalvingRandomSearchCV -</li>
</ul></li>
</ul>

<p>
SH is an iterative selection process where all candidates (the parameter combinations) are evaluated with a
 small amount of resources at the first iteration.  the resource is
</p>
<ul class="org-ul">
<li>the number of training samples</li>
<li>arbitrary numeric parameter such as <b>n<sub>estimators</sub></b> in a <b>random forest</b>.</li>
</ul>

<p>
parameters
</p>
<ul class="org-ul">
<li><b>factor</b> (&gt; 1) - each iteration, the number of resources per candidate is multiplied, candidates is divided</li>
</ul>
<p>
(3 usually works well)
</p>
<ul class="org-ul">
<li>HalvingRandomSearchCV: <b>aggressive<sub>elimination</sub>=True</b> can also be used if the number of available resources is
small.</li>
</ul>

<p>
RandomizedSearchCV vs GridSearchCV <a href="https://analyticsindiamag.com/why-is-random-search-better-than-grid-search-for-machine-learning/">https://analyticsindiamag.com/why-is-random-search-better-than-grid-search-for-machine-learning/</a>
</p>
</div>
</div>

<div id="outline-container-org2f078ea" class="outline-3">
<h3 id="org2f078ea"><span class="section-number-3">10.5.</span> feature importance</h3>
<div class="outline-text-3" id="text-10-5">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> sklearn.ensemble <span style="color: #8ac6f2; font-weight: bold;">import</span> GradientBoostingRegressor
<span style="color: #cae682;">dt</span> = GradientBoostingRegressor()
<span style="color: #cae682;">indices</span> = np.argsort(dt.feature_importances_)[::-1]  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">sort indexes</span>
<span style="color: #e5786d;">print</span>(indices)
<span style="color: #8ac6f2; font-weight: bold;">for</span> i <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(X_column_names)):  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1087;&#1077;&#1088;&#1074;&#1099;&#1077; 100</span>
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"%d. %s (%f)"</span> % (i + 1, X_column_names[indices[i]], dt.feature_importances_[indices[i]] / 100))

</pre>
</div>
</div>
</div>

<div id="outline-container-org53e79d8" class="outline-3">
<h3 id="org53e79d8"><span class="section-number-3">10.6.</span> Encoders - sklearn.preprocessing.*</h3>
<div class="outline-text-3" id="text-10-6">
<ul class="org-ul">
<li>OrdinalEncoder</li>
<li>OneHotEncoder -
<ul class="org-ul">
<li>min<sub>frequency</sub>=0.5 - all values that have &lt; min<sub>frequency</sub> will be as 'others' column</li>
</ul></li>
<li>TargetEncoder - target mean with the target mean conditioned on the value of the category, good for features
with high cordinality and hight correlation with target. Shuffle by default, use internal cross-fitting.</li>
</ul>
</div>
</div>

<div id="outline-container-org936120e" class="outline-3">
<h3 id="org936120e"><span class="section-number-3">10.7.</span> suppress warnings</h3>
<div class="outline-text-3" id="text-10-7">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> warnings
warnings.filterwarnings(<span style="color: #95e454;">"ignore"</span>, category=<span style="color: #92a65e; font-weight: bold;">Warning</span>)
<span style="color: #8ac6f2; font-weight: bold;">from</span> sklearn.metrics <span style="color: #8ac6f2; font-weight: bold;">import</span> precision_score
<span style="color: #cae682;">y_true</span> = [0, 1, 2, 0, 1, 2]
<span style="color: #cae682;">y_pred</span> = [0, 2, 0, 0, 0, 0]
<span style="color: #e5786d;">print</span>(precision_score(y_true, y_pred, average=<span style="color: #95e454;">'macro'</span>))
</pre>
</div>

<pre class="example">
0.13333333333333333
</pre>
</div>
</div>
</div>

<div id="outline-container-org6e8d19f" class="outline-2">
<h2 id="org6e8d19f"><span class="section-number-2">11.</span> <span class="todo TODO">TODO</span> statsmodels</h2>
<div class="outline-text-2" id="text-11">
<p>
used in econometrics, generalised-linear models, time-series-analysis, statistical hypothesis testing, and
 regression models for "rigorous statistics", for explanatory analysis
</p>
</div>
</div>
<div id="outline-container-orgc0f9c45" class="outline-2">
<h2 id="orgc0f9c45"><span class="section-number-2">12.</span> <span class="todo TODO">TODO</span> RAPIDS</h2>
<div class="outline-text-2" id="text-12">
<p>
GPU accelerated data science
</p>
</div>
</div>
<div id="outline-container-orgbfe04a8" class="outline-2">
<h2 id="orgbfe04a8"><span class="section-number-2">13.</span> TensorFlow (TF)</h2>
<div class="outline-text-2" id="text-13">
<ul class="org-ul">
<li>лекция <a href="https://www.youtube.com/watch?v=sTkUjqsjs00">https://www.youtube.com/watch?v=sTkUjqsjs00</a></li>
<li>tutorial <a href="https://www.tensorflow.org/tutorials/">https://www.tensorflow.org/tutorials/</a></li>
<li>guide <a href="https://www.tensorflow.org/guide/">https://www.tensorflow.org/guide/</a></li>
<li>lections pdf <a href="http://web.stanford.edu/class/cs20si/lectures/">http://web.stanford.edu/class/cs20si/lectures/</a></li>
</ul>
<p>
Apache 2.0
</p>
<ul class="org-ul">
<li>разработанная компанией Google</li>
<li>used for machine learning applications such as neural networks</li>
<li>Создается вычислительный граф. - Графовый фреймворк</li>
</ul>


<p>
‐ Cleverhans - фреймворд чтобы атаковать и защищать модели??
</p>
<ul class="org-ul">
<li>Lucid - визуализировать</li>

<li>define computation graph - позволяет автоматическое дифференцирование
<ul class="org-ul">
<li>Nodes - operators, varibles, constants</li>
<li>Edges - tensors</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org0f86393" class="outline-3">
<h3 id="org0f86393"><span class="section-number-3">13.1.</span> history</h3>
<div class="outline-text-3" id="text-13-1">
<p>
2.4.0
</p>
<ul class="org-ul">
<li>MultiWorkerMirroredStrategy - no longer experimental</li>
<li>TensorFlow Profiler now supports profiling `MultiWorkerMirroredStrategy`</li>
</ul>
</div>
</div>
<div id="outline-container-org26337b8" class="outline-3">
<h3 id="org26337b8"><span class="section-number-3">13.2.</span> terms</h3>
<div class="outline-text-3" id="text-13-2">
<dl class="org-dl">
<dt>batch</dt><dd>weights and biases are only updated after all of the inputs and targets are presented</dd>
<dt>epoch</dt><dd>is one single pass over the entire training set</dd>
<dt>train<sub>step</sub></dt><dd>function that is called by fit() for every batch of data. Execute Forward pass with
tf.GradientTape(). Return a dict mapping metric names to current value.</dd>
<dt>Operations (Ops)</dt><dd>high level operation on Tensor.</dd>
<dt>Kernel</dt><dd>implementation of an op tied to specific hardware/platform. Some ops have a one-to-one mapping
from op to kernel while other ops use multiple kernels.</dd>
<dt>Gradient / GradFunc</dt><dd>The ‘backward mode’ definition of an op/kernel that computes the derivative of that
function with regards to some input.</dd>
</dl>
</div>
</div>
<div id="outline-container-org7e3aff5" class="outline-3">
<h3 id="org7e3aff5"><span class="section-number-3">13.3.</span> Features:</h3>
<div class="outline-text-3" id="text-13-3">
<ul class="org-ul">
<li>Stable</li>
<li>Well-documented sources</li>
<li>Flexibility</li>
<li>Portability</li>
<li>Scalability</li>
<li>Popularity</li>
</ul>
<p>
Cons:
</p>
<ul class="org-ul">
<li>Невозможно обучать распределенно</li>
<li>Метрический тензор нельзя запрограммировать</li>
</ul>
</div>
</div>

<div id="outline-container-org8ffb24a" class="outline-3">
<h3 id="org8ffb24a"><span class="section-number-3">13.4.</span> hello world</h3>
<div class="outline-text-3" id="text-13-4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #8ac6f2; font-weight: bold;">import</span> timeit

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- set device manually</span>
<span style="color: #8ac6f2; font-weight: bold;">try</span>:
    <span style="color: #cae682;">gpus</span> = tf.config.experimental.list_physical_devices(<span style="color: #95e454;">'GPU'</span>)
    tf.config.set_visible_devices(gpus[0], <span style="color: #95e454;">'GPU'</span>)
    <span style="color: #cae682;">logical_gpus</span> = tf.config.list_logical_devices(<span style="color: #95e454;">'GPU'</span>)
<span style="color: #8ac6f2; font-weight: bold;">except</span> <span style="color: #92a65e; font-weight: bold;">RuntimeError</span> <span style="color: #8ac6f2; font-weight: bold;">as</span> e:
    <span style="color: #e5786d;">print</span>(e)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- eager execution</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Note:  steps through all of the program operations, needed or not.</span>
<span style="color: #cae682;">a</span> = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], trainable=<span style="color: #e5786d; font-weight: bold;">False</span>)
<span style="color: #cae682;">b</span> = tf.Variable([[1.0, 2.0, 3.0]], trainable=<span style="color: #e5786d; font-weight: bold;">False</span>)
<span style="color: #cae682;">k</span> = a * b
<span style="color: #e5786d;">print</span>(k)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- graph execution</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Note: graph execution enables portability outside Python and tends to offer better performance</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">consist of: tf.Operation objects, which represent units of computation; and tf.Tensor objects, which represent the units of data that flow between operations</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">using graph directly is depricated</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Graph execution only executes the operations necessary to produce the observable effects, which includes:  "Non-strict execution"</span>

<span style="color: #cae682;">x</span> = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">power</span>(x, y):
  <span style="color: #cae682;">result</span> = tf.eye(10, dtype=tf.dtypes.int32)
  <span style="color: #8ac6f2; font-weight: bold;">for</span> _ <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(y):
    <span style="color: #cae682;">result</span> = tf.matmul(x, result)
  <span style="color: #8ac6f2; font-weight: bold;">return</span> result

<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"Eager execution:"</span>, timeit.timeit(<span style="color: #8ac6f2; font-weight: bold;">lambda</span>: power(x, 100), number=1000), <span style="color: #95e454;">"seconds"</span>)

<span style="color: #cae682;">power_as_graph</span> = tf.function(power)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"Graph execution:"</span>, timeit.timeit(<span style="color: #8ac6f2; font-weight: bold;">lambda</span>: power_as_graph(x, 100), number=1000), <span style="color: #95e454;">"seconds"</span>)
</pre>
</div>
</div>
</div>
<div id="outline-container-org1d661a0" class="outline-3">
<h3 id="org1d661a0"><span class="section-number-3">13.5.</span> deployment</h3>
<div class="outline-text-3" id="text-13-5">
<ul class="org-ul">
<li>TensorFlow Serving - models on servers, be them in-house or on the cloud, and is used within the TensorFlow
Extended (TFX) end-to-end Machine Learning platform.
<ul class="org-ul">
<li>deploy with static API.</li>
<li>tightly integrated with <b>Google Cloud</b> via <b>Vertex AI</b> and integrates with Kubernetes and Docker.</li>
<li>Android and iOS, as well as microcontrollers (ARM with Bazel or CMake) and embedded Linux (e.g. a Coral device)</li>
</ul></li>
<li>TensorFlow Lite - on mobile or IoT/embedded devices</li>
</ul>

<p>
TFLite  addresses 5 constraints for on-device Artificial Intelligence:
</p>
<ul class="org-ul">
<li>latency, connectivity, privacy, size, and power consumption</li>
</ul>
</div>
</div>
<div id="outline-container-org56008bd" class="outline-3">
<h3 id="org56008bd"><span class="section-number-3">13.6.</span> ecosystem</h3>
<div class="outline-text-3" id="text-13-6">
<ul class="org-ul">
<li>TensorFlow Hub <a href="https://www.tensorflow.org/hub">https://www.tensorflow.org/hub</a>
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/hub/tutorials">https://www.tensorflow.org/hub/tutorials</a></li>
<li><a href="https://tfhub.dev/s?subtype=module%2Cplaceholder">https://tfhub.dev/s?subtype=module%2Cplaceholder</a></li>
</ul></li>
<li>Model Garden - source code for Hub models - Models and examples built with TensorFlow <a href="https://github.com/tensorflow/models">https://github.com/tensorflow/models</a>
<ul class="org-ul">
<li>the source code for SOTA models available</li>
</ul></li>
<li>Extended (TFX) TensorFlow's end-to-end platform for model deployment. <a href="https://www.tensorflow.org/tfx">https://www.tensorflow.org/tfx</a>
<ul class="org-ul">
<li>can use Apache Airflow/Beam or Kubernetes for orchestration</li>
<li>tightly integrated with Google Cloud and can be used with Vertex AI Pipelines.</li>
</ul></li>
<li>Vertex AI -  Google Cloud’s unified Machine Learning platform
<ul class="org-ul">
<li>seeks to unify services into one platform
<ul class="org-ul">
<li>GCP <a href="https://cloud.google.com/">https://cloud.google.com/</a>,</li>
<li>AI Platform <a href="https://cloud.google.com/ai-platform/docs/technical-overview">https://cloud.google.com/ai-platform/docs/technical-overview</a></li>
<li>AutoML <a href="https://cloud.google.com/automl?ref=assemblyai.com">https://cloud.google.com/automl?ref=assemblyai.com</a></li>
</ul></li>
</ul></li>
<li>MediaPipe  framework for building multimodal, cross-platform applied Machine Learning pipelines <a href="https://mediapipe.dev/">https://mediapipe.dev/</a> <a href="https://google.github.io/mediapipe/">https://google.github.io/mediapipe/</a></li>
<li>Coral - local AI - offers an array of hardware products
<ul class="org-ul">
<li>powerful Raspberry Pis  with Edge TPUs</li>
</ul></li>
<li>TensorFlow.js -  JavaScript library -  to train and deploy models both in the browser and server-side with Node.js</li>
<li>Cloud - allows you to connect your local environment to Google Cloud -  <a href="https://www.tensorflow.org/cloud">https://www.tensorflow.org/cloud</a></li>
<li>Colab</li>
<li>Datasets <a href="https://research.google/tools/datasets/?ref=assemblyai.com">https://research.google/tools/datasets/?ref=assemblyai.com</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgf6c3664" class="outline-3">
<h3 id="orgf6c3664"><span class="section-number-3">13.7.</span> layours</h3>
<div class="outline-text-3" id="text-13-7">
<ul class="org-ul">
<li>tf.Module - is the base class for both tf.keras.layers.Layer and tf.keras.Model</li>
<li>tf.keras.layers.Layer</li>
<li>tf.keras.Model</li>
</ul>
</div>
</div>
<div id="outline-container-org4e3ad9b" class="outline-3">
<h3 id="org4e3ad9b"><span class="section-number-3">13.8.</span> Eager vs Grapth execution</h3>
<div class="outline-text-3" id="text-13-8">
<p>
Eager
</p>
<ul class="org-ul">
<li>evaluate operations immediately</li>
<li>do not build graphs</li>
<li>operations return actual values instead of graphs to run later</li>
</ul>

<p>
Graph @tf.function, tf.Graph
</p>
<ul class="org-ul">
<li>to accelerate your models.</li>
<li>Graph - set of tf.Operation objects, which represent units of computation; and tf.Tensor objects, which
represent the units of data that flow between operations.</li>
<li>can be saved, run, and restored all without the original Python code.</li>
<li>By default, Model.fit() we will attempt to compile your model to a static graph</li>
</ul>
</div>
<div id="outline-container-org617e3c0" class="outline-4">
<h4 id="org617e3c0"><span class="section-number-4">13.8.1.</span> links</h4>
<div class="outline-text-4" id="text-13-8-1">
<ul class="org-ul">
<li><a href="https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6">https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6</a></li>
</ul>
<p>
Tensorflow:
</p>
<ul class="org-ul">
<li>eager <a href="https://www.tensorflow.org/guide/autodiff">https://www.tensorflow.org/guide/autodiff</a></li>
<li>graph <a href="https://www.tensorflow.org/guide/intro_to_graphs">https://www.tensorflow.org/guide/intro_to_graphs</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orga9f23fa" class="outline-3">
<h3 id="orga9f23fa"><span class="section-number-3">13.9.</span> TF 2.0</h3>
<div class="outline-text-3" id="text-13-9">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/guide/effective_tf2?hl=ru">https://www.tensorflow.org/guide/effective_tf2?hl=ru</a></li>
<li><a href="https://medium.com/tensorflow/effective-tensorflow-2-0-best-practices-and-whats-changed-a0ca48767aff">https://medium.com/tensorflow/effective-tensorflow-2-0-best-practices-and-whats-changed-a0ca48767aff</a></li>
<li>Chinese <a href="https://tf.wiki/en/basic/tools.html#graph-execution-mode-tf-function">https://tf.wiki/en/basic/tools.html#graph-execution-mode-tf-function</a>
<ul class="org-ul">
<li><a href="https://github.com/snowkylin/tensorflow-handbook/blob/3ee1d0fdb6518a08b2e9fbb7353ace2d3110bd4b/docs/_static/code/zh/savedmodel/custom/train_and_export.py">https://github.com/snowkylin/tensorflow-handbook/blob/3ee1d0fdb6518a08b2e9fbb7353ace2d3110bd4b/docs/_static/code/zh/savedmodel/custom/train_and_export.py</a></li>
</ul></li>
</ul>
<p>
API:
</p>
<ul class="org-ul">
<li>tf.keras - High level API</li>
<li>Eager Execution By Default with "Gradient Tape". For optimization require @tf.function
<a href="https://www.tensorflow.org/guide/eager">https://www.tensorflow.org/guide/eager</a>
<ul class="org-ul">
<li>keras API Model subclassing <a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models">https://www.tensorflow.org/guide/keras/custom_layers_and_models</a></li>
</ul></li>

<li>tf.data is going to replace tf.placeholders</li>
<li>No more tf.Session()</li>
</ul>
</div>

<div id="outline-container-orgdfcbe6b" class="outline-4">
<h4 id="orgdfcbe6b"><span class="section-number-4">13.9.1.</span> tf.GradientTape API</h4>
<div class="outline-text-4" id="text-13-9-1">
<p>
for automatic differentiation using "reverse mode differentiation"
</p>
<ul class="org-ul">
<li>resources held by a GradientTape are released as soon as GradientTape.gradient() method is called</li>
<li>Trainable variables (created by tf.Variable or tf.compat.v1.get<sub>variable</sub>, where trainable=True is default in both cases) are automatically watched.</li>
<li>at least one of inputs is being "watched".</li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">with</span> tf.GradientTape() <span style="color: #8ac6f2; font-weight: bold;">as</span> g:
  g.watch(x)
  <span style="color: #cae682;">y</span> = x * x
<span style="color: #cae682;">dy_dx</span> = g.gradient(y, x)

</pre>
</div>
</div>
</div>
<div id="outline-container-orgbb38e5f" class="outline-4">
<h4 id="orgbb38e5f"><span class="section-number-4">13.9.2.</span> tf.function</h4>
<div class="outline-text-4" id="text-13-9-2">
<ul class="org-ul">
<li><a href="https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md">https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md</a></li>
</ul>
<p>
TensorFlow graphs require static dtypes and shape dimensions. tf.function keeps a cache of concrete functions
generated by tracing.
</p>

<p>
trace<sub>cache</sub><sub>key</sub> as function of datatype and shape of every Tensor argument and tf.device() scope. For a Python
primitive is its value. Key is used to determine if a new graph needs to be created or if a previously created graph can be invoked.
</p>

<p>
Nones:
</p>
<ul class="org-ul">
<li>Can only use Tensors arguments.</li>
<li>runs all stateful operations (e.g. tf.print)</li>
</ul>

<p>
Argumets must be either:
</p>
<ul class="org-ul">
<li>Tensor (ndarrays are converted to the equivalent Tensor)</li>
<li>list of Tensor</li>
<li>arbitrary Python value</li>
</ul>

<p>
The main takeaways and recommendations are:
</p>
<ul class="org-ul">
<li>Don't rely on Python side effects like object mutation or list appends.</li>
<li>tf.function works best with TensorFlow ops, rather than NumPy ops or Python primitives.</li>
<li>When in doubt, use the for x in y idiom.</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org7e40973"></a>wrap function<br />
<div class="outline-text-5" id="text-13-9-2-1">
<p>
<a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/wrap_function">https://www.tensorflow.org/api_docs/python/tf/compat/v1/wrap_function</a>
</p>

<p>
tf.compat.v1.wrap<sub>function</sub>
</p>

<ul class="org-ul">
<li>do not runs all stateful operations (e.g. tf.cond)</li>
<li>only trace the Python function once</li>
</ul>


<pre class="example">
from tensorflow_core.python.eager.wrap_function import WrappedFunction, VariableHolder, wrap_function
wf:WrappedFunction = wrap_function(f)
</pre>


<pre class="example">
class WrappedFunction(function.ConcreteFunction):
"""Callable object encapsulating a function definition and its gradient.
</pre>
</div>
</li>



<li><a id="org827cd11"></a>AutoGraph включен в tf.function<br />
<div class="outline-text-5" id="text-13-9-2-2">
<p>
для преобразования if и for в tf.cond и tf.while.
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org4dea415" class="outline-4">
<h4 id="org4dea415"><span class="section-number-4">13.9.3.</span> migrate 1 to 2</h4>
<div class="outline-text-4" id="text-13-9-3">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/guide/migrate?hl=ru">https://www.tensorflow.org/guide/migrate?hl=ru</a></li>
<li>2017 stratch <a href="https://ai.googleblog.com/2017/10/eager-execution-imperative-define-by.html">https://ai.googleblog.com/2017/10/eager-execution-imperative-define-by.html</a></li>
<li><a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/migrate.ipynb">https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/migrate.ipynb</a></li>
</ul>

<p>
import tensorflow.compat.v1 as tf
tf.disable<sub>v2</sub><sub>behavior</sub>()
</p>
<ul class="org-ul">
<li>Eager execution, v1.enable<sub>eager</sub><sub>execution</sub>() - tf.Graph will fail - wrap this code in a with
tf.Graph().as<sub>default</sub>() context.</li>
<li>Resource variables, v1.enable<sub>resource</sub><sub>variables</sub>() - 2.0 Resource variables are locked while being written to</li>
<li>Tensor shapes, v1.enable<sub>v2</sub><sub>tensorshape</sub>() - t.shape[0].value will fail</li>
<li>Control flow, v1.enable<sub>control</sub><sub>flow</sub><sub>v2</sub>()</li>
</ul>
</div>
</div>

<div id="outline-container-orgbbebfa2" class="outline-4">
<h4 id="orgbbebfa2"><span class="section-number-4">13.9.4.</span> custome layer</h4>
<div class="outline-text-4" id="text-13-9-4">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/tutorials/customization/custom_layers">https://www.tensorflow.org/tutorials/customization/custom_layers</a></li>
<li><a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models">https://www.tensorflow.org/guide/keras/custom_layers_and_models</a></li>
<li>Convolution <a href="https://github.com/basveeling/keras-gcnn/blob/master/keras_gcnn/layers/convolutional.py">https://github.com/basveeling/keras-gcnn/blob/master/keras_gcnn/layers/convolutional.py</a></li>
</ul>
<p>
Custom layers
</p>

<p>
Methods:
</p>
<ul class="org-ul">
<li>_<sub>init</sub>_<sub>()</sub></li>
<li>build()`: Called once from `_<sub>call</sub>__`, when we know the shapes of inputs and `dtype`.</li>
<li>call()</li>
</ul>

<p>
Arguments _<sub>init</sub>_<sub>()</sub>:
</p>
<dl class="org-dl">
<dt>trainable</dt><dd>Boolean, whether the layer's variables should be trainable.</dd>
<dt>name</dt><dd>String name of the layer.</dd>
<dt>dtype</dt><dd>The dtype of the layer's computations and weights (default of `None` means use
`tf.keras.backend.floatx` in TensorFlow 2, or the type of the first input in TensorFlow 1).</dd>
<dt>dynamic</dt><dd>Set this to `True` if your layer should only be run eagerly, and should not be used to generate a
static computation graph.  This would be the case for a Tree-RNN or a recursive network, for example, or
generally for any layer that manipulates tensors using Python control flow. If `False`, we assume that the
layer can safely be used to generate a static computation graph.</dd>
</dl>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">class</span> <span style="color: #92a65e; font-weight: bold;">Linear</span>(layers.Layer):

  <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__init__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, units=32):
    <span style="color: #e5786d;">super</span>(Linear, <span style="color: #8ac6f2; font-weight: bold;">self</span>).__init__()
    <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">units</span> = units

  <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">build</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, input_shape):
    <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">w</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.add_weight(shape=(input_shape[-1], <span style="color: #8ac6f2; font-weight: bold;">self</span>.units),
                             initializer=<span style="color: #95e454;">'random_normal'</span>,
                             trainable=<span style="color: #e5786d; font-weight: bold;">True</span>) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1074;&#1089;&#1077; self &#1087;&#1077;&#1088;&#1077;&#1084;&#1077;&#1085;&#1085;&#1099;&#1077; &#1087;&#1086;&#1087;&#1072;&#1076;&#1072;&#1102;&#1090; &#1074; model.variables  &#1072;&#1074;&#1090;&#1086;&#1084;&#1072;&#1090;&#1080;&#1095;&#1077;&#1089;&#1082;&#1080;</span>
    <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">b</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.add_weight(shape=(<span style="color: #8ac6f2; font-weight: bold;">self</span>.units,),
                             initializer=<span style="color: #95e454;">'random_normal'</span>,
                             trainable=<span style="color: #e5786d; font-weight: bold;">True</span>)

  <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">call</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, inputs):
    <span style="color: #8ac6f2; font-weight: bold;">return</span> tf.matmul(inputs, <span style="color: #8ac6f2; font-weight: bold;">self</span>.w) + <span style="color: #8ac6f2; font-weight: bold;">self</span>.b

</pre>
</div>
</div>
</div>


<div id="outline-container-org89b26ed" class="outline-4">
<h4 id="org89b26ed"><span class="section-number-4">13.9.5.</span> decayed learning rate</h4>
<div class="outline-text-4" id="text-13-9-5">
<pre class="example">
optimizer = SGD(learning_rate=0.006, decay=0.003, momentum=0.3)
</pre>


<pre class="example">
lr = optimizer._decayed_lr(tf.float32)
print("lr: %f" % lr)
</pre>
</div>
</div>

<div id="outline-container-org9c3cf35" class="outline-4">
<h4 id="org9c3cf35"><span class="section-number-4">13.9.6.</span> layer-wise learning rate in Tensorflow?</h4>
<div class="outline-text-4" id="text-13-9-6">
<p>
<a href="https://stackoverflow.com/questions/34945554/how-to-set-layer-wise-learning-rate-in-tensorflow?noredirect=1">https://stackoverflow.com/questions/34945554/how-to-set-layer-wise-learning-rate-in-tensorflow?noredirect=1</a>
</p>
</div>
</div>
</div>

<div id="outline-container-orgfbc8a5f" class="outline-3">
<h3 id="orgfbc8a5f"><span class="section-number-3">13.10.</span> Save a model</h3>
<div class="outline-text-3" id="text-13-10">
<ul class="org-ul">
<li>v1 <a href="https://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/">https://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/</a></li>
</ul>

<p>
API
</p>
<ul class="org-ul">
<li>tf.compat.v1.train.Saver - binary format. Not-object-based
<ul class="org-ul">
<li>my<sub>test</sub><sub>model</sub>-1000.index</li>
<li>my<sub>test</sub><sub>model</sub>-1000.meta</li>
<li>my<sub>test</sub><sub>model</sub>-1000.data-00000-of-00001</li>
<li>checkpoint -  keeps a record of latest checkpoint files saved</li>
</ul></li>
<li>tf.keras.Model</li>
<li>tf.compat.v2.train.Checkpoint - binary object-based checkpoints</li>
</ul>
</div>

<div id="outline-container-orgc8d379b" class="outline-4">
<h4 id="orgc8d379b"><span class="section-number-4">13.10.1.</span> v1 Saver loading:</h4>
<div class="outline-text-4" id="text-13-10-1">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/import_meta_graph">https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/import_meta_graph</a></li>
<li>example <a href="https://github.com/ZZUTK/TensorFlow_VGG_train_test/blob/master/testing.py">https://github.com/ZZUTK/TensorFlow_VGG_train_test/blob/master/testing.py</a></li>
</ul>
<p>
steps
</p>
<ol class="org-ol">
<li>with tf.compat.v1.Session() as sess: or tf.compat.v1.Session()</li>
<li>saver = tf.compat.v1.train.import<sub>meta</sub><sub>graph</sub>('my<sub>test</sub><sub>model</sub>-1000.meta') # this will create the graph/network for you
but we still need to load the value of the parameters that we had trained on this graph</li>
<li>saver.restore(sess,tf.train.latest<sub>checkpoint</sub>('./')) # restore the parameters of the network</li>
<li>print(sess.run('w1:0')) - print saved value of w1.</li>
</ol>

<p>
Run:
</p>
<pre class="example">
graph = tf.compat.v1.get_default_graph()
w1 = graph.get_tensor_by_name("w1:0")
w2 = graph.get_tensor_by_name("w2:0")
feed_dict ={w1:13.0,w2:17.0}
op_to_restore = graph.get_tensor_by_name("op_to_restore:0")
 print sess.run(op_to_restore,feed_dict)
</pre>
</div>
</div>

<div id="outline-container-orgb9e20e7" class="outline-4">
<h4 id="orgb9e20e7"><span class="section-number-4">13.10.2.</span> v2 saving loading</h4>
<div class="outline-text-4" id="text-13-10-2">
<ul class="org-ul">
<li>Checkpoints - exact value of all parameters (tf.Variable) - source code required
<ul class="org-ul">
<li>tf.keras.Model.save<sub>weights</sub>(path/mymodel)</li>
</ul></li>
<li>Model.save(path) - the parameter values &amp;&amp; serialized description of the computation defined by the model. Source code not needed.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org03ecb97" class="outline-3">
<h3 id="org03ecb97"><span class="section-number-3">13.11.</span> datasets</h3>
<div class="outline-text-3" id="text-13-11">
<ol class="org-ol">
<li>tf.keras.datasets: <a href="https://www.tensorflow.org/api_docs/python/tf/keras/datasets">https://www.tensorflow.org/api_docs/python/tf/keras/datasets</a>
<ul class="org-ul">
<li>boston<sub>housing</sub> module</li>
<li>cifar10 module</li>
<li>cifar100 module</li>
<li>fashion<sub>mnist</sub> module</li>
<li>imdb module</li>
<li>mnist module</li>
<li>reuters module</li>
</ul></li>
<li>tensorflow<sub>datasets</sub>
<ul class="org-ul">
<li>catalog <a href="https://www.tensorflow.org/datasets/catalog/overview">https://www.tensorflow.org/datasets/catalog/overview</a></li>
<li>API <a href="https://www.tensorflow.org/datasets/overview">https://www.tensorflow.org/datasets/overview</a></li>
</ul></li>
</ol>

<p>
tfds.load is a thin wrapper around tfds.core.DatasetBuilder
</p>
</div>
<div id="outline-container-org58cebae" class="outline-4">
<h4 id="org58cebae"><span class="section-number-4">13.11.1.</span> install and use tfds</h4>
<div class="outline-text-4" id="text-13-11-1">
<pre class="example">
pip install tensorflow-datasets
</pre>


<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow_datasets <span style="color: #8ac6f2; font-weight: bold;">as</span> tfds
tfds.display_progress_bar(<span style="color: #e5786d; font-weight: bold;">True</span>)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">1) easy way</span>
<span style="color: #cae682;">ds</span> = tfds.load(<span style="color: #95e454;">'mnist'</span>, split=<span style="color: #95e454;">'train'</span>, shuffle_files=<span style="color: #e5786d; font-weight: bold;">True</span>)
<span style="color: #8ac6f2; font-weight: bold;">assert</span> <span style="color: #e5786d;">isinstance</span>(ds, tf.data.Dataset)

</pre>
</div>
</div>
</div>

<div id="outline-container-org6254fae" class="outline-4">
<h4 id="org6254fae"><span class="section-number-4">13.11.2.</span> download</h4>
<div class="outline-text-4" id="text-13-11-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">create directory required</span>
<span style="color: #8ac6f2; font-weight: bold;">from</span> pathlib <span style="color: #8ac6f2; font-weight: bold;">import</span> Path
Path(<span style="color: #95e454;">"/mnt/ssd/datasets/tensorflow_datasets/downloads/manual"</span>).mkdir(parents=<span style="color: #e5786d; font-weight: bold;">True</span>, exist_ok=<span style="color: #e5786d; font-weight: bold;">True</span>)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">test</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">tfds.load('mnist', data_dir="/mnt/ssd/datasets/tensorflow_datasets")</span>

<span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow_datasets <span style="color: #8ac6f2; font-weight: bold;">as</span> tfds
tfds.display_progress_bar(<span style="color: #e5786d; font-weight: bold;">True</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">do not download 'robotics:mt_opt_rlds' and  'huggingface:wmt19'</span>
<span style="color: #cae682;">l</span> = [x <span style="color: #8ac6f2; font-weight: bold;">for</span> x <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">sorted</span>(tfds.list_builders()) <span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #95e454;">":"</span> <span style="color: #8ac6f2; font-weight: bold;">not</span> <span style="color: #8ac6f2; font-weight: bold;">in</span> x ]
<span style="color: #cae682;">errors</span>=[]
<span style="color: #8ac6f2; font-weight: bold;">for</span> x <span style="color: #8ac6f2; font-weight: bold;">in</span> l:
    <span style="color: #8ac6f2; font-weight: bold;">try</span>:
        <span style="color: #cae682;">ds</span> = tfds.load(x, data_dir=<span style="color: #95e454;">"/mnt/ssd/datasets/tensorflow_datasets"</span>)
    <span style="color: #8ac6f2; font-weight: bold;">except</span> <span style="color: #92a65e; font-weight: bold;">Exception</span> <span style="color: #8ac6f2; font-weight: bold;">as</span> e:
        errors.append(x)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"datasets with errors:"</span>, errors)
</pre>
</div>
</div>
</div>
<div id="outline-container-org9693fe4" class="outline-4">
<h4 id="org9693fe4"><span class="section-number-4">13.11.3.</span> landmark 2020</h4>
<div class="outline-text-4" id="text-13-11-3">
<p>
Number of unique landmark<sub>id</sub>: 81313
</p>
<ul class="org-ul">
<li><a href="https://www.kaggle.com/code/alifrahman/landmark-recognition2020-google">https://www.kaggle.com/code/alifrahman/landmark-recognition2020-google</a></li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> os
<span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">------- data</span>
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">get_paths</span>(path=<span style="color: #95e454;">"/landmark-retrieval-2020/train"</span>, max_count=-1):
    <span style="color: #cae682;">index</span> = [<span style="color: #95e454;">"0"</span>,<span style="color: #95e454;">"1"</span>,<span style="color: #95e454;">"2"</span>,<span style="color: #95e454;">"3"</span>,<span style="color: #95e454;">"4"</span>,<span style="color: #95e454;">"5"</span>,<span style="color: #95e454;">"6"</span>,<span style="color: #95e454;">"7"</span>,<span style="color: #95e454;">"8"</span>,<span style="color: #95e454;">"9"</span>,<span style="color: #95e454;">"a"</span>,<span style="color: #95e454;">"b"</span>,<span style="color: #95e454;">"c"</span>,<span style="color: #95e454;">"d"</span>,<span style="color: #95e454;">"e"</span>,<span style="color: #95e454;">"f"</span>]
    <span style="color: #cae682;">paths</span> = []
    <span style="color: #8ac6f2; font-weight: bold;">for</span> a <span style="color: #8ac6f2; font-weight: bold;">in</span> index:
        <span style="color: #8ac6f2; font-weight: bold;">for</span> b <span style="color: #8ac6f2; font-weight: bold;">in</span> index:
            <span style="color: #8ac6f2; font-weight: bold;">for</span> c <span style="color: #8ac6f2; font-weight: bold;">in</span> index:
                paths.extend([path+f<span style="color: #95e454;">"/</span>{a}<span style="color: #95e454;">/</span>{b}<span style="color: #95e454;">/</span>{c}<span style="color: #95e454;">/"</span> + x <span style="color: #8ac6f2; font-weight: bold;">for</span> x <span style="color: #8ac6f2; font-weight: bold;">in</span> os.listdir(path+f<span style="color: #95e454;">"/</span>{a}<span style="color: #95e454;">/</span>{b}<span style="color: #95e454;">/</span>{c}<span style="color: #95e454;">"</span>)])
        <span style="color: #8ac6f2; font-weight: bold;">if</span> max_count &gt; 0 <span style="color: #8ac6f2; font-weight: bold;">and</span> <span style="color: #e5786d;">len</span>(paths) &gt; max_count:
            <span style="color: #8ac6f2; font-weight: bold;">break</span>
    <span style="color: #8ac6f2; font-weight: bold;">return</span> paths

<span style="color: #cae682;">paths</span> = get_paths(<span style="color: #95e454;">"/landmark-retrieval-2020/train"</span>, 100)
<span style="color: #cae682;">df</span> = pd.read_csv(<span style="color: #95e454;">"/landmark-retrieval-2020/train.csv"</span>) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">count 1580470 # id  landmark_id</span>
<span style="color: #cae682;">mapping</span> = {}
<span style="color: #8ac6f2; font-weight: bold;">for</span> path <span style="color: #8ac6f2; font-weight: bold;">in</span> paths:
    mapping[path.split(<span style="color: #95e454;">'/'</span>)[-1].split(<span style="color: #95e454;">'.'</span>)[0]] = path

<span style="color: #cae682;">df</span>[<span style="color: #95e454;">'path'</span>] = df[<span style="color: #95e454;">'id'</span>].<span style="color: #e5786d;">map</span>(mapping) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">add path column</span>
<span style="color: #cae682;">df</span> = df[~ df.path.isna()] <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">select records with "path" column</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- add probability for ...</span>
<span style="color: #cae682;">alpha</span>=0.6
<span style="color: #cae682;">counts_map</span> = <span style="color: #e5786d;">dict</span>(df.groupby(<span style="color: #95e454;">'landmark_id'</span>)[<span style="color: #95e454;">'path'</span>].agg(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x: <span style="color: #e5786d;">len</span>(x)))
<span style="color: #cae682;">df</span>[<span style="color: #95e454;">'counts'</span>] = df[<span style="color: #95e454;">'landmark_id'</span>].<span style="color: #e5786d;">map</span>(counts_map)
<span style="color: #cae682;">df</span>[<span style="color: #95e454;">'prob'</span>] = (  (1/df.counts**alpha) / (1/df.counts**alpha).<span style="color: #e5786d;">max</span>()).astype(np.float32) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">?</span>

<span style="color: #cae682;">uniques</span> = df[<span style="color: #95e454;">'landmark_id'</span>].unique() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">unique classes</span>
<span style="color: #cae682;">df</span>[<span style="color: #95e454;">'label'</span>] = df[<span style="color: #95e454;">'landmark_id'</span>].<span style="color: #e5786d;">map</span>(<span style="color: #e5786d;">dict</span>(<span style="color: #e5786d;">zip</span>(uniques, <span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(uniques))))) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">scale landmark_id to 0-</span>

<span style="color: #cae682;">image_paths</span>, <span style="color: #cae682;">labels</span>, <span style="color: #cae682;">probs</span> = df.path.to_numpy(), df.label.to_numpy(), df.prob.to_numpy()


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">split_data</span>(images, labels, train_size=0.9, shuffle=<span style="color: #e5786d; font-weight: bold;">True</span>):
    <span style="color: #f08080; font-style: italic;">""" not stratified, train will have not all classes """</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">1. Get the total size of the dataset</span>
    <span style="color: #cae682;">size</span> = <span style="color: #e5786d;">len</span>(images)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">2. Make an indices array and shuffle it, if required</span>
    <span style="color: #cae682;">indices</span> = np.arange(size)
    <span style="color: #8ac6f2; font-weight: bold;">if</span> shuffle:
        np.random.shuffle(indices)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">3. Get the size of training samples</span>
    <span style="color: #cae682;">train_samples</span> = <span style="color: #e5786d;">int</span>(size * train_size)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">4. Split data into training and validation sets</span>
    <span style="color: #cae682;">x_train</span>, <span style="color: #cae682;">y_train</span> = images[indices[:train_samples]], labels[indices[:train_samples]]
    <span style="color: #cae682;">x_valid</span>, <span style="color: #cae682;">y_valid</span> = images[indices[train_samples:]], labels[indices[train_samples:]]
    <span style="color: #8ac6f2; font-weight: bold;">return</span> x_train, x_valid, y_train, y_valid

<span style="color: #cae682;">x_train</span>, <span style="color: #cae682;">x_valid</span>, <span style="color: #cae682;">y_train</span>, <span style="color: #cae682;">y_valid</span> = split_data(image_paths, labels)


<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">--------- dataset class</span>
<span style="color: #cae682;">img_width</span> = 736
<span style="color: #cae682;">img_height</span> = 736

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">encode_single_sample</span>(img_path, label):
    <span style="color: #e5786d;">print</span>(img_path, label)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">1. Read image</span>
    <span style="color: #cae682;">img</span> = tf.io.read_file(img_path)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">2. Decode and convert to grayscale</span>
    <span style="color: #cae682;">img</span> = tf.io.decode_jpeg(img, channels=3)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">3. Convert to float32 in [0, 1] range</span>
    <span style="color: #cae682;">img</span> = tf.image.convert_image_dtype(img, tf.float32)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">4. Resize to the desired size</span>
    <span style="color: #cae682;">img</span> = tf.image.resize(img, [img_height, img_width])
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">5. Transpose the image because we want the time</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dimension to correspond to the width of the image.</span>
    <span style="color: #cae682;">img</span> = tf.transpose(img, perm=[1, 0, 2])
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">7. Return a dict as our model is expecting two inputs</span>
    <span style="color: #8ac6f2; font-weight: bold;">return</span> {<span style="color: #95e454;">"image"</span>: img, <span style="color: #95e454;">"label"</span>: label}


<span style="color: #cae682;">train_dataset</span> = tf.data.Dataset.from_tensor_slices((x_train.astype(<span style="color: #e5786d;">str</span>), y_train.astype(<span style="color: #e5786d;">int</span>)))
<span style="color: #cae682;">train_dataset</span> = train_dataset.<span style="color: #e5786d;">map</span>(encode_single_sample)
<span style="color: #cae682;">valid_dataset</span> = tf.data.Dataset.from_tensor_slices((x_valid.astype(<span style="color: #e5786d;">str</span>), y_valid.astype(<span style="color: #e5786d;">int</span>)))
<span style="color: #cae682;">valid_dataset</span> = valid_dataset.<span style="color: #e5786d;">map</span>(encode_single_sample)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dataset = dataset.map(</span>
<span style="color: #fa8072;">#         </span><span style="color: #99968b; font-style: italic;">lambda x, y, p: (read_image(x), y, p),</span>
<span style="color: #fa8072;">#         </span><span style="color: #99968b; font-style: italic;">tf.data.experimental.AUTOTUNE)</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;"># anotehr approach:</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">train_list = glob.glob('../input/landmark-retrieval-2020/train/*/*/*/*')</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">test_list = glob.glob('../input/landmark-retrieval-2020/test/*/*/*/*')</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">index_list = glob.glob('../input/landmark-retrieval-2020/index/*/*/*/*')</span>

<span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #e5786d;">__name__</span>==<span style="color: #95e454;">"__main__"</span>:
    <span style="color: #cae682;">args</span> = sys.argv[1:]
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">'args'</span>, args)
    main(args)
</pre>
</div>
</div>
</div>
<div id="outline-container-orgfa2e55e" class="outline-4">
<h4 id="orgfa2e55e"><span class="section-number-4">13.11.4.</span> mnist</h4>
<div class="outline-text-4" id="text-13-11-4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">encode_single_sample</span>(img_path, label):
    tf.io.read_file(image_path)
    tf.image.decode_jpeg(image, channels=3)

<span style="color: #cae682;">mnist</span> = tf.keras.datasets.mnist

(x_train, y_train), (<span style="color: #cae682;">x_test</span>, <span style="color: #cae682;">y_test</span>) = mnist.load_data()
<span style="color: #cae682;">x_train</span>, <span style="color: #cae682;">x_test</span> = x_train / 255.0, x_test / 255.0
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- dataset</span>
<span style="color: #cae682;">batch_size</span>=16
<span style="color: #cae682;">train_dataset</span> = tf.data.Dataset.from_tensor_slices((x_train, y_train))
<span style="color: #e5786d;">map</span>(
        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE
    )
<span style="color: #cae682;">train_dataset</span> = train_dataset.shuffle(60000).repeat().batch(batch_size)
<span style="color: #cae682;">validation_dataset</span> = tf.data.Dataset.from_tensor_slices((x_test, y_test))
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- train</span>
model.fit(train_dataset, epochs=5, steps_per_epoch=200)
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org58eb80b" class="outline-3">
<h3 id="org58eb80b"><span class="section-number-3">13.12.</span> tf.data.dataset</h3>
<div class="outline-text-3" id="text-13-12">
<ul class="org-ul">
<li><a href="https://keras.io/examples/vision/captcha_ocr/">https://keras.io/examples/vision/captcha_ocr/</a></li>
</ul>

<p>
train<sub>dataset</sub> = tf.data.Dataset.from<sub>tensor</sub><sub>slices</sub>((x<sub>train</sub>, y<sub>train</sub>))
</p>



<p>
dataset must consist of typeles - (x, y) by default, but it may be dictionary
</p>
</div>

<div id="outline-container-orgff04a5b" class="outline-4">
<h4 id="orgff04a5b"><span class="section-number-4">13.12.1.</span> test</h4>
<div class="outline-text-4" id="text-13-12-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">for</span> elem <span style="color: #8ac6f2; font-weight: bold;">in</span> train_dataset_y.take(10):
    <span style="color: #e5786d;">print</span>(elem.numpy().shape)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">or</span>
    <span style="color: #e5786d;">print</span>(elem[<span style="color: #95e454;">'label'</span>].numpy().shape)

<span style="color: #e5786d;">print</span>(train_dataset.__iter__().<span style="color: #e5786d;">next</span>())
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org27b9182" class="outline-3">
<h3 id="org27b9182"><span class="section-number-3">13.13.</span> install</h3>
<div class="outline-text-3" id="text-13-13">
<p>
   see Tested build configurations
tensorflow.org/install/source#linux
</p>
<ol class="org-ol">
<li>apt clean; apt updatel apt purge cuda ; apt purge nvidia-*; apt autoremoveq</li>
<li>install "cuda toolkit" from archive</li>
<li>pip3 install tensorflow-gpu==2.3.0</li>
</ol>
</div>
</div>
<div id="outline-container-orga7a23e3" class="outline-3">
<h3 id="orga7a23e3"><span class="section-number-3">13.14.</span> install from source</h3>
<div class="outline-text-3" id="text-13-14">
<p>
Для компиляции tensorflow используется гугловая система сборки Bazel
</p>
</div>
</div>
<div id="outline-container-org598bdc2" class="outline-3">
<h3 id="org598bdc2"><span class="section-number-3">13.15.</span> APIs</h3>
<div class="outline-text-3" id="text-13-15">
<ol class="org-ol">
<li>tf.nn - very low level</li>
<li>tf.layers - higher</li>
<li>tf.keras - highest</li>
<li>просто сразу вычисляет tf.enable<sub>eager</sub><sub>execution</sub>()</li>
</ol>
</div>
</div>

<div id="outline-container-org416fbe9" class="outline-3">
<h3 id="org416fbe9"><span class="section-number-3">13.16.</span> tf.placeholder</h3>
<div class="outline-text-3" id="text-13-16">
<p>
amy = placeholder - это тензоры в графе, которым присваивается имя amy
</p>

<pre class="example">
sess.run([tensors], feed_dict={amy: 1})  # заполняет placeholders and выполняет тензоры
</pre>
</div>
</div>

<div id="outline-container-org7eef3bf" class="outline-3">
<h3 id="org7eef3bf"><span class="section-number-3">13.17.</span> Logger = Disable</h3>
<div class="outline-text-3" id="text-13-17">
<pre class="example">
import os
import tensorflow as tf
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
</pre>
</div>
</div>
<div id="outline-container-orgd9d9661" class="outline-3">
<h3 id="orgd9d9661"><span class="section-number-3">13.18.</span> 4D tensor <a id="org82a95e8"></a></h3>
<div class="outline-text-3" id="text-13-18">
<ul class="org-ul">
<li>N refers to the number of images in a batch.</li>
<li>H refers to the number of pixels in the vertical (height) dimension.</li>
<li>W refers to the number of pixels in the horizontal (width) dimension.</li>
<li>C refers to the channels. For example, 1 for black and white or grayscale and 3 for RGB.</li>
</ul>
<p>
Formats:
</p>
<ul class="org-ul">
<li>NCHW or channels<sub>first</sub> - optimal for NVIDIA GPUs cuDNN - If not using the Intel MKL, some operations are not
supported on CPU when using NCHW</li>
<li>NHWC or channels<sub>last</sub> - TensorFlow default - little faster on CPU - we are working on tools to auto
rewrite graphs to make switching between the formats transparent and take advantages of micro optimizations
where a GPU op may be faster using NHWC</li>
</ul>

<p>
channels<sub>last</sub> - default for keras
</p>
</div>
</div>
<div id="outline-container-org7bb9a94" class="outline-3">
<h3 id="org7bb9a94"><span class="section-number-3">13.19.</span> install</h3>
<div class="outline-text-3" id="text-13-19">
<ul class="org-ul">
<li>pip install tensorflow &#x2013;user</li>
<li>import tensorflow as tf</li>
<li>tf.InteractiveSession()</li>
</ul>
</div>
</div>
<div id="outline-container-org2652efe" class="outline-3">
<h3 id="org2652efe"><span class="section-number-3">13.20.</span> Deploy</h3>
<div class="outline-text-3" id="text-13-20">
<ul class="org-ul">
<li>Java</li>
<li>C</li>
<li>Go</li>
</ul>
</div>
</div>
<div id="outline-container-org6363e4e" class="outline-3">
<h3 id="org6363e4e"><span class="section-number-3">13.21.</span> tensor</h3>
<div class="outline-text-3" id="text-13-21">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/guide/tensors">https://www.tensorflow.org/guide/tensors</a></li>
<li>Tensor a mathematical object analogous to but more general than a vector, represented by an array of
components that are functions of the coordinates of a space</li>
<li>unit of data, geometric objects that describe linear relations between geometric vectors, scalars, and other</li>
</ul>
<p>
tensors
</p>
<ul class="org-ul">
<li>has Rank</li>
<li>set of primitive values shaped into an array of any number of dimensions</li>
<li>rank/dimension zero tensor - 5 - scalar - shape is []</li>
<li>rank/dimension 1 tensor - [ 1., 2., 3., 4. ] - Vector - shape is [4]</li>
<li>rank/dimension 2 tensor or a Matrix - shape [ 2, 4] - [ [ 1., 2., 3., 4. ], [ 5., 6., 7., 8. ] ]</li>
</ul>

<p>
Граф состоит из узлов op, связанных друг с другом, представляющих операции.
</p>
<ul class="org-ul">
<li>Операция выделяет память для своих выходов, которые доступны в конечных точках :0, :1 и т.д. - похожих на
тензор</li>
</ul>
</div>
</div>
<div id="outline-container-org28b7416" class="outline-3">
<h3 id="org28b7416"><span class="section-number-3">13.22.</span> hardware</h3>
<div class="outline-text-3" id="text-13-22">
<p>
GPU могу ускорить работу сети в 10-20 раз[1]
</p>

<p>
<b>CPU</b>
</p>
<ul class="org-ul">
<li>С достаточно мощной видеокартой мощность процессора практически не важна, потому что всю нагрузку возмет GPU</li>
<li>желательно Intel® Xeon®, Intel® Xeon Phi™</li>
<li>если 2 видеокарты, то процессор должен их поддерживать.</li>
</ul>


<p>
<b>GPU</b>
</p>
<ul class="org-ul">
<li>две GPU лучше чем одна на 20%. Переносимость модели на систему без GPU реализована.</li>
<li>CUDA-Enabled NVIDIA video vard <a href="https://developer.nvidia.com/cuda-gpus">https://developer.nvidia.com/cuda-gpus</a></li>
<li>Deep Learning Primitives (cuDNN) - part of Deep Learning SDK, requires CUDA Toolkit</li>
<li>GPU Memory &gt;=11 GB - больше лучше</li>
<li>чем больше FLOPS тем лучше</li>
<li>топы: NVIDIA QUADRO® GV100 или NVIDIA TITAN RTX</li>
<li>GPU Cooling - очень важен - Air cooling - для одного или двух если между ними поместится ещё две</li>
</ul>

<p>
<b>RAM</b>
</p>
<ul class="org-ul">
<li>RAM clock rates not required</li>
<li>RAM size больше чем GPU Memory одной из карт - больше памяти, удобнее работа для человека.</li>
</ul>

<p>
<b>PSU</b> if you have 4 GPUs with each 250 watts TDP and a CPU with 150 watts TDP, then you will need a PSU with a
 minimum of 4×250 + 150 + 100 = 1250 watts
</p>


<p>
Quandro P1000 PCE-3.0
кабинет 42 Соловьев
</p>

<p>
Счет на Кирила скинуть, Артем сказал скинуть счет на оплату, с Минофьевым согласовали, отправить в москву.
</p>

<p>
Андрей Свиридов поговорил с ЦФТ о возможности получить тестовый доступ к их облачному сервису расладвающему
назначения на компоненты.
</p>

<p>
Почтовый ящик с заявками, текст и сканы.
</p>

<ol class="org-ol">
<li>TensorFlow для глубокого обучения. Барат Рамсундар, Реза Босаг Заде. 2019г.</li>
<li><a href="https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/">https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/</a></li>
</ol>


<ol class="org-ol">
<li>проверить материнскую плату что она PCI-E 3.0</li>
</ol>


<ol class="org-ol">
<li>Написать письмо</li>
<li>Можно ли с keras использовать несколько GPU</li>
<li>прочитать по автокредиту что прислал в почте, посмотреть бизнес процессы</li>
<li>читать банковское дело.</li>
<li>Военкомат!! 11:00</li>
</ol>

<p>
<a href="https://www.ferra.ru/review/computers/nvidia-geforce-gtx-1070-asus-gigabyte-msi-palit-zotac.htm">https://www.ferra.ru/review/computers/nvidia-geforce-gtx-1070-asus-gigabyte-msi-palit-zotac.htm</a>
</p>

<p>
Выбор видеокарты PALIT GeForce GTX 1070 27030р - 29000р
</p>
<ul class="org-ul">
<li><a href="https://belgorod.nix.ru/autocatalog/palit_graphics_accelerators/8Gb-PCI-E-GDDR5-Palit-GTX1070-JetStream-RTL-DVI-plus-HDMI-plus-3xDP-plus-SLI-GeForce-GTX1070_274136.html">https://belgorod.nix.ru/autocatalog/palit_graphics_accelerators/8Gb-PCI-E-GDDR5-Palit-GTX1070-JetStream-RTL-DVI-plus-HDMI-plus-3xDP-plus-SLI-GeForce-GTX1070_274136.html</a></li>
<li><a href="https://www.onlinetrade.ru/catalogue/videokarty-c338/palit/videokarta_palit_geforce_gtx_1070_1506mhz_pci_e_3.0_8192mb_8000mhz_256_bit_dvi_hdmi_hdcp_jetstream_ne51070015p2_1041j-556700.html?utm_source=market.yandex.ru&amp;utm_medium=cpc&amp;city=55&amp;_openstat=bWFya2V0LnlhbmRleC5ydTvQktC40LTQtdC-0LrQsNGA0YLQsCBQQUxJVCBHZUZvcmNlIEdUWCAxMDcwIDE1MDZNaHogUENJLUUgMy4wIDgxOTJNYiA4MDAwTWh6IDI1NiBiaXQgRFZJIEhETUkgSERDUCBKZXRTdHJlYW0gKE5FNTEwNzAwMTVQMi0xMDQxSik7dVFPbk1jckprVlZZWmNEamR5UVBiUTs&amp;ymclid=15602370129371193275200002">https://www.onlinetrade.ru/catalogue/videokarty-c338/palit/videokarta_palit_geforce_gtx_1070_1506mhz_pci_e_3.0_8192mb_8000mhz_256_bit_dvi_hdmi_hdcp_jetstream_ne51070015p2_1041j-556700.html?utm_source=market.yandex.ru&amp;utm_medium=cpc&amp;city=55&amp;_openstat=bWFya2V0LnlhbmRleC5ydTvQktC40LTQtdC-0LrQsNGA0YLQsCBQQUxJVCBHZUZvcmNlIEdUWCAxMDcwIDE1MDZNaHogUENJLUUgMy4wIDgxOTJNYiA4MDAwTWh6IDI1NiBiaXQgRFZJIEhETUkgSERDUCBKZXRTdHJlYW0gKE5FNTEwNzAwMTVQMi0xMDQxSik7dVFPbk1jckprVlZZWmNEamR5UVBiUTs&amp;ymclid=15602370129371193275200002</a></li>
</ul>

<p>
GeForce RTX 2060
</p>

<p>
Железо 50 70
</p>
</div>
</div>

<div id="outline-container-orgdf7c940" class="outline-3">
<h3 id="orgdf7c940"><span class="section-number-3">13.23.</span> hello world</h3>
<div class="outline-text-3" id="text-13-23">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #cae682;">a</span> = tf.add(3, 5)

<span style="color: #cae682;">sess</span> = tf.Session()
<span style="color: #e5786d;">print</span> sess.run(a)
sess.close()
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">or</span>
<span style="color: #8ac6f2; font-weight: bold;">with</span> tf.Session() <span style="color: #8ac6f2; font-weight: bold;">as</span> sess:
  <span style="color: #e5786d;">print</span> sess.run(a)
</pre>
</div>
</div>
</div>
<div id="outline-container-org3371430" class="outline-3">
<h3 id="org3371430"><span class="section-number-3">13.24.</span> main objects</h3>
<div class="outline-text-3" id="text-13-24">
<ul class="org-ul">
<li>tf.Session - содержит один глобальный граф
<ul class="org-ul">
<li>tf.InteractiveSession - makes itself the default</li>
</ul></li>
<li>tf.Tensor
<ul class="org-ul">
<li>tf.constant(value, dtype=None, shape=None, name='Const', verify<sub>shape</sub>=False)
<ul class="org-ul">
<li>stored in the graph definition</li>
<li>loading graphs expensive</li>
</ul></li>
</ul></li>
<li>tf.placeholder - input for graph</li>
</ul>
<p>
when constants are big
</p>
<ul class="org-ul">
<li>tf.Operation</li>
<li>tf.Graph - состоит из экземпляров tf.Tensor и tf.Operation.
<ul class="org-ul">
<li>Multiple graphs require multiple sessions, each will try to use all available resources by default</li>
<li>Can't pass data between them without passing them through python/numpy, which doesn't work in distributed</li>
<li>It’s better to have disconnected subgraphs within one graph</li>
</ul></li>
<li>data types
<ul class="org-ul">
<li>tf.int32</li>
<li>tf.float32</li>
<li>tf.float64</li>
<li>tf.string</li>
<li>tf.bool</li>
<li></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgea07880" class="outline-3">
<h3 id="orgea07880"><span class="section-number-3">13.25.</span> Переменные</h3>
<div class="outline-text-3" id="text-13-25">
<ul class="org-ul">
<li>tf.Varible - контейнер Tensor</li>
<li>tf.assign</li>
</ul>
<p>
Инициализация
</p>
<pre class="example">
init = tf.global_variables_initializer()
with tf.Session() as sess:
  sess.run(init)
</pre>


<p>
nitialize a single variable
</p>
<pre class="example">
W = tf.Variable(tf.zeros([784,10]))
with tf.Session() as sess:
  sess.run(W.initializer)
  print W.eval()
</pre>
</div>
</div>
<div id="outline-container-orge0eead1" class="outline-3">
<h3 id="orge0eead1"><span class="section-number-3">13.26.</span> TensorBoard</h3>
<div class="outline-text-3" id="text-13-26">
<p>
2 run it:
</p>
<ul class="org-ul">
<li>$ python [yourprogram].py</li>
<li>$ tensorboard &#x2013;logdir="./graphs" &#x2013;port 6006</li>
<li><a href="http://localhost:6006/">http://localhost:6006/</a></li>
</ul>

<p>
1 save it:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #cae682;">a</span> = tf.constant(2, name=<span style="color: #95e454;">"a"</span>)
<span style="color: #cae682;">b</span> = tf.constant(3, name=<span style="color: #95e454;">"b"</span>)
<span style="color: #cae682;">x</span> = tf.add(a, b, name=<span style="color: #95e454;">"add"</span>)
<span style="color: #8ac6f2; font-weight: bold;">with</span> tf.Session() <span style="color: #8ac6f2; font-weight: bold;">as</span> sess:
  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">add this line to use TensorBoard.</span>
  <span style="color: #cae682;">writer</span> = tf.summary.FileWriter(<span style="color: #95e454;">'./graphs, sess.graph)</span>
<span style="color: #95e454;">  print sess.run(x)</span>
<span style="color: #95e454;">writer.close() # close the writer when you&#8217;re done using</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orge524dd5" class="outline-3">
<h3 id="orge524dd5"><span class="section-number-3">13.27.</span> GPU</h3>
<div class="outline-text-3" id="text-13-27">
<p>
<a href="https://www.tensorflow.org/install/gpu">https://www.tensorflow.org/install/gpu</a>
</p>
<ul class="org-ul">
<li>pip3 install tensorflow-gpu &#x2013;user</li>
</ul>

<p>
Required:
</p>
<ul class="org-ul">
<li>import tensorflow as tf</li>
<li>config = tf.ConfigProto()</li>
<li>config.gpu<sub>options.allow</sub><sub>growth</sub> = True</li>
<li>session = tf.Session(config=config)</li>
</ul>
</div>
</div>
<div id="outline-container-orgfa05aa6" class="outline-3">
<h3 id="orgfa05aa6"><span class="section-number-3">13.28.</span> keras</h3>
<div class="outline-text-3" id="text-13-28">
<pre class="example">
from tensorflow import keras
from tensorflow.python.keras.api._v2.keras.layers import BatchNormalization, Dense, Dropout, Activation, Flatten, \
    Conv2D, MaxPooling2D
from tensorflow.python.keras.api._v2.keras.models import Sequential
</pre>
</div>
</div>



<div id="outline-container-org2842634" class="outline-3">
<h3 id="org2842634"><span class="section-number-3">13.29.</span> CNN</h3>
<div class="outline-text-3" id="text-13-29">
<p>
tf.nn.conv2d(feat,
</p>
<ul class="org-ul">
<li>weight, - input</li>
<li>strides=[1,1,1,1], -  1,2 or 4 - stride of the sliding window for each dimension of input</li>
<li>padding="VALID")+bias</li>
</ul>

<p>
tf.nn.max<sub>pool</sub>(feat,
</p>
<ul class="org-ul">
<li>ksize=[1,2,2,1] - window per every dimension</li>
<li>strides=[1,2,2,1]</li>
<li>padding="VALID")</li>
</ul>
</div>
</div>

<div id="outline-container-org9d27e05" class="outline-3">
<h3 id="org9d27e05"><span class="section-number-3">13.30.</span> RNN and LSTM</h3>
<div class="outline-text-3" id="text-13-30">
<ul class="org-ul">
<li>TODO <a href="https://www.tensorflow.org/guide/keras/rnn">https://www.tensorflow.org/guide/keras/rnn</a></li>
<li><a href="https://github.com/curiousily/Deep-Learning-For-Hackers">https://github.com/curiousily/Deep-Learning-For-Hackers</a></li>
<li><a href="https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/recurrent_network.ipynb">https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/recurrent_network.ipynb</a></li>
</ul>

<p>
stateful=True requre constant batch<sub>size</sub>
</p>

<p>
Change bach <a href="https://stackoverflow.com/questions/58799212/how-can-i-use-a-stateful-lstm-model-to-predict-without-specifying-the-same-batch">https://stackoverflow.com/questions/58799212/how-can-i-use-a-stateful-lstm-model-to-predict-without-specifying-the-same-batch</a>
</p>
</div>
<div id="outline-container-org764f9aa" class="outline-4">
<h4 id="org764f9aa"><span class="section-number-4">13.30.1.</span> CNN</h4>
<div class="outline-text-4" id="text-13-30-1">
<p>
<a href="https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/">https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/</a>
</p>
</div>
</div>
<div id="outline-container-org2624f19" class="outline-4">
<h4 id="org2624f19"><span class="section-number-4">13.30.2.</span> batch</h4>
<div class="outline-text-4" id="text-13-30-2">
<p>
<a href="https://machinelearningmastery.com/stateful-stateless-lstm-time-series-forecasting-python/">https://machinelearningmastery.com/stateful-stateless-lstm-time-series-forecasting-python/</a>
</p>

<p>
You can set RNN layers to be 'stateful', which means that the states computed for the samples in one batch
will be reused as initial states for the samples in the next batch. This assumes a one-to-one mapping between
samples in different successive batches.
</p>

<p>
You can specify the initial state of RNN layers symbolically by calling them with the keyword argument
<b>initial<sub>state</sub></b>. The value of <b>initial<sub>state</sub></b> should be a tensor or list of tensors representing the initial state
of the RNN layer.
</p>

<p>
You can specify the initial state of RNN layers numerically by calling <b>reset<sub>states</sub></b> with the keyword argument
<b>states</b>. The value of <b>states</b> should be a numpy array or list of numpy arrays representing the initial state of
the RNN layer.
</p>


<p>
it may be possible to simulate a stateful LSTM with a stateless LSTM using a large batch size.
</p>
</div>
</div>
</div>

<div id="outline-container-org766ef6e" class="outline-3">
<h3 id="org766ef6e"><span class="section-number-3">13.31.</span> plot learning curve</h3>
<div class="outline-text-3" id="text-13-31">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #e5786d;">print</span>(history.history.keys()) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">['loss', 'acc', 'val_loss', 'val_acc']</span>

<span style="color: #8ac6f2; font-weight: bold;">from</span> matplotlib <span style="color: #8ac6f2; font-weight: bold;">import</span> pyplot <span style="color: #8ac6f2; font-weight: bold;">as</span> plt

plt.figure(1)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">summarize history for accuracy</span>

plt.subplot(211)
plt.plot(history.history[<span style="color: #95e454;">'acc'</span>])
plt.plot(history.history[<span style="color: #95e454;">'val_acc'</span>])
plt.title(<span style="color: #95e454;">'model accuracy'</span>)
plt.ylabel(<span style="color: #95e454;">'accuracy'</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">plt.xlabel('epoch')</span>
plt.legend([<span style="color: #95e454;">'train'</span>, <span style="color: #95e454;">'test'</span>], loc=<span style="color: #95e454;">'upper left'</span>)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">summarize history for loss</span>

plt.subplot(212)
plt.plot(history.history[<span style="color: #95e454;">'loss'</span>])
plt.plot(history.history[<span style="color: #95e454;">'val_loss'</span>])
plt.title(<span style="color: #95e454;">'model loss'</span>)
plt.ylabel(<span style="color: #95e454;">'loss'</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">plt.xlabel('epoch')</span>
plt.legend([<span style="color: #95e454;">'train'</span>, <span style="color: #95e454;">'test'</span>], loc=<span style="color: #95e454;">'upper left'</span>)
plt.show()
</pre>
</div>
</div>
</div>
<div id="outline-container-orgf22c122" class="outline-3">
<h3 id="orgf22c122"><span class="section-number-3">13.32.</span> plot CNN layout</h3>
<div class="outline-text-3" id="text-13-32">
<ul class="org-ul">
<li><a href="https://stackoverflow.com/questions/55421290/tensorflow-2-0-keras-how-to-write-image-summaries-for-tensorboard">https://stackoverflow.com/questions/55421290/tensorflow-2-0-keras-how-to-write-image-summaries-for-tensorboard</a></li>
</ul>
<p>
summaryWriter = tf.summary.FileWriter("model<sub>name</sub>")
summaryWriter.add<sub>graph</sub>(sess.graph)
</p>

<p>
summaryWriter.add<sub>summary</sub>(sess.run(summaryMeanTest0,feed<sub>dict</sub>={testImagePH:testMean[0]}),i+1)
</p>
</div>
</div>
<div id="outline-container-orgb34ab04" class="outline-3">
<h3 id="orgb34ab04"><span class="section-number-3">13.33.</span> Optimizer</h3>
<div class="outline-text-3" id="text-13-33">
<p>
softmaxLoss = tf.losses.softmax<sub>cross</sub><sub>entropy</sub>(onehot<sub>labels</sub>=labelOnehot, logits=output) -&gt; float or [batch]
</p>
<ul class="org-ul">
<li>labelOnehot - оригиналы</li>
<li>logits - то что вернула сеть</li>
<li>reduction: str = Reduction.SUM<sub>BY</sub><sub>NONZERO</sub><sub>WEIGHTS</sub> - default</li>

<li>optimizer = tf.train.GradientDescentOptimizer(learning<sub>rate</sub>).minimize(cost)
<ul class="org-ul">
<li>cost - ?</li>
</ul></li>
<li>sess.run(tf.global<sub>variables</sub><sub>initializer</sub>())</li>
<li>sess.run([optim,loss],feed<sub>dict</sub>=batch)</li>
</ul>

<p>
ways:
</p>
<ul class="org-ul">
<li>minimize()
<ol class="org-ol">
<li>opt = GradientDescentOptimizer(learning<sub>rate</sub>=0.1)</li>
<li>opt<sub>op</sub> = opt.minimize(cost, var<sub>list</sub>=&lt;list of variables&gt;) - computing the gradients and applying them to
the variables</li>
<li>sess.run([opt<sub>op,loss</sub>], feed<sub>dict</sub>=batch) or opt<sub>op.run</sub>()</li>
</ol></li>
<li>compute<sub>gradients</sub>() - process the gradients before applying them
<ol class="org-ol">
<li>opt = GradientDescentOptimizer(learning<sub>rate</sub>=0.1)</li>
<li>grads<sub>and</sub><sub>vars</sub> = opt.compute<sub>gradients</sub>(loss, &lt;list of variables&gt;)</li>
<li>capped<sub>grads</sub><sub>and</sub><sub>vars</sub> = [(MyCapper(gv[0]), gv[1]) for gv in grads<sub>and</sub><sub>vars</sub>]</li>
<li>opt.apply<sub>gradients</sub>(capped<sub>grads</sub><sub>and</sub><sub>vars</sub>)</li>
<li>sess.run([opt,loss], feed<sub>dict</sub>=batch)</li>
</ol></li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">lrGP_PH</span>, <span style="color: #cae682;">lrC_PH</span> = tf.placeholder(tf.float32, shape=[]), tf.placeholder(tf.float32, shape=[])
<span style="color: #cae682;">optim</span> = tf.train.AdamOptimizer(learning_rate=lrC_PH).minimize(loss, global_step=tf.train.get_global_step())


<span style="color: #cae682;">lrC</span> = opt.lrC*opt.lrCdecay**(i//opt.lrCstep)
<span style="color: #cae682;">batch</span>[lrC_PH] = lrC
sess.run
</pre>
</div>
</div>
</div>
<div id="outline-container-orge18ba36" class="outline-3">
<h3 id="orge18ba36"><span class="section-number-3">13.34.</span> models - tensorflow<sub>models</sub> as tfm</h3>
<div class="outline-text-3" id="text-13-34">
<ul class="org-ul">
<li><a href="https://github.com/tensorflow/models/">https://github.com/tensorflow/models/</a></li>
<li>usage guide <a href="https://github.com/tensorflow/models/blob/master/tensorflow_models/tensorflow_models_pypi.ipynb">https://github.com/tensorflow/models/blob/master/tensorflow_models/tensorflow_models_pypi.ipynb</a></li>
<li>usage examp <a href="https://colab.research.google.com/github/tensorflow/models/blob/master/docs/vision/image_classification.ipynb">https://colab.research.google.com/github/tensorflow/models/blob/master/docs/vision/image_classification.ipynb</a></li>
<li>mnist legacy <a href="https://github.com/tensorflow/models/blob/e11f52948a993c8de15c4d87241044bc769e767b/official/legacy/image_classification/mnist_main.py">https://github.com/tensorflow/models/blob/e11f52948a993c8de15c4d87241044bc769e767b/official/legacy/image_classification/mnist_main.py</a></li>
</ul>
</div>
<div id="outline-container-orgc4c0bed" class="outline-4">
<h4 id="orgc4c0bed"><span class="section-number-4">13.34.1.</span> install</h4>
<div class="outline-text-4" id="text-13-34-1">
<pre class="example">
pip3 install tf-models-official==2.13
</pre>

<p>
/usr/local/lib/python3.8/dist-packages
</p>
<pre class="example">
pip3 install tf-models-official==2.13 ; apt install -y emacs-nox
</pre>
</div>
</div>
<div id="outline-container-org9f3b30e" class="outline-4">
<h4 id="org9f3b30e"><span class="section-number-4">13.34.2.</span> usage</h4>
<div class="outline-text-4" id="text-13-34-2">
<p>
git clone &#x2013;depth=1 <a href="https://github.com/tensorflow/models">https://github.com/tensorflow/models</a>
</p>

<ul class="org-ul">
<li>Experiment factory (config in JSON/YAML) <a href="https://colab.research.google.com/github/tensorflow/models/blob/master/docs/vision/image_classification.ipynb#scrollTo=5iN8mHEJjKYE">https://colab.research.google.com/github/tensorflow/models/blob/master/docs/vision/image_classification.ipynb#scrollTo=5iN8mHEJjKYE</a></li>
<li>class constructor (tf.keras.Model) <a href="https://github.com/tensorflow/models/blob/master/tensorflow_models/tensorflow_models_pypi.ipynb">https://github.com/tensorflow/models/blob/master/tensorflow_models/tensorflow_models_pypi.ipynb</a>
<ul class="org-ul">
<li>orbit <a href="https://github.com/tensorflow/models/blob/master/docs/orbit/index.ipynb">https://github.com/tensorflow/models/blob/master/docs/orbit/index.ipynb</a></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org5441171" class="outline-4">
<h4 id="org5441171"><span class="section-number-4">13.34.3.</span> mnist</h4>
<div class="outline-text-4" id="text-13-34-3">
<p>
cd models/official/legacy/image<sub>classification</sub>
python mnist<sub>main.py</sub>
python mnist<sub>main.py</sub> -ds parameter<sub>server</sub> &#x2013;data<sub>dir</sub> /workspace/mnist
</p>

<p>
-ds,&#x2013;distribution<sub>strategy</sub>:
    The Distribution Strategy to use for training. Accepted values are 'off',
    'one<sub>device</sub>', 'mirrored', 'parameter<sub>server</sub>', 'collective', case
    insensitive.
    'off' means not to use Distribution Strategy; 'default' means to choose from
    `MirroredStrategy` or `OneDeviceStrategy` according to the number of GPUs.
    (default: 'mirrored')
</p>

<p>
-ng,&#x2013;num<sub>gpus</sub>:
    How many GPUs to use at each worker with the DistributionStrategies API. The
    default is 1.
    (default: '1')
    (an integer)
</p>

<p>
-te,&#x2013;train<sub>epochs</sub>:
    The number of epochs used to train.
    (default: '1')
    (an integer)
</p>


<p>
official.utils.flags.<sub>base</sub>:
  -bs,&#x2013;batch<sub>size</sub>:
    Batch size for training and evaluation. When using multiple gpus, this is
    the
    global batch size for all devices. For example, if the batch size is 32 and
    there are 4 GPUs, each GPU will get 8 examples on each step.
    (default: '1024')
    (an integer)
</p>

<p>
-te,&#x2013;train<sub>epochs</sub>:
    The number of epochs used to train.
    (default: '1')
    (an integer)
</p>
</div>
</div>

<div id="outline-container-org802348c" class="outline-4">
<h4 id="org802348c"><span class="section-number-4">13.34.4.</span> dummy dataset for MNIST</h4>
<div class="outline-text-4" id="text-13-34-4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">dummy_data</span> = (
        tf.ones(shape=(10, 28, 28, 1), dtype=tf.int32),
        tf.<span style="color: #e5786d;">range</span>(10),
    )
    <span style="color: #cae682;">datasets</span> = (
        tf.data.Dataset.from_tensor_slices(dummy_data),
        tf.data.Dataset.from_tensor_slices(dummy_data),
    )
</pre>
</div>
</div>
</div>
<div id="outline-container-org1289558" class="outline-4">
<h4 id="org1289558"><span class="section-number-4">13.34.5.</span> Mobilenet example</h4>
<div class="outline-text-4" id="text-13-34-5">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">https://www.tensorflow.org/api_docs/python/tfm/vision/backbones/MobileNet</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">https://stackoverflow.com/questions/63284471/tensorflow-use-model-inside-another-model-as-layer</span>
<span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow_models <span style="color: #8ac6f2; font-weight: bold;">as</span> tfm
<span style="color: #8ac6f2; font-weight: bold;">from</span> tensorflow.keras <span style="color: #8ac6f2; font-weight: bold;">import</span> Input
<span style="color: #8ac6f2; font-weight: bold;">from</span> tensorflow.keras <span style="color: #8ac6f2; font-weight: bold;">import</span> Model


<span style="color: #cae682;">IS</span> = 28
<span style="color: #cae682;">INPUT_SIZE</span> = (IS, IS)
<span style="color: #cae682;">OUTPUT_SIZE</span> = 2

<span style="color: #cae682;">input_specs</span> = tf.keras.layers.InputSpec(shape=[<span style="color: #e5786d; font-weight: bold;">None</span>, IS, IS, 3])

<span style="color: #cae682;">sub_model</span> = tfm.vision.backbones.MobileNet(
    input_specs=input_specs,
    filter_size_scale=0.65,
)

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">model_test</span>(input_shape, sub_model):
  <span style="color: #cae682;">inputs</span> = Input(input_shape)
  <span style="color: #cae682;">intermedio</span> = sub_model(inputs)
  <span style="color: #cae682;">iv</span> = <span style="color: #e5786d;">list</span>(intermedio.values())
  <span style="color: #cae682;">f0</span> = tf.keras.layers.Flatten()(iv[0])
  <span style="color: #cae682;">f1</span> = tf.keras.layers.Flatten()(iv[1])
  <span style="color: #cae682;">f2</span> = tf.keras.layers.Flatten()(iv[2])
  <span style="color: #cae682;">dense_intr</span> = tf.keras.layers.Concatenate()([f0, f1, f2])
  <span style="color: #cae682;">outputs</span> = tf.keras.layers.Dense(OUTPUT_SIZE, activation=tf.keras.activations.softmax, name=<span style="color: #95e454;">"d-out"</span>)(dense_intr)
  <span style="color: #cae682;">model</span> = Model(inputs=inputs, outputs=outputs)
  <span style="color: #8ac6f2; font-weight: bold;">return</span> model

<span style="color: #cae682;">model</span> = model_test((IS, IS, 3), sub_model)

<span style="color: #cae682;">model</span> = model_test(INPUT_SIZE, sub_model)


<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- inference with dummy test</span>
<span style="color: #cae682;">inputs</span> = tf.keras.Input(shape=(IS, IS, 3), batch_size=1)
<span style="color: #cae682;">endpoints</span> = model(inputs=inputs)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- compile</span>
model.<span style="color: #e5786d;">compile</span>(loss=<span style="color: #95e454;">"categorical_crossentropy"</span>, optimizer=<span style="color: #95e454;">"adam"</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- train</span>

<span style="color: #e5786d;">print</span>(model.name)
<span style="color: #e5786d;">print</span>(endpoints)
</pre>
</div>
</div>
</div>
<div id="outline-container-org9e77d49" class="outline-4">
<h4 id="org9e77d49"><span class="section-number-4">13.34.6.</span> RESNET example</h4>
<div class="outline-text-4" id="text-13-34-6">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">https://www.tensorflow.org/api_docs/python/tfm/vision/backbones/MobileNet</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">https://stackoverflow.com/questions/63284471/tensorflow-use-model-inside-another-model-as-layer</span>
<span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow_models <span style="color: #8ac6f2; font-weight: bold;">as</span> tfm
<span style="color: #8ac6f2; font-weight: bold;">from</span> tensorflow.keras <span style="color: #8ac6f2; font-weight: bold;">import</span> Input
<span style="color: #8ac6f2; font-weight: bold;">from</span> tensorflow.keras <span style="color: #8ac6f2; font-weight: bold;">import</span> Model
<span style="color: #8ac6f2; font-weight: bold;">import</span> os
<span style="color: #8ac6f2; font-weight: bold;">import</span> pandas <span style="color: #8ac6f2; font-weight: bold;">as</span> pd
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">IS</span> = 736
<span style="color: #cae682;">INPUT_SIZE</span> = (IS, IS, 3)
<span style="color: #cae682;">OUTPUT_SIZE</span> = <span style="color: #e5786d; font-weight: bold;">None</span> <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">lets get count of classes from Data</span>
<span style="color: #cae682;">BATCH_SIZE</span> = 5
<span style="color: #cae682;">DROUPOUT_RATE</span>=0.2
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- Data ----</span>
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">get_paths</span>(path=<span style="color: #95e454;">"/landmark-retrieval-2020/train"</span>, max_count=-1):
    <span style="color: #cae682;">index</span> = [<span style="color: #95e454;">"0"</span>,<span style="color: #95e454;">"1"</span>,<span style="color: #95e454;">"2"</span>,<span style="color: #95e454;">"3"</span>,<span style="color: #95e454;">"4"</span>,<span style="color: #95e454;">"5"</span>,<span style="color: #95e454;">"6"</span>,<span style="color: #95e454;">"7"</span>,<span style="color: #95e454;">"8"</span>,<span style="color: #95e454;">"9"</span>,<span style="color: #95e454;">"a"</span>,<span style="color: #95e454;">"b"</span>,<span style="color: #95e454;">"c"</span>,<span style="color: #95e454;">"d"</span>,<span style="color: #95e454;">"e"</span>,<span style="color: #95e454;">"f"</span>]
    <span style="color: #cae682;">paths</span> = []
    <span style="color: #8ac6f2; font-weight: bold;">for</span> a <span style="color: #8ac6f2; font-weight: bold;">in</span> index:
        <span style="color: #8ac6f2; font-weight: bold;">for</span> b <span style="color: #8ac6f2; font-weight: bold;">in</span> index:
            <span style="color: #8ac6f2; font-weight: bold;">for</span> c <span style="color: #8ac6f2; font-weight: bold;">in</span> index:
                paths.extend([path+f<span style="color: #95e454;">"/</span>{a}<span style="color: #95e454;">/</span>{b}<span style="color: #95e454;">/</span>{c}<span style="color: #95e454;">/"</span> + x <span style="color: #8ac6f2; font-weight: bold;">for</span> x <span style="color: #8ac6f2; font-weight: bold;">in</span> os.listdir(path+f<span style="color: #95e454;">"/</span>{a}<span style="color: #95e454;">/</span>{b}<span style="color: #95e454;">/</span>{c}<span style="color: #95e454;">"</span>)])
        <span style="color: #8ac6f2; font-weight: bold;">if</span> max_count &gt; 0 <span style="color: #8ac6f2; font-weight: bold;">and</span> <span style="color: #e5786d;">len</span>(paths) &gt; max_count:
            <span style="color: #8ac6f2; font-weight: bold;">break</span>
    <span style="color: #8ac6f2; font-weight: bold;">return</span> paths

<span style="color: #cae682;">paths</span> = get_paths(<span style="color: #95e454;">"/landmark-retrieval-2020/train"</span>, 150000)
<span style="color: #cae682;">df</span> = pd.read_csv(<span style="color: #95e454;">"/landmark-retrieval-2020/train.csv"</span>) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">count 1580470 # id  landmark_id</span>
<span style="color: #cae682;">mapping</span> = {}
<span style="color: #8ac6f2; font-weight: bold;">for</span> path <span style="color: #8ac6f2; font-weight: bold;">in</span> paths:
    mapping[path.split(<span style="color: #95e454;">'/'</span>)[-1].split(<span style="color: #95e454;">'.'</span>)[0]] = path

<span style="color: #cae682;">df</span>[<span style="color: #95e454;">'path'</span>] = df[<span style="color: #95e454;">'id'</span>].<span style="color: #e5786d;">map</span>(mapping) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">add path column</span>
<span style="color: #cae682;">df</span> = df[~ df.path.isna()] <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">select records with "path" column</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- add probability for ...</span>
<span style="color: #cae682;">alpha</span>=0.6
<span style="color: #cae682;">counts_map</span> = <span style="color: #e5786d;">dict</span>(df.groupby(<span style="color: #95e454;">'landmark_id'</span>)[<span style="color: #95e454;">'path'</span>].agg(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x: <span style="color: #e5786d;">len</span>(x)))
<span style="color: #cae682;">df</span>[<span style="color: #95e454;">'counts'</span>] = df[<span style="color: #95e454;">'landmark_id'</span>].<span style="color: #e5786d;">map</span>(counts_map)
<span style="color: #cae682;">df</span>[<span style="color: #95e454;">'prob'</span>] = (  (1/df.counts**alpha) / (1/df.counts**alpha).<span style="color: #e5786d;">max</span>()).astype(np.float32) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">?</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">select classes where we have enough examples</span>
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"df[df.counts &gt;70].shape"</span>, df[df.counts &gt;70].shape) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&gt;&gt;&gt; (4934, 5)</span>
<span style="color: #cae682;">df</span> = df[df.counts &gt;70]
<span style="color: #cae682;">uniques</span> = df[<span style="color: #95e454;">'landmark_id'</span>].unique() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">unique classes</span>
<span style="color: #cae682;">OUTPUT_SIZE</span> = <span style="color: #e5786d;">len</span>(uniques)
<span style="color: #cae682;">df</span>[<span style="color: #95e454;">'label'</span>] = df[<span style="color: #95e454;">'landmark_id'</span>].<span style="color: #e5786d;">map</span>(<span style="color: #e5786d;">dict</span>(<span style="color: #e5786d;">zip</span>(uniques, <span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(uniques))))) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">scale landmark_id to 0-</span>

<span style="color: #cae682;">image_paths</span>, <span style="color: #cae682;">labels</span>, <span style="color: #cae682;">probs</span> = df.path.to_numpy(), df.label.to_numpy(), df.prob.to_numpy()


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">split_data</span>(images, labels, train_size=0.9, shuffle=<span style="color: #e5786d; font-weight: bold;">True</span>):
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">1. Get the total size of the dataset</span>
    <span style="color: #cae682;">size</span> = <span style="color: #e5786d;">len</span>(images)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">2. Make an indices array and shuffle it, if required</span>
    <span style="color: #cae682;">indices</span> = np.arange(size)
    <span style="color: #8ac6f2; font-weight: bold;">if</span> shuffle:
        np.random.shuffle(indices)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">3. Get the size of training samples</span>
    <span style="color: #cae682;">train_samples</span> = <span style="color: #e5786d;">int</span>(size * train_size)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">4. Split data into training and validation sets</span>
    <span style="color: #cae682;">x_train</span>, <span style="color: #cae682;">y_train</span> = images[indices[:train_samples]], labels[indices[:train_samples]]
    <span style="color: #cae682;">x_valid</span>, <span style="color: #cae682;">y_valid</span> = images[indices[train_samples:]], labels[indices[train_samples:]]
    <span style="color: #8ac6f2; font-weight: bold;">return</span> x_train, x_valid, y_train, y_valid

<span style="color: #cae682;">x_train</span>, <span style="color: #cae682;">x_valid</span>, <span style="color: #cae682;">y_train</span>, <span style="color: #cae682;">y_valid</span> = split_data(image_paths, labels)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">----- Model ----</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- sub_model - depend on model</span>
<span style="color: #cae682;">input_specs</span> = tf.keras.layers.InputSpec(shape=[<span style="color: #e5786d; font-weight: bold;">None</span>, IS, IS, 3])

<span style="color: #cae682;">sub_model</span> = tfm.vision.backbones.resnet.ResNet(
    model_id = 50,
    input_specs = input_specs,
)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- Get outputs tensor of submodel</span>
<span style="color: #cae682;">inputs</span> = tf.keras.Input(shape=INPUT_SIZE, batch_size=1)
<span style="color: #cae682;">endpoints</span> = sub_model(inputs=inputs)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"endpoints"</span>, endpoints)
<span style="color: #e5786d;">print</span>()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- wrap sub_model in new Model to add input and output layers</span>
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">wrap_model</span>(input_shape, sub_model):
    <span style="color: #f08080; font-style: italic;">""" add inputs and outputs to model """</span>
    <span style="color: #cae682;">inputs</span> = Input(input_shape)
    <span style="color: #cae682;">intermedio</span> = sub_model(inputs)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">"""Merge outputs - depende on model"""</span>
    <span style="color: #cae682;">pooling</span> = tf.keras.layers.GlobalAveragePooling2D(name=<span style="color: #95e454;">'head/pooling'</span>)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dropout = tf.keras.layers.Dropout(DROUPOUT_RATE, name='head/dropout')</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dense = tf.keras.layers.Dense(dense_units, name='head/dense')</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">x = intermedio</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">x = pooling(x)</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">x = dropout(x)</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">x = dense(x)</span>
    <span style="color: #cae682;">iv</span> = <span style="color: #e5786d;">list</span>(intermedio.values())
    <span style="color: #cae682;">f0</span> = tf.keras.layers.Flatten()(pooling(iv[0]))
    <span style="color: #cae682;">f1</span> = tf.keras.layers.Flatten()(pooling(iv[1]))
    <span style="color: #cae682;">f2</span> = tf.keras.layers.Flatten()(pooling(iv[2]))
    <span style="color: #cae682;">f3</span> = tf.keras.layers.Flatten()(pooling(iv[3]))
    <span style="color: #cae682;">x</span> = tf.keras.layers.Concatenate()([f0, f1, f2, f3])
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">final layout:</span>
    <span style="color: #cae682;">outputs</span> = tf.keras.layers.Dense(OUTPUT_SIZE, activation=tf.keras.activations.softmax, name=<span style="color: #95e454;">"d-out"</span>)(x)
    <span style="color: #cae682;">model</span> = Model(inputs=inputs, outputs=outputs)
    <span style="color: #8ac6f2; font-weight: bold;">return</span> model

<span style="color: #cae682;">model</span> = wrap_model(INPUT_SIZE, sub_model)
model.summary()
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"model.layers[0]._name"</span>, model.layers[0]._name)
model.layers[0].<span style="color: #cae682;">_name</span> = <span style="color: #95e454;">"image"</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- compile</span>
model.<span style="color: #e5786d;">compile</span>(loss=<span style="color: #95e454;">"categorical_crossentropy"</span>, optimizer=<span style="color: #95e454;">"adam"</span>)


<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- Dataset class ----</span>
<span style="color: #cae682;">img_width</span> = 736
<span style="color: #cae682;">img_height</span> = 736

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">encode_single_sample</span>(img_path, label):
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">1. Read image</span>
    <span style="color: #cae682;">img</span> = tf.io.read_file(img_path)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">2. Decode and convert to grayscale</span>
    <span style="color: #cae682;">img</span> = tf.io.decode_jpeg(img, channels=3)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">3. Convert to float32 in [0, 1] range</span>
    <span style="color: #cae682;">img</span> = tf.image.convert_image_dtype(img, tf.float32)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">4. Resize to the desired size</span>
    <span style="color: #cae682;">img</span> = tf.image.resize(img, [img_height, img_width])
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">5. Transpose the image because we want the time</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dimension to correspond to the width of the image.</span>
    <span style="color: #cae682;">img</span> = tf.transpose(img, perm=[1, 0, 2])
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">7. Return a dict as our model is expecting two inputs</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">layer = tf.keras.layers.CategoryEncoding(num_tokens=OUTPUT_SIZE, output_mode="one_hot")</span>
    <span style="color: #cae682;">label</span> = tf.one_hot(label, OUTPUT_SIZE)
    <span style="color: #8ac6f2; font-weight: bold;">return</span> img, label


<span style="color: #cae682;">train_dataset</span> = tf.data.Dataset.from_tensor_slices((x_train.astype(<span style="color: #e5786d;">str</span>), y_train.astype(<span style="color: #e5786d;">int</span>))).skip(df.shape[0] - df.shape[0]//4)
<span style="color: #cae682;">train_dataset</span> = train_dataset.<span style="color: #e5786d;">map</span>(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x, y: encode_single_sample(x, y), tf.data.experimental.AUTOTUNE)

<span style="color: #cae682;">train_dataset</span> = train_dataset.batch(BATCH_SIZE).prefetch(100)

<span style="color: #cae682;">validation_dataset</span> = tf.data.Dataset.from_tensor_slices((x_valid.astype(<span style="color: #e5786d;">str</span>), y_valid.astype(<span style="color: #e5786d;">int</span>))).skip(df.shape[0] - df.shape[0]//4)
<span style="color: #cae682;">validation_dataset</span> = validation_dataset.<span style="color: #e5786d;">map</span>(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x, y: encode_single_sample(x, y), tf.data.experimental.AUTOTUNE)
<span style="color: #cae682;">validation_dataset</span> = train_dataset.prefetch(100)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- train ----</span>
model.fit(train_dataset, epochs=1)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- checks the model's performance</span>
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"evaluate"</span>)
model.evaluate(validation_dataset, verbose=2)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- inferece</span>
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"inference"</span>, x_valid[0], y_valid[0])
<span style="color: #cae682;">im</span>, <span style="color: #cae682;">l</span> = encode_single_sample(x_valid[0], y_valid[0])
<span style="color: #cae682;">im</span> = tf.expand_dims(im, axis=0)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"im"</span>, im.shape)
<span style="color: #cae682;">predictions</span> = model.predict(im, batch_size=1)
<span style="color: #e5786d;">print</span>(np.argmax(predictions))
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"label:"</span>, y_valid[0])

</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-orgb2007f5" class="outline-3">
<h3 id="orgb2007f5"><span class="section-number-3">13.35.</span> TensorFlow Serving</h3>
<div class="outline-text-3" id="text-13-35">
</div>
<div id="outline-container-orgdac3456" class="outline-4">
<h4 id="orgdac3456"><span class="section-number-4">13.35.1.</span> terms</h4>
<div class="outline-text-4" id="text-13-35-1">
<ul class="org-ul">
<li>Servables - anything, and multiple independent servables</li>
<li>Loaders - manage a servable's life cycle</li>
<li>Sources - are plugin modules that find and provide servables</li>
<li>Managers - loading, serving, unloading</li>
</ul>


<ul class="org-ul">
<li>main <a href="https://github.com/tensorflow/serving">https://github.com/tensorflow/serving</a></li>
<li>basic tutorial <a href="https://www.tensorflow.org/tfx/serving/serving_basic">https://www.tensorflow.org/tfx/serving/serving_basic</a></li>
<li>advanced tutorial <a href="https://www.tensorflow.org/tfx/serving/serving_advanced">https://www.tensorflow.org/tfx/serving/serving_advanced</a></li>
</ul>
<p>
kubernetes install <a href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/serving_kubernetes.md">https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/serving_kubernetes.md</a>
</p>

<p>
<a href="https://pypi.org/project/tensorflow-serving-api/">https://pypi.org/project/tensorflow-serving-api/</a>
</p>

<ul class="org-ul">
<li>client: <a href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/resnet_client_grpc.py">https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/resnet_client_grpc.py</a></li>
<li>build with docker? <a href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/building_with_docker.md">https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/building_with_docker.md</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org7f95c0e" class="outline-3">
<h3 id="org7f95c0e"><span class="section-number-3">13.36.</span> <span class="todo TODO">TODO</span> TFX pipeline - MLOps</h3>
<div class="outline-text-3" id="text-13-36">
<p>
is a portable implementation of an ML workflow that can be run on various orchestrators, such as: Apache Airflow, Apache Beam, and Kubeflow Pipelines.
</p>
</div>
</div>
<div id="outline-container-org8a4a72b" class="outline-3">
<h3 id="org8a4a72b"><span class="section-number-3">13.37.</span> loss</h3>
<div class="outline-text-3" id="text-13-37">
<ul class="org-ul">
<li>loss = tf.losses.softmax<sub>cross</sub><sub>entropy</sub>(onehot<sub>labels</sub>=labelOnehot, logits=output,  reduction=tf.losses.Reduction.MEAN)</li>
<li>lossm = tf.metrics.mean(loss)</li>
</ul>
</div>
</div>

<div id="outline-container-orgbeb7a9c" class="outline-3">
<h3 id="orgbeb7a9c"><span class="section-number-3">13.38.</span> ctc<sub>loss</sub></h3>
<div class="outline-text-3" id="text-13-38">
<ul class="org-ul">
<li><a href="https://programtalk.com/python-more-examples/tensorflow.nn.ctc_loss/">https://programtalk.com/python-more-examples/tensorflow.nn.ctc_loss/</a>
<ul class="org-ul">
<li><a href="https://github.com/lz1313/BlockCIrculantRNN/blob/master/model.py">https://github.com/lz1313/BlockCIrculantRNN/blob/master/model.py</a></li>
<li><a href="https://github.com/zfxxfeng/cnn_lstm_ctc_ocr_for_ICPR/blob/master/src/model.py">https://github.com/zfxxfeng/cnn_lstm_ctc_ocr_for_ICPR/blob/master/src/model.py</a></li>
<li><a href="https://github.com/mdangschat/ctc-asr/blob/master/asr/model.py">https://github.com/mdangschat/ctc-asr/blob/master/asr/model.py</a></li>
<li><a href="https://github.com/nginyc/rafiki/blob/master/examples/models/speech_recognition/TfDeepSpeech.py">https://github.com/nginyc/rafiki/blob/master/examples/models/speech_recognition/TfDeepSpeech.py</a></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgb2b8851" class="outline-3">
<h3 id="orgb2b8851"><span class="section-number-3">13.39.</span> custom metric</h3>
<div class="outline-text-3" id="text-13-39">
<p>
levels:
</p>
<ul class="org-ul">
<li>function -&gt; values summarized and divided by count</li>
<li>class -&gt; gives full control</li>
</ul>
</div>
<div id="outline-container-org76afeca" class="outline-4">
<h4 id="org76afeca"><span class="section-number-4">13.39.1.</span> function</h4>
<div class="outline-text-4" id="text-13-39-1">
<p>
<b>total categorical accuracy</b>
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">total_categorical_accuracy</span>(y_true, y_pred):
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">a = tf.cast(tf.math.equal(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1)), dtype=y_pred.dtype)</span>
        <span style="color: #cae682;">a</span> = keras.metrics.categorical_accuracy(y_true, y_pred)
        <span style="color: #cae682;">classes</span> = tf.constant(a.shape[1], a.dtype)
        <span style="color: #cae682;">a2</span> = tf.reduce_sum(a, axis=-1)
        <span style="color: #cae682;">c</span> = tf.cast(tf.math.equal(a2, classes), dtype=classes.dtype)
        <span style="color: #8ac6f2; font-weight: bold;">return</span> c
model.<span style="color: #e5786d;">compile</span>(loss=loss, optimizer=opt.optimizer, metrics=[<span style="color: #95e454;">"categorical_accuracy"</span>,total_categorical_accuracy])
</pre>
</div>
</div>
</div>
<div id="outline-container-orge2833be" class="outline-4">
<h4 id="orge2833be"><span class="section-number-4">13.39.2.</span> class</h4>
<div class="outline-text-4" id="text-13-39-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">class</span> <span style="color: #92a65e; font-weight: bold;">ConfusionMatrixMetric</span>(tf.keras.metrics.Metric):


    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">update_state</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, y_true, y_pred,sample_weight=<span style="color: #e5786d; font-weight: bold;">None</span>):
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.total_cm.assign_add(<span style="color: #8ac6f2; font-weight: bold;">self</span>.confusion_matrix(y_true,y_pred))
        <span style="color: #8ac6f2; font-weight: bold;">return</span> <span style="color: #8ac6f2; font-weight: bold;">self</span>.total_cm

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">result</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>):
        <span style="color: #8ac6f2; font-weight: bold;">return</span> <span style="color: #8ac6f2; font-weight: bold;">self</span>.process_confusion_matrix()

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">confusion_matrix</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>,y_true, y_pred):
        <span style="color: #f08080; font-style: italic;">"""</span>
<span style="color: #f08080; font-style: italic;">        Make a confusion matrix</span>
<span style="color: #f08080; font-style: italic;">        """</span>
        <span style="color: #cae682;">y_pred</span>=tf.argmax(y_pred,1)
        <span style="color: #cae682;">cm</span>=tf.math.confusion_matrix(y_true,y_pred,dtype=tf.float32,num_classes=<span style="color: #8ac6f2; font-weight: bold;">self</span>.num_classes)
        <span style="color: #8ac6f2; font-weight: bold;">return</span> cm

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">process_confusion_matrix</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>):
        <span style="color: #f08080; font-style: italic;">"returns precision, recall and f1 along with overall accuracy"</span>
        <span style="color: #cae682;">cm</span>=<span style="color: #8ac6f2; font-weight: bold;">self</span>.total_cm
        <span style="color: #cae682;">diag_part</span>=tf.linalg.diag_part(cm)
        <span style="color: #cae682;">precision</span>=diag_part/(tf.reduce_sum(cm,0)+tf.constant(1e-15))
        <span style="color: #cae682;">recall</span>=diag_part/(tf.reduce_sum(cm,1)+tf.constant(1e-15))
        <span style="color: #cae682;">f1</span>=2*precision*recall/(precision+recall+tf.constant(1e-15))
        <span style="color: #8ac6f2; font-weight: bold;">return</span> precision,recall,f1

</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgb581e38" class="outline-3">
<h3 id="orgb581e38"><span class="section-number-3">13.40.</span> distributed training</h3>
<div class="outline-text-3" id="text-13-40">
</div>
<div id="outline-container-orga6c540e" class="outline-4">
<h4 id="orga6c540e"><span class="section-number-4">13.40.1.</span> API</h4>
<div class="outline-text-4" id="text-13-40-1">
<ul class="org-ul">
<li><b>tf.distribute.Strategy</b></li>
<li>high-level API Keras <b>Model.fit</b></li>
<li>Custom training loop</li>
<li>Estimator API (Limited Support)</li>
</ul>

<p>
Notes:
</p>
<ul class="org-ul">
<li>Custom training loops: <i>Eager mode</i> is only recommended for debugging, in <i>a graph</i> recommended using tf.function (custom training loops)</li>
</ul>
</div>
</div>

<div id="outline-container-org49cf41d" class="outline-4">
<h4 id="org49cf41d"><span class="section-number-4">13.40.2.</span> terms</h4>
<div class="outline-text-4" id="text-13-40-2">
<dl class="org-dl">
<dt>replica</dt><dd>copy of the model</dd>
<dt>Parameter servers</dt><dd>machines that hold a single copy of parameters/variables</dd>
<dt>Replica context</dt><dd>strategy.run function - when executing the computation function that is being replicated.</dd>
<dt>Cross-replica context</dt><dd>when you enter a strategy.scope</dd>
<dt>Update context</dt><dd>tf.distribute.StrategyExtended.update call</dd>
<dt>Reductions</dt><dd>method of aggregating multiple values into one value (sync training)
<dl class="org-dl">
<dt>All-reduce</dt><dd>is an algorithm for performing a reduction on values from multiple devices and making the result available on all of those devices</dd>
</dl></dd>
<dt>Mirrored variables</dt><dd>variables that are created on multiple devices, where we keep the variables in sync by applying the same updates to every copy.</dd>
<dt>Distribute-aware layers</dt><dd>generally called in a replica context.</dd>
</dl>
</div>
</div>
<div id="outline-container-orge8ceab8" class="outline-4">
<h4 id="orge8ceab8"><span class="section-number-4">13.40.3.</span> Synchronous vs asynchronous training</h4>
<div class="outline-text-4" id="text-13-40-3">
<p>
sync - via <b>all-reduce</b>
</p>
<ul class="org-ul">
<li>workers train over different slices of input data (Data parallelism)</li>
<li>aggregating gradients at each step</li>
<li>the updates from each replica are aggregated together before updating the model variables</li>
</ul>

<p>
async - via <b>parameter server architecture</b>
</p>
<ul class="org-ul">
<li>all workers are independently training over the input data and updating variables asynchronously</li>
<li>each replica updates the model variables independently</li>
</ul>

<p>
groups:
</p>
<ul class="org-ul">
<li><b>replicas partitioned</b> into groups which are in sync within each group but async between groups.</li>
</ul>
</div>
</div>
<div id="outline-container-org442500a" class="outline-4">
<h4 id="org442500a"><span class="section-number-4">13.40.4.</span> strategies</h4>
<div class="outline-text-4" id="text-13-40-4">
<p>
<b>MultiWorkerMirroredStrategy</b> is very similar to MirroredStrategy. It implements synchronous distributed
 training across multiple workers, each with potentially multiple GPUs.
</p>
</div>
<ol class="org-ol">
<li><a id="org4d9473c"></a>MirroredStrategy<br />
<div class="outline-text-5" id="text-13-40-4-1">
<p>
tf.distribute.MirroredStrategy
</p>

<p>
mirrors variables to multiple devices.
</p>

<p>
Each variable in the model is mirrored across all the replicas. These variables are kept in sync with each
 other by applying identical updates.
</p>
</div>

<ol class="org-ol">
<li><a id="org5d02848"></a>kubeflow ex MultiWorkerMirroredStrategy<br />
<div class="outline-text-6" id="text-13-40-4-1-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #f08080; font-style: italic;">"""An example of multi-worker training with Keras model using Strategy API."""</span>

<span style="color: #8ac6f2; font-weight: bold;">from</span> __future__ <span style="color: #8ac6f2; font-weight: bold;">import</span> absolute_import, division, print_function

<span style="color: #8ac6f2; font-weight: bold;">import</span> argparse
<span style="color: #8ac6f2; font-weight: bold;">import</span> json
<span style="color: #8ac6f2; font-weight: bold;">import</span> os

<span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow_datasets <span style="color: #8ac6f2; font-weight: bold;">as</span> tfds
<span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #8ac6f2; font-weight: bold;">from</span> tensorflow.keras <span style="color: #8ac6f2; font-weight: bold;">import</span> layers, models


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">make_datasets_unbatched</span>():
  <span style="color: #cae682;">BUFFER_SIZE</span> = 10000

  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Scaling MNIST data from (0, 255] to (0., 1.]</span>
  <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">scale</span>(image, label):
    <span style="color: #cae682;">image</span> = tf.cast(image, tf.float32)
    <span style="color: #cae682;">image</span> /= 255
    <span style="color: #8ac6f2; font-weight: bold;">return</span> image, label

  <span style="color: #cae682;">datasets</span>, <span style="color: #cae682;">_</span> = tfds.load(name=<span style="color: #95e454;">'mnist'</span>, with_info=<span style="color: #e5786d; font-weight: bold;">True</span>, as_supervised=<span style="color: #e5786d; font-weight: bold;">True</span>)

  <span style="color: #8ac6f2; font-weight: bold;">return</span> datasets[<span style="color: #95e454;">'train'</span>].<span style="color: #e5786d;">map</span>(scale).cache().shuffle(BUFFER_SIZE)


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">build_and_compile_cnn_model</span>():
  <span style="color: #cae682;">model</span> = models.Sequential()
  model.add(
      layers.Conv2D(32, (3, 3), activation=<span style="color: #95e454;">'relu'</span>, input_shape=(28, 28, 1)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation=<span style="color: #95e454;">'relu'</span>))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation=<span style="color: #95e454;">'relu'</span>))
  model.add(layers.Flatten())
  model.add(layers.Dense(64, activation=<span style="color: #95e454;">'relu'</span>))
  model.add(layers.Dense(10, activation=<span style="color: #95e454;">'softmax'</span>))

  model.summary()

  model.<span style="color: #e5786d;">compile</span>(optimizer=<span style="color: #95e454;">'adam'</span>,
                loss=<span style="color: #95e454;">'sparse_categorical_crossentropy'</span>,
                metrics=[<span style="color: #95e454;">'accuracy'</span>])

  <span style="color: #8ac6f2; font-weight: bold;">return</span> model


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">decay</span>(epoch):
  <span style="color: #8ac6f2; font-weight: bold;">if</span> epoch &lt; 3: <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">pylint: disable=no-else-return</span>
    <span style="color: #8ac6f2; font-weight: bold;">return</span> 1e-3
  <span style="color: #8ac6f2; font-weight: bold;">if</span> 3 &lt;= epoch &lt; 7:
    <span style="color: #8ac6f2; font-weight: bold;">return</span> 1e-4
  <span style="color: #8ac6f2; font-weight: bold;">return</span> 1e-5


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">main</span>(args):

  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">MultiWorkerMirroredStrategy creates copies of all variables in the model's</span>
  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">layers on each device across all workers</span>
  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">if your GPUs don't support NCCL, replace "communication" with another</span>
  <span style="color: #cae682;">strategy</span> = tf.distribute.MultiWorkerMirroredStrategy(
      communication_options=tf.distribute.experimental.CommunicationOptions(implementation=tf.distribute.experimental.CollectiveCommunication.AUTO))

  <span style="color: #cae682;">BATCH_SIZE_PER_REPLICA</span> = 64
  <span style="color: #cae682;">BATCH_SIZE</span> = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync

  <span style="color: #8ac6f2; font-weight: bold;">with</span> strategy.scope():
    <span style="color: #cae682;">ds_train</span> = make_datasets_unbatched().batch(BATCH_SIZE).repeat()
    <span style="color: #cae682;">options</span> = tf.data.Options()
    options.experimental_distribute.<span style="color: #cae682;">auto_shard_policy</span> = \
        tf.data.experimental.AutoShardPolicy.DATA
    <span style="color: #cae682;">ds_train</span> = ds_train.with_options(options)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Model building/compiling need to be within `strategy.scope()`.</span>
    <span style="color: #cae682;">multi_worker_model</span> = build_and_compile_cnn_model()

  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Define the checkpoint directory to store the checkpoints</span>
  <span style="color: #cae682;">checkpoint_dir</span> = args.checkpoint_dir

  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Name of the checkpoint files</span>
  <span style="color: #cae682;">checkpoint_prefix</span> = os.path.join(checkpoint_dir, <span style="color: #95e454;">"ckpt_{epoch}"</span>)

  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Function for decaying the learning rate.</span>
  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">You can define any decay function you need.</span>
  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Callback for printing the LR at the end of each epoch.</span>
  <span style="color: #8ac6f2; font-weight: bold;">class</span> <span style="color: #92a65e; font-weight: bold;">PrintLR</span>(tf.keras.callbacks.Callback):

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">on_epoch_end</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, epoch, logs=<span style="color: #e5786d; font-weight: bold;">None</span>): <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">pylint: disable=no-self-use</span>
      <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">'</span><span style="color: #e5786d; font-weight: bold;">\n</span><span style="color: #95e454;">Learning rate for epoch {} is {}'</span>.<span style="color: #e5786d;">format</span>(
        epoch + 1, multi_worker_model.optimizer.lr.numpy()))

  <span style="color: #cae682;">callbacks</span> = [
      tf.keras.callbacks.TensorBoard(log_dir=<span style="color: #95e454;">'./logs'</span>),
      tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,
                                         save_weights_only=<span style="color: #e5786d; font-weight: bold;">True</span>),
      tf.keras.callbacks.LearningRateScheduler(decay),
      PrintLR()
  ]

  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Keras' `model.fit()` trains the model with specified number of epochs and</span>
  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">number of steps per epoch. Note that the numbers here are for demonstration</span>
  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">purposes only and may not sufficiently produce a model with good quality.</span>
  multi_worker_model.fit(ds_train,
                         epochs=10,
                         steps_per_epoch=70,
                         callbacks=callbacks)

  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Saving a model</span>
  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Let `is_chief` be a utility function that inspects the cluster spec and</span>
  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">current task type and returns True if the worker is the chief and False</span>
  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">otherwise.</span>
  <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">is_chief</span>():
    <span style="color: #8ac6f2; font-weight: bold;">return</span> TASK_INDEX == 0

  <span style="color: #8ac6f2; font-weight: bold;">if</span> is_chief():
    <span style="color: #cae682;">model_path</span> = args.saved_model_dir

  <span style="color: #8ac6f2; font-weight: bold;">else</span>:
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Save to a path that is unique across workers.</span>
    <span style="color: #cae682;">model_path</span> = args.saved_model_dir + <span style="color: #95e454;">'/worker_tmp_'</span> + <span style="color: #e5786d;">str</span>(TASK_INDEX)

  multi_worker_model.save(model_path)


<span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #e5786d;">__name__</span> == <span style="color: #95e454;">'__main__'</span>:
  os.<span style="color: #cae682;">environ</span>[<span style="color: #95e454;">'NCCL_DEBUG'</span>] = <span style="color: #95e454;">'INFO'</span>

  tfds.disable_progress_bar()

  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">to decide if a worker is chief, get TASK_INDEX in Cluster info</span>
  <span style="color: #cae682;">tf_config</span> = json.loads(os.environ.get(<span style="color: #95e454;">'TF_CONFIG'</span>) <span style="color: #8ac6f2; font-weight: bold;">or</span> <span style="color: #95e454;">'{}'</span>)
  <span style="color: #cae682;">TASK_INDEX</span> = tf_config[<span style="color: #95e454;">'task'</span>][<span style="color: #95e454;">'index'</span>]

  <span style="color: #cae682;">parser</span> = argparse.ArgumentParser()
  parser.add_argument(<span style="color: #95e454;">'--saved_model_dir'</span>,
                      <span style="color: #e5786d;">type</span>=<span style="color: #e5786d;">str</span>,
                      required=<span style="color: #e5786d; font-weight: bold;">True</span>,
                      <span style="color: #e5786d;">help</span>=<span style="color: #95e454;">'Tensorflow export directory.'</span>)

  parser.add_argument(<span style="color: #95e454;">'--checkpoint_dir'</span>,
                      <span style="color: #e5786d;">type</span>=<span style="color: #e5786d;">str</span>,
                      required=<span style="color: #e5786d; font-weight: bold;">True</span>,
                      <span style="color: #e5786d;">help</span>=<span style="color: #95e454;">'Tensorflow checkpoint directory.'</span>)

  <span style="color: #cae682;">parsed_args</span> = parser.parse_args()
  main(parsed_args)

</pre>
</div>
</div>
</li>
</ol>
</li>
<li><a id="orgd8c26e0"></a>CentralStorageStrategy (experimental)<br />
<div class="outline-text-5" id="text-13-40-4-2">
<p>
tf.distribute.experimental.CentralStorageStrategy
</p>

<p>
puts all variables on a single device on the same machine (and does sync training).
</p>
</div>
</li>
<li><a id="org632241c"></a>ParameterServerStrategy (experimental)<br />
<div class="outline-text-5" id="text-13-40-4-3">
<p>
creates variables on the parameter servers.
</p>

<p>
api
</p>
<ul class="org-ul">
<li>Model.fit</li>
<li>custom training loop
<ul class="org-ul">
<li>tf.distribute.experimental.ParameterServerStrategy (tensorflow 1.0)</li>
<li>tf.distribute.ParameterServerStrategy</li>
</ul></li>
</ul>

<p>
notes:
</p>
<ul class="org-ul">
<li>data-parallel method</li>
<li>All replicas that want to operate on a variable retrieve parameters/variables from Par server at the
beginning of a step and send an update to be applied at the end of the step. These can in principle support
either sync or async training, but right now we only have support for async training with parameter servers.</li>
<li>workers and parameter servers</li>
<li>Variables are created on parameter servers and they are read and updated by workers in each step</li>
<li>workers read and update these variables independently without synchronizing with each other (asynchronous training)</li>
<li>'cluster' with several 'jobs', and each of the jobs may have one or more 'tasks'</li>
</ul>

<p>
recommended to have:
</p>
<ul class="org-ul">
<li>One coordinator job (has the job name or task type: <b>chief</b>) - creates resources, dispatches training tasks, writes checkpoints, and deals with task failures.
<ul class="org-ul">
<li>know the addresses and ports of all other TensorFlow servers, except the evaluator.</li>
</ul></li>
<li>Multiple worker jobs (job name or task type: <b>worker</b>)
<ul class="org-ul">
<li>need to know which port they need to listen to.</li>
<li>all workers should have the same number of GPUs available.</li>
<li>each worker receives the same dataset, except when it is shuffled differently</li>
</ul></li>
<li>Multiple parameter server jobs (job name or task type: <b>ps</b>) - tf.distribute.Server
<ul class="org-ul">
<li>need to know which port they need to listen to.</li>
</ul></li>
<li>evaluator (optional) -</li>
</ul>

<p>
<b>worker</b> and <b>ps</b>
</p>
<ul class="org-ul">
<li>run <b>tf.distribute.Server</b> instances that listen for requests from the <b>chief</b>.</li>
<li>dataset<sub>fn</sub> will be wrapped into a tf.function and then executed on each worker to generate the data pipeline.</li>
<li>apply the transformation inside the dataset<sub>fn</sub> via tf.data.Dataset.map</li>
</ul>

<p>
datasets allowed to use:
</p>
<ul class="org-ul">
<li>tf.data.Dataset</li>
<li>tf.distribute.DistributedDataset</li>
<li>tf.keras.utils.experimental.DatasetCreator - the code in dataset<sub>fn</sub> will be invoked on the input device,
which is usually the CPU, on each of the worker machines.</li>
</ul>

<p>
<b>repeat and steps<sub>per</sub><sub>epoch</sub></b>
</p>
<ul class="org-ul">
<li>Dataset.repeat — which repeats a dataset indefinitely when called without an argument—and specify the
steps<sub>per</sub><sub>epoch</sub> argument in the Model.fit call.</li>
</ul>

<p>
Note from TF (Model.fit):
</p>
<ul class="org-ul">
<li>When using a `tf.keras.utils.experimental.DatasetCreator`, `steps<sub>per</sub><sub>epoch</sub>`, `validation<sub>steps</sub>`, `steps`,
or `pss<sub>evaluation</sub><sub>shards</sub>` argument must be provided in `Model.fit`, `Model.evaluate`, or `Model.predict`
<ul class="org-ul">
<li>validation<sub>steps</sub> - for validation data</li>
<li>pss<sub>evaluation</sub><sub>shards</sub> - The number of shards should be at least the number of workers for good performance.</li>
</ul></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgafff6de"></a>tf.data.experimental.AutoShardPolicy<br />
<div class="outline-text-6" id="text-13-40-4-3-1">
<ul class="org-ul">
<li>OFF: No sharding will be performed.</li>
<li>AUTO: Attempts FILE-based sharding, falling back to DATA-based sharding.</li>
<li>FILE: Shards by input files (i.e. each worker will get a set of files to process). When this option is selected, make sure that there is at least as many files as workers. If there are fewer input files than workers, a runtime error will be raised.</li>
<li>DATA: Shards by elements produced by the dataset. Each worker will process the whole dataset and discard the portion that is not for itself. Note that for this mode to correctly partitions the dataset elements, the dataset needs to produce elements in a deterministic order.</li>
<li>HINT: Looks for the presence of shard(SHARD<sub>HINT</sub>, &#x2026;) which is treated as a placeholder to replace with shard(num<sub>workers</sub>, worker<sub>index</sub>).</li>
</ul>


<p>
usage:
</p>
<ul class="org-ul">
<li>options = tf.data.Options()</li>
<li>options.experimental<sub>distribute.auto</sub><sub>shard</sub><sub>policy</sub> = tf.data.experimental.AutoShardPolicy.OFF</li>
<li>train<sub>dataset</sub> = tf.data.Dataset.from<sub>tensor</sub><sub>slices</sub>((x<sub>train</sub>, y<sub>train</sub>))</li>
<li>train<sub>dataset</sub> = train<sub>dataset.with</sub><sub>options</sub>(options)</li>
</ul>


<p>
AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the
 following reason: Did not find a shardable source, walked to a node which is not a dataset: name:
 "FlatMapDataset/<sub>2</sub>"
</p>
<ul class="org-ul">
<li><a href="https://community.intel.com/t5/Intel-DevCloud/How-to-disable-this-waring-message-in-Tensorflow-2-8-training/td-p/1388632">https://community.intel.com/t5/Intel-DevCloud/How-to-disable-this-waring-message-in-Tensorflow-2-8-training/td-p/1388632</a></li>
</ul>
</div>
</li>
<li><a id="org2327352"></a>Evaluation<br />
<div class="outline-text-6" id="text-13-40-4-3-2">
<p>
For users using Model.fit, Model.evaluate uses inline (distributed) evaluation under the hood.
</p>
<ul class="org-ul">
<li>inline evaluation</li>
<li>sidecar evaluation</li>
</ul>
</div>
</li>
<li><a id="org5dff97d"></a>algorithm<br />
<div class="outline-text-6" id="text-13-40-4-3-3">
<p>
explanation 2014 <a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf">https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf</a>
</p>

<p>
useful to compare "parameter server" to more general-purpose distributed systems:
</p>
<ul class="org-ul">
<li>which mandate synchronous, iterative communication - iterative MapReduce framework</li>
<li>Distributed GraphLab - asycnronously schedules communication using a graph abstraction.</li>
</ul>

<p>
core goal of parameter server:
</p>
<ul class="org-ul">
<li>preserving state between iterations</li>
</ul>

<p>
Мы, как и прежде, создаём копии модели на всех воркерах. <a href="#org3e365c7">8</a>
</p>
<ul class="org-ul">
<li>парализм данных</li>
</ul>
</div>
</li>
<li><a id="org7011a20"></a>model and fit<br />
<div class="outline-text-6" id="text-13-40-4-3-4">
<p>
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model">https://www.tensorflow.org/api_docs/python/tf/keras/Model</a>
</p>
<ul class="org-ul">
<li>steps<sub>per</sub><sub>epoch</sub> - Total number of steps (batches of samples) before declaring one epoch finished and
starting the next epoch</li>
<li></li>
</ul>
</div>
</li>
<li><a id="orgdec3700"></a>dataset<br />
<div class="outline-text-6" id="text-13-40-4-3-5">
<p>
batches that straddle epoch boundaries - пакетов, которые пересекают границы эпох
</p>

<ul class="org-ul">
<li>repeat with no argument - infinity</li>

<li>repeat + batch = batches that straddle epoch boundaries</li>
<li>batch + repeat = clear epoch separation</li>
<li>shuffle + repeat = show every element of one epoch before moving to the next</li>
<li>repeat + shuffle =  mixes the epoch boundaries together</li>
</ul>
</div>
</li>

<li><a id="org1e9f21d"></a>usage<br />
<div class="outline-text-6" id="text-13-40-4-3-6">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- who do what</span>
<span style="color: #cae682;">cluster_resolver</span> = tf.distribute.cluster_resolver.TFConfigClusterResolver()
<span style="color: #8ac6f2; font-weight: bold;">if</span> cluster_resolver.task_type <span style="color: #8ac6f2; font-weight: bold;">in</span> (<span style="color: #95e454;">"worker"</span>, <span style="color: #95e454;">"ps"</span>):
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Start a TensorFlow server and wait.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Set the environment variable to allow reporting worker and ps failure to the</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">coordinator. This is a workaround and won't be necessary in the future.</span>
    os.<span style="color: #cae682;">environ</span>[<span style="color: #95e454;">"GRPC_FAIL_FAST"</span>] = <span style="color: #95e454;">"use_caller"</span>

    <span style="color: #cae682;">server</span> = tf.distribute.Server(
        cluster_resolver.cluster_spec(),
        job_name=cluster_resolver.task_type,
        task_index=cluster_resolver.task_id,
        protocol=cluster_resolver.rpc_layer <span style="color: #8ac6f2; font-weight: bold;">or</span> <span style="color: #95e454;">"grpc"</span>,
        start=<span style="color: #e5786d; font-weight: bold;">True</span>)
    server.join()
<span style="color: #8ac6f2; font-weight: bold;">elif</span> cluster_resolver.task_type == <span style="color: #95e454;">"evaluator"</span>:   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Run sidecar evaluation</span>
    <span style="color: #8ac6f2; font-weight: bold;">pass</span> <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">note used</span>
<span style="color: #8ac6f2; font-weight: bold;">else</span>:  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Run the coordinator.</span>




<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- ParameterServerStrategy object. will use all the available GPUs on each worker</span>
<span style="color: #cae682;">NUM_PS</span>=1
<span style="color: #cae682;">variable_partitioner</span> = (
    tf.distribute.experimental.partitioners.MinSizePartitioner(
        min_shard_bytes=(256 &lt;&lt; 10),
        max_shards=NUM_PS))

<span style="color: #cae682;">strategy</span> = tf.distribute.ParameterServerStrategy(
    cluster_resolver,
    variable_partitioner=variable_partitioner)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- trivial model</span>
<span style="color: #8ac6f2; font-weight: bold;">with</span> strategy.scope(): <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dataset_fn will be wrapped into a tf.function and then executed on each worker to generate the data pipeline.</span>
  <span style="color: #cae682;">model</span> = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])
  model.<span style="color: #e5786d;">compile</span>(tf.keras.optimizers.legacy.SGD(), loss=<span style="color: #95e454;">"mse"</span>, steps_per_execution=10)


</pre>
</div>
</div>
</li>
<li><a id="orgf3d4d2d"></a>usage working parameter server strategy for TF 2.0<br />
<div class="outline-text-6" id="text-13-40-4-3-7">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #8ac6f2; font-weight: bold;">import</span> os
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- who do what</span>
<span style="color: #cae682;">cluster_resolver</span> = tf.distribute.cluster_resolver.TFConfigClusterResolver()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- set GPU for worker</span>
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">set_gpu</span>():
    <span style="color: #cae682;">gpus</span> = tf.config.list_physical_devices(<span style="color: #95e454;">'GPU'</span>)
    <span style="color: #8ac6f2; font-weight: bold;">if</span> gpus:
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Restrict TensorFlow to only use the first GPU</span>
        <span style="color: #8ac6f2; font-weight: bold;">try</span>:
            tf.config.set_visible_devices(gpus[0], <span style="color: #95e454;">'GPU'</span>)
            <span style="color: #cae682;">logical_gpus</span> = tf.config.list_logical_devices(<span style="color: #95e454;">'GPU'</span>)
            <span style="color: #e5786d;">print</span>(<span style="color: #e5786d;">len</span>(gpus), <span style="color: #95e454;">"Physical GPUs,"</span>, <span style="color: #e5786d;">len</span>(logical_gpus), <span style="color: #95e454;">"Logical GPU"</span>)
        <span style="color: #8ac6f2; font-weight: bold;">except</span> <span style="color: #92a65e; font-weight: bold;">RuntimeError</span> <span style="color: #8ac6f2; font-weight: bold;">as</span> e:
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Visible devices must be set before GPUs have been initialized</span>
            <span style="color: #e5786d;">print</span>(e)

<span style="color: #8ac6f2; font-weight: bold;">if</span> cluster_resolver.task_type <span style="color: #8ac6f2; font-weight: bold;">in</span> (<span style="color: #95e454;">"worker"</span>):
    set_gpu()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- wait for task for worker and ps</span>
<span style="color: #8ac6f2; font-weight: bold;">if</span> cluster_resolver.task_type <span style="color: #8ac6f2; font-weight: bold;">in</span> (<span style="color: #95e454;">"worker"</span>, <span style="color: #95e454;">"ps"</span>):
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Start a TensorFlow server and wait.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Set the environment variable to allow reporting worker and ps failure to the</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">coordinator. This is a workaround and won't be necessary in the future.</span>
    os.<span style="color: #cae682;">environ</span>[<span style="color: #95e454;">"GRPC_FAIL_FAST"</span>] = <span style="color: #95e454;">"use_caller"</span>

    <span style="color: #cae682;">server</span> = tf.distribute.Server(
        cluster_resolver.cluster_spec(),
        job_name=cluster_resolver.task_type,
        task_index=cluster_resolver.task_id,
        protocol=cluster_resolver.rpc_layer <span style="color: #8ac6f2; font-weight: bold;">or</span> <span style="color: #95e454;">"grpc"</span>,
        start=<span style="color: #e5786d; font-weight: bold;">True</span>)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.task_type"</span>, cluster_resolver.task_type)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.task_id"</span>, cluster_resolver.task_id)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.rpc_layer"</span>, cluster_resolver.rpc_layer <span style="color: #8ac6f2; font-weight: bold;">or</span> <span style="color: #95e454;">"grpc"</span>)
    server.join()
<span style="color: #8ac6f2; font-weight: bold;">elif</span> cluster_resolver.task_type == <span style="color: #95e454;">"evaluator"</span>:   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Run sidecar evaluation</span>
    <span style="color: #8ac6f2; font-weight: bold;">pass</span> <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">note used</span>
<span style="color: #8ac6f2; font-weight: bold;">else</span>:  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Run the coordinator.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- ParameterServerStrategy object. will use all the available GPUs on each worker</span>
    <span style="color: #cae682;">NUM_PS</span>=1
    <span style="color: #cae682;">variable_partitioner</span> = (
        tf.distribute.experimental.partitioners.MinSizePartitioner(
            min_shard_bytes=(256 &lt;&lt; 10),
            max_shards=NUM_PS))

    <span style="color: #cae682;">strategy</span> = tf.distribute.ParameterServerStrategy(
        cluster_resolver,
        variable_partitioner=variable_partitioner)


    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- data</span>
    <span style="color: #cae682;">mnist</span> = tf.keras.datasets.mnist
    (x_train, y_train), (<span style="color: #cae682;">x_test</span>, <span style="color: #cae682;">y_test</span>) = mnist.load_data()
    <span style="color: #cae682;">x_train</span>, <span style="color: #cae682;">x_test</span> = x_train / 255.0, x_test / 255.0

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- trivial model</span>
    <span style="color: #8ac6f2; font-weight: bold;">with</span> strategy.scope(): <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dataset_fn will be wrapped into a tf.function and then executed on each worker to generate the data pipeline.</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- Dataset TF class</span>
        <span style="color: #cae682;">batch_size</span>=16
        <span style="color: #cae682;">train_dataset</span> = tf.data.Dataset.from_tensor_slices((x_train, y_train))
        <span style="color: #cae682;">train_dataset</span> = train_dataset.shuffle(60000).repeat().batch(batch_size)
        <span style="color: #cae682;">validation_dataset</span> = tf.data.Dataset.from_tensor_slices((x_test, y_test))
        <span style="color: #cae682;">validation_dataset</span> = validation_dataset.shuffle(60000).batch(batch_size)
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- model</span>
        <span style="color: #cae682;">model</span> = tf.keras.models.Sequential([
            tf.keras.layers.Flatten(input_shape=(28, 28)),
            tf.keras.layers.Dense(128, activation=<span style="color: #95e454;">'relu'</span>),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(10)
        ])

        <span style="color: #cae682;">loss_fn</span> = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span style="color: #e5786d; font-weight: bold;">True</span>)
        model.<span style="color: #e5786d;">compile</span>(optimizer=<span style="color: #95e454;">'adam'</span>,
                      loss=loss_fn,
                      metrics=[<span style="color: #95e454;">'accuracy'</span>],
                      pss_evaluation_shards=<span style="color: #95e454;">'auto'</span>)

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- train</span>
        model.fit(train_dataset, epochs=5, steps_per_epoch=300)
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- save</span>
        model.save(<span style="color: #95e454;">'aa.keras'</span>, overwrite=<span style="color: #e5786d; font-weight: bold;">True</span>, save_format=<span style="color: #95e454;">"tf"</span>)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">The file needs to end with the .keras extension</span>
    <span style="color: #cae682;">model</span> = tf.keras.models.load_model(<span style="color: #95e454;">'aa.keras'</span>)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- checks the model's performance</span>
    model.evaluate(validation_dataset, verbose=2)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- inferece</span>
    <span style="color: #cae682;">predictions</span> = model(x_train[:1]).numpy()
    <span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
    <span style="color: #e5786d;">print</span>(np.argmax(predictions))
    <span style="color: #e5786d;">print</span>(y_train[:1])
</pre>
</div>
</div>
</li>
<li><a id="org62760e6"></a>usage working parameter server strategy for TF 2.0 v2<br />
<div class="outline-text-6" id="text-13-40-4-3-8">
<div class="org-src-container">
<pre class="src src-python">
</pre>
</div>
</div>
</li>
<li><a id="org301639e"></a>usage3 dataset creator (comment several prams)<br />
<div class="outline-text-6" id="text-13-40-4-3-9">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #8ac6f2; font-weight: bold;">import</span> os
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- who do what</span>
<span style="color: #cae682;">cluster_resolver</span> = tf.distribute.cluster_resolver.TFConfigClusterResolver()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- set GPU for worker</span>
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">set_gpu</span>():
    <span style="color: #cae682;">gpus</span> = tf.config.list_physical_devices(<span style="color: #95e454;">'GPU'</span>)
    <span style="color: #8ac6f2; font-weight: bold;">if</span> gpus:
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Restrict TensorFlow to only use the first GPU</span>
        <span style="color: #8ac6f2; font-weight: bold;">try</span>:
            tf.config.set_visible_devices(gpus[0], <span style="color: #95e454;">'GPU'</span>)
            <span style="color: #cae682;">logical_gpus</span> = tf.config.list_logical_devices(<span style="color: #95e454;">'GPU'</span>)
            <span style="color: #e5786d;">print</span>(<span style="color: #e5786d;">len</span>(gpus), <span style="color: #95e454;">"Physical GPUs,"</span>, <span style="color: #e5786d;">len</span>(logical_gpus), <span style="color: #95e454;">"Logical GPU"</span>)
        <span style="color: #8ac6f2; font-weight: bold;">except</span> <span style="color: #92a65e; font-weight: bold;">RuntimeError</span> <span style="color: #8ac6f2; font-weight: bold;">as</span> e:
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Visible devices must be set before GPUs have been initialized</span>
            <span style="color: #e5786d;">print</span>(e)

<span style="color: #8ac6f2; font-weight: bold;">if</span> cluster_resolver.task_type <span style="color: #8ac6f2; font-weight: bold;">in</span> (<span style="color: #95e454;">"worker"</span>):
    set_gpu()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- wait for task for worker and ps</span>
<span style="color: #8ac6f2; font-weight: bold;">if</span> cluster_resolver.task_type <span style="color: #8ac6f2; font-weight: bold;">in</span> (<span style="color: #95e454;">"worker"</span>, <span style="color: #95e454;">"ps"</span>):
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Start a TensorFlow server and wait.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Set the environment variable to allow reporting worker and ps failure to the</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">coordinator. This is a workaround and won't be necessary in the future.</span>
    os.<span style="color: #cae682;">environ</span>[<span style="color: #95e454;">"GRPC_FAIL_FAST"</span>] = <span style="color: #95e454;">"use_caller"</span>

    <span style="color: #cae682;">server</span> = tf.distribute.Server(
        cluster_resolver.cluster_spec(),
        job_name=cluster_resolver.task_type,
        task_index=cluster_resolver.task_id,
        protocol=cluster_resolver.rpc_layer <span style="color: #8ac6f2; font-weight: bold;">or</span> <span style="color: #95e454;">"grpc"</span>,
        start=<span style="color: #e5786d; font-weight: bold;">True</span>)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.task_type"</span>, cluster_resolver.task_type)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.task_id"</span>, cluster_resolver.task_id)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.rpc_layer"</span>, cluster_resolver.rpc_layer <span style="color: #8ac6f2; font-weight: bold;">or</span> <span style="color: #95e454;">"grpc"</span>)
    server.join()
<span style="color: #8ac6f2; font-weight: bold;">elif</span> cluster_resolver.task_type == <span style="color: #95e454;">"evaluator"</span>:   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Run sidecar evaluation</span>
    <span style="color: #8ac6f2; font-weight: bold;">pass</span> <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">note used</span>
<span style="color: #8ac6f2; font-weight: bold;">else</span>:  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Run the coordinator.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">def dataset_fn(input_context):</span>
    <span style="color: #fa8072;">#     </span><span style="color: #99968b; font-style: italic;">dataset = dataset.map(preprocessing_layer)</span>
    <span style="color: #fa8072;">#     </span><span style="color: #99968b; font-style: italic;">return dataset</span>

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dataset_creator = tf.keras.utils.experimental.DatasetCreator(dataset_fn)</span>

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- ParameterServerStrategy object. will use all the available GPUs on each worker</span>
    <span style="color: #cae682;">NUM_PS</span>=1
    <span style="color: #cae682;">variable_partitioner</span> = (
        tf.distribute.experimental.partitioners.MinSizePartitioner(
            min_shard_bytes=(256 &lt;&lt; 10),
            max_shards=NUM_PS))

    <span style="color: #cae682;">strategy</span> = tf.distribute.ParameterServerStrategy(
        cluster_resolver,
        variable_partitioner=variable_partitioner)


    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- data</span>
    <span style="color: #cae682;">mnist</span> = tf.keras.datasets.mnist
    (x_train, y_train), (<span style="color: #cae682;">x_test</span>, <span style="color: #cae682;">y_test</span>) = mnist.load_data()
    <span style="color: #cae682;">x_train</span>, <span style="color: #cae682;">x_test</span> = x_train / 255.0, x_test / 255.0

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- trivial model</span>
    <span style="color: #8ac6f2; font-weight: bold;">with</span> strategy.scope(): <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dataset_fn will be wrapped into a tf.function and then executed on each worker to generate the data pipeline.</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- Dataset TF class</span>
        <span style="color: #cae682;">train_dataset</span> = tf.data.Dataset.from_tensor_slices((x_train, y_train))
        <span style="color: #cae682;">validation_dataset</span> = tf.data.Dataset.from_tensor_slices((x_test, y_test))
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- model</span>
        <span style="color: #cae682;">model</span> = tf.keras.models.Sequential([
            tf.keras.layers.Flatten(input_shape=(28, 28)),
            tf.keras.layers.Dense(128, activation=<span style="color: #95e454;">'relu'</span>),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(10)
        ])

        <span style="color: #cae682;">loss_fn</span> = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span style="color: #e5786d; font-weight: bold;">True</span>)

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">steps_per_execution=10,</span>
        ,
                      <span style="color: #cae682;">pss_evaluation_shards</span>=<span style="color: #95e454;">'auto'</span>
        model.<span style="color: #e5786d;">compile</span>(optimizer=<span style="color: #95e454;">'adam'</span>,
                      loss=loss_fn,
                      metrics=[<span style="color: #95e454;">'accuracy'</span>])

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- train</span>

        model.fit(x_train, y_train, epochs=5, steps_per_epoch=3)
        model.fit(train_dataset, epochs=5, steps_per_epoch=3000)
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- checks the model's performance</span>
        model.evaluate(validation_dataset, verbose=2)
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;"># -- inferece</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">predictions = model(x_train[:1]).numpy()</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">import numpy as np</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(np.argmax(predictions))</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(y_train[:1])</span>
</pre>
</div>
</div>
</li>
<li><a id="org5884af2"></a>mnist last version<br />
<div class="outline-text-6" id="text-13-40-4-3-10">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Disable all GPUs. This prevents errors caused by all workers trying to use the same GPU. In a real-world application, each worker would be on a different machine.</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">import os</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">os.environ["CUDA_VISIBLE_DEVICES"] = "-1"</span>

<span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #8ac6f2; font-weight: bold;">import</span> os
<span style="color: #8ac6f2; font-weight: bold;">import</span> logging
<span style="color: #8ac6f2; font-weight: bold;">import</span> multiprocessing

tf.get_logger().setLevel(logging.DEBUG)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- who do what</span>
<span style="color: #cae682;">cluster_resolver</span> = tf.distribute.cluster_resolver.TFConfigClusterResolver()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- set GPU for worker</span>
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">set_gpu</span>():
    <span style="color: #cae682;">gpus</span> = tf.config.list_physical_devices(<span style="color: #95e454;">'GPU'</span>)
    <span style="color: #8ac6f2; font-weight: bold;">if</span> gpus:
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Restrict TensorFlow to only use the first GPU</span>
        <span style="color: #8ac6f2; font-weight: bold;">try</span>:
            <span style="color: #8ac6f2; font-weight: bold;">for</span> device <span style="color: #8ac6f2; font-weight: bold;">in</span> gpus:
                tf.config.experimental.set_memory_growth(device, <span style="color: #e5786d; font-weight: bold;">True</span>)
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">tf.config.set_logical_device_configuration(</span>
            <span style="color: #fa8072;">#         </span><span style="color: #99968b; font-style: italic;">gpus[0],</span>
            <span style="color: #fa8072;">#         </span><span style="color: #99968b; font-style: italic;">[tf.config.LogicalDeviceConfiguration(memory_limit=3024)])</span>
            <span style="color: #cae682;">gpu_devices</span> = tf.config.experimental.list_physical_devices(<span style="color: #95e454;">'GPU'</span>)
            tf.config.set_visible_devices(gpus[0], <span style="color: #95e454;">'GPU'</span>)
            <span style="color: #cae682;">logical_gpus</span> = tf.config.list_logical_devices(<span style="color: #95e454;">'GPU'</span>)
            <span style="color: #e5786d;">print</span>()
            <span style="color: #e5786d;">print</span>(<span style="color: #e5786d;">len</span>(gpus), <span style="color: #95e454;">"Physical GPUs,"</span>, <span style="color: #e5786d;">len</span>(logical_gpus), <span style="color: #95e454;">"Logical GPU"</span>)
            <span style="color: #e5786d;">print</span>()
            <span style="color: #cae682;">cpu_ph</span> = tf.config.list_physical_devices(<span style="color: #95e454;">'CPU'</span>)
            <span style="color: #cae682;">cpu_lg</span> = tf.config.list_logical_devices(<span style="color: #95e454;">'CPU'</span>)
            <span style="color: #e5786d;">print</span>(<span style="color: #e5786d;">len</span>(cpu_ph), <span style="color: #95e454;">"Physical CPUs,"</span>, <span style="color: #e5786d;">len</span>(cpu_lg), <span style="color: #95e454;">"Logical CPU"</span>)

        <span style="color: #8ac6f2; font-weight: bold;">except</span> <span style="color: #92a65e; font-weight: bold;">RuntimeError</span> <span style="color: #8ac6f2; font-weight: bold;">as</span> e:
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Visible devices must be set before GPUs have been initialized</span>
            <span style="color: #e5786d;">print</span>(e)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">if cluster_resolver.task_type in ("worker", "ps"):</span>
set_gpu() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">for all</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- wait for task for worker and ps</span>
<span style="color: #8ac6f2; font-weight: bold;">if</span> cluster_resolver.task_type <span style="color: #8ac6f2; font-weight: bold;">in</span> (<span style="color: #95e454;">"worker"</span>, <span style="color: #95e454;">"ps"</span>):
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Start a TensorFlow server and wait.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Set the environment variable to allow reporting worker and ps failure to the</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">coordinator. This is a workaround and won't be necessary in the future.</span>
    os.<span style="color: #cae682;">environ</span>[<span style="color: #95e454;">"GRPC_FAIL_FAST"</span>] = <span style="color: #95e454;">"use_caller"</span>

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;"># Workers need some inter_ops threads to work properly.</span>
    <span style="color: #cae682;">worker_config</span> = tf.compat.v1.ConfigProto(device_count={<span style="color: #95e454;">'GPU'</span>: 1, <span style="color: #95e454;">'CPU'</span>:1})
    <span style="color: #8ac6f2; font-weight: bold;">if</span> cluster_resolver.task_type <span style="color: #8ac6f2; font-weight: bold;">in</span> (<span style="color: #95e454;">"worker"</span>):
        <span style="color: #cae682;">NUM_WORKERS</span>=<span style="color: #e5786d;">len</span>(cluster_resolver.cluster_spec().job_tasks(<span style="color: #95e454;">'worker'</span>))
        <span style="color: #8ac6f2; font-weight: bold;">if</span> multiprocessing.cpu_count() &lt; NUM_WORKERS + 1:
            worker_config.<span style="color: #cae682;">inter_op_parallelism_threads</span> = NUM_WORKERS + 1

    <span style="color: #cae682;">server</span> = tf.distribute.Server(
        cluster_resolver.cluster_spec(),
        job_name=cluster_resolver.task_type,
        task_index=cluster_resolver.task_id,
        config=worker_config,
        protocol=cluster_resolver.rpc_layer <span style="color: #8ac6f2; font-weight: bold;">or</span> <span style="color: #95e454;">"grpc"</span>,
        start=<span style="color: #e5786d; font-weight: bold;">True</span>)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.task_type"</span>, cluster_resolver.task_type)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.task_id"</span>, cluster_resolver.task_id)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.rpc_layer"</span>, cluster_resolver.rpc_layer <span style="color: #8ac6f2; font-weight: bold;">or</span> <span style="color: #95e454;">"grpc"</span>)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"server.default_session_config"</span>, server.server_def.default_session_config)
    <span style="color: #e5786d;">print</span>()
    server.join()
<span style="color: #8ac6f2; font-weight: bold;">elif</span> cluster_resolver.task_type == <span style="color: #95e454;">"evaluator"</span>:   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Run sidecar evaluation</span>
    <span style="color: #8ac6f2; font-weight: bold;">pass</span> <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">note used</span>
<span style="color: #8ac6f2; font-weight: bold;">else</span>:  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Run the coordinator.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- ParameterServerStrategy object. will use all the available GPUs on each worker</span>
    <span style="color: #cae682;">NUM_PS</span>=<span style="color: #e5786d;">len</span>(cluster_resolver.cluster_spec().job_tasks(<span style="color: #95e454;">'ps'</span>))
    <span style="color: #cae682;">variable_partitioner</span> = (
        tf.distribute.experimental.partitioners.MinSizePartitioner(
            min_shard_bytes=(256 &lt;&lt; 10),
            max_shards=NUM_PS))

    <span style="color: #cae682;">strategy</span> = tf.distribute.ParameterServerStrategy(
        cluster_resolver,
        variable_partitioner=variable_partitioner)


    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- data</span>
    <span style="color: #cae682;">mnist</span> = tf.keras.datasets.mnist
    (x_train, y_train), (<span style="color: #cae682;">x_test</span>, <span style="color: #cae682;">y_test</span>) = mnist.load_data()
    <span style="color: #cae682;">x_train</span>, <span style="color: #cae682;">x_test</span> = x_train / 255.0, x_test / 255.0

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- trivial model</span>
    <span style="color: #8ac6f2; font-weight: bold;">with</span> strategy.scope(): <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">dataset_fn will be wrapped into a tf.function and then executed on each worker to generate the data pipeline.</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">with tf.device('/device:GPU:0'):</span>
        <span style="color: #cae682;">batch_size</span>=32

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- Dataset TF class</span>
        <span style="color: #cae682;">train_dataset</span> = tf.data.Dataset.from_tensor_slices((x_train, y_train))

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">suppress warning at worker, maybe fix error.</span>
        <span style="color: #cae682;">options</span> = tf.data.Options()
        options.experimental_distribute.<span style="color: #cae682;">auto_shard_policy</span> = tf.data.experimental.AutoShardPolicy.DATA

        <span style="color: #cae682;">train_dataset</span> = train_dataset.with_options(options)
        <span style="color: #cae682;">train_dataset</span> = train_dataset.shuffle(600).repeat().batch(batch_size).prefetch(300)
        <span style="color: #cae682;">train_dataset</span> = strategy.experimental_distribute_dataset(train_dataset)
        <span style="color: #cae682;">validation_dataset</span> = tf.data.Dataset.from_tensor_slices((x_test, y_test))
        <span style="color: #cae682;">validation_dataset</span> = validation_dataset.shuffle(600).batch(batch_size)
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- model</span>
        <span style="color: #cae682;">model</span> = tf.keras.models.Sequential([
            tf.keras.layers.Flatten(input_shape=(28, 28)),
            tf.keras.layers.Dense(400, activation=<span style="color: #95e454;">'relu'</span>),
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">tf.keras.layers.Dense(3420, activation='relu'),</span>
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">tf.keras.layers.Dense(3420, activation='relu'),</span>
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(10)
        ])

        <span style="color: #cae682;">loss_fn</span> = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span style="color: #e5786d; font-weight: bold;">True</span>)
        model.<span style="color: #e5786d;">compile</span>(optimizer=<span style="color: #95e454;">'adam'</span>,
                      loss=loss_fn,
                      metrics=[<span style="color: #95e454;">'accuracy'</span>],
                      <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">not required: pss_evaluation_shards='auto'</span>
                      )
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print model</span>
        model.summary()

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- train</span>
        model.fit(train_dataset, epochs=5, steps_per_epoch=300)
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- save</span>
        model.save(<span style="color: #95e454;">'aa.keras'</span>, overwrite=<span style="color: #e5786d; font-weight: bold;">True</span>, save_format=<span style="color: #95e454;">"tf"</span>)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">The file needs to end with the .keras extension</span>
    <span style="color: #cae682;">model</span> = tf.keras.models.load_model(<span style="color: #95e454;">'aa.keras'</span>)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- checks the model's performance</span>
    model.evaluate(validation_dataset, verbose=2)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- inferece</span>
    <span style="color: #cae682;">predictions</span> = model(x_train[:1]).numpy()
    <span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
    <span style="color: #e5786d;">print</span>(np.argmax(predictions))
    <span style="color: #e5786d;">print</span>(y_train[:1])

</pre>
</div>
</div>
</li>
<li><a id="org1429f95"></a>resnet<br />
<div class="outline-text-6" id="text-13-40-4-3-11">
<pre class="example">
pip3 install tf-models-official==2.13 ; apt install -y emacs-nox
</pre>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Disable all GPUs. This prevents errors caused by all workers trying to use the same GPU. In a real-world application, each worker would be on a different machine.</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">import os</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">os.environ["CUDA_VISIBLE_DEVICES"] = "-1"</span>

<span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #8ac6f2; font-weight: bold;">import</span> os
<span style="color: #8ac6f2; font-weight: bold;">import</span> logging
<span style="color: #8ac6f2; font-weight: bold;">import</span> multiprocessing

tf.get_logger().setLevel(logging.DEBUG)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- who do what</span>
<span style="color: #cae682;">cluster_resolver</span> = tf.distribute.cluster_resolver.TFConfigClusterResolver()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- set GPU for worker</span>
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">set_gpu</span>():
    <span style="color: #cae682;">gpus</span> = tf.config.list_physical_devices(<span style="color: #95e454;">'GPU'</span>)
    <span style="color: #8ac6f2; font-weight: bold;">if</span> gpus:
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Restrict TensorFlow to only use the first GPU</span>
        <span style="color: #8ac6f2; font-weight: bold;">try</span>:
            <span style="color: #8ac6f2; font-weight: bold;">for</span> device <span style="color: #8ac6f2; font-weight: bold;">in</span> gpus:
                tf.config.experimental.set_memory_growth(device, <span style="color: #e5786d; font-weight: bold;">True</span>)
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">tf.config.set_logical_device_configuration(</span>
            <span style="color: #fa8072;">#         </span><span style="color: #99968b; font-style: italic;">gpus[0],</span>
            <span style="color: #fa8072;">#         </span><span style="color: #99968b; font-style: italic;">[tf.config.LogicalDeviceConfiguration(memory_limit=3024)])</span>
            <span style="color: #cae682;">gpu_devices</span> = tf.config.experimental.list_physical_devices(<span style="color: #95e454;">'GPU'</span>)
            tf.config.set_visible_devices(gpus[0], <span style="color: #95e454;">'GPU'</span>)
            <span style="color: #cae682;">logical_gpus</span> = tf.config.list_logical_devices(<span style="color: #95e454;">'GPU'</span>)
            <span style="color: #e5786d;">print</span>()
            <span style="color: #e5786d;">print</span>(<span style="color: #e5786d;">len</span>(gpus), <span style="color: #95e454;">"Physical GPUs,"</span>, <span style="color: #e5786d;">len</span>(logical_gpus), <span style="color: #95e454;">"Logical GPU"</span>)
            <span style="color: #e5786d;">print</span>()
            <span style="color: #cae682;">cpu_ph</span> = tf.config.list_physical_devices(<span style="color: #95e454;">'CPU'</span>)
            <span style="color: #cae682;">cpu_lg</span> = tf.config.list_logical_devices(<span style="color: #95e454;">'CPU'</span>)
            <span style="color: #e5786d;">print</span>(<span style="color: #e5786d;">len</span>(cpu_ph), <span style="color: #95e454;">"Physical CPUs,"</span>, <span style="color: #e5786d;">len</span>(cpu_lg), <span style="color: #95e454;">"Logical CPU"</span>)

        <span style="color: #8ac6f2; font-weight: bold;">except</span> <span style="color: #92a65e; font-weight: bold;">RuntimeError</span> <span style="color: #8ac6f2; font-weight: bold;">as</span> e:
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Visible devices must be set before GPUs have been initialized</span>
            <span style="color: #e5786d;">print</span>(e)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">if cluster_resolver.task_type in ("worker", "ps"):</span>
set_gpu() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">for all</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- wait for task for worker and ps</span>
<span style="color: #8ac6f2; font-weight: bold;">if</span> cluster_resolver.task_type <span style="color: #8ac6f2; font-weight: bold;">in</span> (<span style="color: #95e454;">"worker"</span>, <span style="color: #95e454;">"ps"</span>):
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Start a TensorFlow server and wait.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Set the environment variable to allow reporting worker and ps failure to the</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">coordinator. This is a workaround and won't be necessary in the future.</span>
    os.<span style="color: #cae682;">environ</span>[<span style="color: #95e454;">"GRPC_FAIL_FAST"</span>] = <span style="color: #95e454;">"use_caller"</span>

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;"># Workers need some inter_ops threads to work properly.</span>
    <span style="color: #cae682;">worker_config</span> = tf.compat.v1.ConfigProto(device_count={<span style="color: #95e454;">'GPU'</span>: 1, <span style="color: #95e454;">'CPU'</span>:1})
    <span style="color: #8ac6f2; font-weight: bold;">if</span> cluster_resolver.task_type <span style="color: #8ac6f2; font-weight: bold;">in</span> (<span style="color: #95e454;">"worker"</span>):
        <span style="color: #cae682;">NUM_WORKERS</span>=<span style="color: #e5786d;">len</span>(cluster_resolver.cluster_spec().job_tasks(<span style="color: #95e454;">'worker'</span>))
        <span style="color: #8ac6f2; font-weight: bold;">if</span> multiprocessing.cpu_count() &lt; NUM_WORKERS + 1:
            worker_config.<span style="color: #cae682;">inter_op_parallelism_threads</span> = NUM_WORKERS + 1

    <span style="color: #cae682;">server</span> = tf.distribute.Server(
        cluster_resolver.cluster_spec(),
        job_name=cluster_resolver.task_type,
        task_index=cluster_resolver.task_id,
        config=worker_config,
        protocol=cluster_resolver.rpc_layer <span style="color: #8ac6f2; font-weight: bold;">or</span> <span style="color: #95e454;">"grpc"</span>,
        start=<span style="color: #e5786d; font-weight: bold;">True</span>)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.task_type"</span>, cluster_resolver.task_type)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.task_id"</span>, cluster_resolver.task_id)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cluster_resolver.rpc_layer"</span>, cluster_resolver.rpc_layer <span style="color: #8ac6f2; font-weight: bold;">or</span> <span style="color: #95e454;">"grpc"</span>)
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"server.default_session_config"</span>, server.server_def.default_session_config)
    <span style="color: #e5786d;">print</span>()
    server.join()
<span style="color: #8ac6f2; font-weight: bold;">elif</span> cluster_resolver.task_type == <span style="color: #95e454;">"evaluator"</span>:   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Run sidecar evaluation</span>
    <span style="color: #8ac6f2; font-weight: bold;">pass</span> <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">note used</span>
<span style="color: #8ac6f2; font-weight: bold;">else</span>:  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Run the coordinator.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- ParameterServerStrategy object. will use all the available GPUs on each worker</span>
    <span style="color: #cae682;">NUM_PS</span>=<span style="color: #e5786d;">len</span>(cluster_resolver.cluster_spec().job_tasks(<span style="color: #95e454;">'ps'</span>))
    <span style="color: #cae682;">variable_partitioner</span> = (
        tf.distribute.experimental.partitioners.MinSizePartitioner(
            min_shard_bytes=(256 &lt;&lt; 10),
            max_shards=NUM_PS))

    <span style="color: #cae682;">strategy</span> = tf.distribute.ParameterServerStrategy(
        cluster_resolver,
        variable_partitioner=variable_partitioner)

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---------------------------------------------------------------------------------------------------</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">----------------------- Model, Dataset, Training --------------------------------------------------</span>
    <span style="color: #8ac6f2; font-weight: bold;">with</span> strategy.scope()
        <span style="color: #8ac6f2; font-weight: bold;">from</span> importlib <span style="color: #8ac6f2; font-weight: bold;">import</span> <span style="color: #e5786d;">reload</span>
        <span style="color: #e5786d;">reload</span>(<span style="color: #95e454;">"./resnet-model-and-data.py"</span>)

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">------------ Part require modification for ParameterServer strategy</span>
    <span style="color: #cae682;">train_dataset</span> = tf.data.Dataset.from_tensor_slices((x_train.astype(<span style="color: #e5786d;">str</span>), y_train.astype(<span style="color: #e5786d;">int</span>))).skip(df.shape[0] - df.shape[0]//4)
    <span style="color: #cae682;">train_dataset</span> = train_dataset.<span style="color: #e5786d;">map</span>(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x, y: encode_single_sample(x, y), tf.data.experimental.AUTOTUNE)

    <span style="color: #cae682;">train_dataset</span> = train_dataset.batch(BATCH_SIZE).prefetch(100)

    <span style="color: #cae682;">validation_dataset</span> = tf.data.Dataset.from_tensor_slices((x_valid.astype(<span style="color: #e5786d;">str</span>), y_valid.astype(<span style="color: #e5786d;">int</span>))).skip(df.shape[0] - df.shape[0]//4)
    <span style="color: #cae682;">validation_dataset</span> = validation_dataset.<span style="color: #e5786d;">map</span>(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x, y: encode_single_sample(x, y), tf.data.experimental.AUTOTUNE)
    <span style="color: #cae682;">validation_dataset</span> = train_dataset.prefetch(100)

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- train ----</span>
    model.fit(train_dataset, epochs=1)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- checks the model's performance</span>
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"evaluate"</span>)
model.evaluate(validation_dataset, verbose=2)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- inferece</span>
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"inference"</span>, x_valid[0], y_valid[0])
<span style="color: #cae682;">im</span>, <span style="color: #cae682;">l</span> = encode_single_sample(x_valid[0], y_valid[0])
<span style="color: #cae682;">im</span> = tf.expand_dims(im, axis=0)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"im"</span>, im.shape)
<span style="color: #cae682;">predictions</span> = model.predict(im, batch_size=1)
<span style="color: #e5786d;">print</span>(np.argmax(predictions))
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"label:"</span>, y_valid[0])

</pre>
</div>
</div>
</li>

<li><a id="org6814ab1"></a>Variable sharding<br />
<div class="outline-text-6" id="text-13-40-4-3-12">
<p>
for very large embeddings that may not fit in a single machine's memory
</p>
</div>
</li>
<li><a id="org687e364"></a>TF<sub>CONFIG</sub><br />
<div class="outline-text-6" id="text-13-40-4-3-13">
<p>
'TF<sub>CONFIG</sub>' environment variable if you use TFConfigClusterResolver.
</p>
</div>
</li>
<li><a id="orgc218d0a"></a>logging steps<br />
<div class="outline-text-6" id="text-13-40-4-3-14">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">train_step</span> = model.train_step
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">my_train_step</span>(data):
    tf.<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"step:"</span>, model._train_counter)
    <span style="color: #8ac6f2; font-weight: bold;">return</span> train_step(data)
model.<span style="color: #cae682;">train_step</span> = my_train_step
</pre>
</div>
</div>
</li>
<li><a id="org2c86608"></a>troubleshooting<br />
<div class="outline-text-6" id="text-13-40-4-3-15">
<ul class="org-ul">
<li>after 1 epoch - TensorFlow device GPU:0 was not registered
<ul class="org-ul">
<li><a href="https://github.com/tensorflow/tensorflow/issues/26208">https://github.com/tensorflow/tensorflow/issues/26208</a></li>
</ul></li>
</ul>

<p>
auto<sub>shard.cc</sub>: AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/<sub>2</sub>"
</p>
<ul class="org-ul">
<li><a href="https://stackoverflow.com/questions/72740907/tensorflow-cant-apply-sharing-policy-file-when-using-mirrored-strategy">https://stackoverflow.com/questions/72740907/tensorflow-cant-apply-sharing-policy-file-when-using-mirrored-strategy</a></li>
<li>dataset = # some dataset</li>
<li>options = tf.data.Options()</li>
<li>options.experimental<sub>distribute.auto</sub><sub>shard</sub><sub>policy</sub> = tf.data.experimental.AutoShardPolicy.FILE</li>
<li>dataset = dataset.with<sub>options</sub>(options)  # use this as input for your model</li>
</ul>


<p>
Attempting to perform BLAS operation using StreamExecutor without BLAS support" error occurs
</p>
<ul class="org-ul">
<li>tf.config.set<sub>logical</sub><sub>device</sub><sub>configuration</sub>(gpus[0],[tf.config.LogicalDeviceConfiguration(memory<sub>limit</sub>=1024)])</li>
</ul>


<p>
NOT<sub>FOUND</sub>: TensorFlow device GPU:1 was not registered - several times after start
</p>
<ul class="org-ul">
<li>all pods should have equal amount of GPU:
<ul class="org-ul">
<li>in YAML: resources: limits: nvidia.com/gpu: 1</li>
<li>tf.compat.v1.ConfigProto(device<sub>count</sub>={'GPU': 1, 'CPU':1}) - for all pods</li>
</ul></li>
</ul>


<p>
SessionOptions: device<sub>count</sub>{key: "CPU", value:1,}, device<sub>count</sub>{key: "GPU", value:0,}
</p>
<ul class="org-ul">
<li>enable GPU at chief and PS</li>
</ul>


<p>
Successful NUMA node read from SysFS had negative value (-1)
</p>
<ul class="org-ul">
<li><a href="https://gist.github.com/zrruziev/b93e1292bf2ee39284f834ec7397ee9f">https://gist.github.com/zrruziev/b93e1292bf2ee39284f834ec7397ee9f</a></li>
<li>apt install pciutils</li>
</ul>
</div>
</li>
<li><a id="orge7e32f1"></a>links<br />
<div class="outline-text-6" id="text-13-40-4-3-16">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/tutorials/distribute/parameter_server_training">https://www.tensorflow.org/tutorials/distribute/parameter_server_training</a>
<ul class="org-ul">
<li><a href="https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb">https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb</a></li>
</ul></li>
<li>article tfv1.0 <a href="https://support.huawei.com/enterprise/en/doc/EDOC1100164821/704ae7ed/distributed-training-based-on-the-ps-worker-architecture">https://support.huawei.com/enterprise/en/doc/EDOC1100164821/704ae7ed/distributed-training-based-on-the-ps-worker-architecture</a></li>
<li>keras faq <a href="https://keras.io/getting_started/faq/#how-can-i-distribute-training-across-multiple-machines">https://keras.io/getting_started/faq/#how-can-i-distribute-training-across-multiple-machines</a></li>
<li>keras distrib <a href="https://keras.io/guides/distributed_training/">https://keras.io/guides/distributed_training/</a></li>
<li>TF input for distributed training <a href="https://www.tensorflow.org/tutorials/distribute/input">https://www.tensorflow.org/tutorials/distribute/input</a></li>
<li>ps example <a href="https://github.com/tensorflow/tensorflow/issues/57694">https://github.com/tensorflow/tensorflow/issues/57694</a></li>
<li>explanation 2014 <a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf">https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf</a></li>
<li><a id="org3e365c7"></a><a href="https://habr.com/ru/companies/wunderfund/articles/663104/">https://habr.com/ru/companies/wunderfund/articles/663104/</a></li>
</ul>
</div>
</li>
</ol>
</li>
</ol>
</div>
<div id="outline-container-org924aa92" class="outline-4">
<h4 id="org924aa92"><span class="section-number-4">13.40.5.</span> TF<sub>CONFIG</sub></h4>
<div class="outline-text-4" id="text-13-40-5">
<p>
'TF<sub>CONFIG</sub>' environment variable is a JSON string
</p>
<ul class="org-ul">
<li>what tasks constitute a cluster</li>
<li>their addresses</li>
<li>each task's role in the cluster</li>
</ul>
</div>
</div>
<div id="outline-container-org581f4dd" class="outline-4">
<h4 id="org581f4dd"><span class="section-number-4">13.40.6.</span> data sharding</h4>
<div class="outline-text-4" id="text-13-40-6">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/tutorials/distribute/keras">https://www.tensorflow.org/tutorials/distribute/keras</a></li>
<li><a href="https://www.tensorflow.org/tutorials/distribute/input">https://www.tensorflow.org/tutorials/distribute/input</a></li>
<li><a href="https://www.tensorflow.org/guide/distributed_training">https://www.tensorflow.org/guide/distributed_training</a></li>
</ul>

<p>
tf.data.experimental.AutoShardPolicy
</p>
<ul class="org-ul">
<li>AUTO or FILE -  tf.data.Dataset that reads from files.</li>
</ul>


<p>
Note: tf.data.experimental.AutoShardPolicy.FILE - the actual per-step batch size may be smaller than the one
 you defined for the global batch size - when the remaining elements in the file are less than the global
 batch size
</p>
</div>
</div>

<div id="outline-container-org28877cb" class="outline-4">
<h4 id="org28877cb"><span class="section-number-4">13.40.7.</span> links</h4>
<div class="outline-text-4" id="text-13-40-7">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/guide/distributed_training">https://www.tensorflow.org/guide/distributed_training</a></li>
<li>kubernetes template for TF <a href="https://github.com/tensorflow/ecosystem/tree/master/kubernetes">https://github.com/tensorflow/ecosystem/tree/master/kubernetes</a></li>
<li>strategies <a href="https://habr.com/ru/companies/wunderfund/articles/663104/">https://habr.com/ru/companies/wunderfund/articles/663104/</a></li>
</ul>
</div>
</div>
<div id="outline-container-org931e299" class="outline-4">
<h4 id="org931e299"><span class="section-number-4">13.40.8.</span> monitor</h4>
<div class="outline-text-4" id="text-13-40-8">
</div>
<ol class="org-ol">
<li><a id="orgca2d200"></a>chargpt<br />
<div class="outline-text-5" id="text-13-40-8-1">
<ol class="org-ol">
<li>TensorFlow Extended (TFX): TFX provides a comprehensive end-to-end pipeline for building,</li>
</ol>
<p>
training, and deploying machine learning models. It includes components for monitoring the model
training process and tracking model metrics during training.
</p>

<ol class="org-ol">
<li>TensorBoard: TensorBoard is a web-based tool provided by TensorFlow that allows you to</li>
</ol>
<p>
visualize and monitor various aspects of your model training, such as loss, accuracy, and
computational graphs. It can be integrated with Kubernetes to monitor the training process
running on the cluster.
</p>

<ol class="org-ol">
<li>Kubernetes Dashboard: The Kubernetes dashboard is a web-based user interface that provides a</li>
</ol>
<p>
visual representation of the cluster, including information about deployments, pods, jobs, and
other resources. It can be used to monitor the status and progress of the neural network training
on the Kubernetes cluster.
</p>

<ol class="org-ol">
<li>Prometheus and Grafana: Prometheus is a popular open-source monitoring and alerting platform</li>
</ol>
<p>
that can be used to collect and store metrics from your TensorFlow cluster. Grafana is a
visualization and analytics tool that can be integrated with Prometheus to create customizable
dashboards for monitoring and analyzing training metrics.
</p>

<ol class="org-ol">
<li>KubeFlow: KubeFlow is an open-source project that provides a platform for end-to-end machine</li>
</ol>
<p>
learning workflows on Kubernetes. It includes components for model training, hyperparameter
tuning, model packaging, and serving. KubeFlow also provides monitoring capabilities to track the
progress of your model training and performance metrics.
</p>
</div>
</li>

<li><a id="org5470ad0"></a><span class="todo TODO">TODO</span> tensorboard<br /></li>
</ol>
</div>
</div>
<div id="outline-container-orgfaa94ab" class="outline-3">
<h3 id="orgfaa94ab"><span class="section-number-3">13.41.</span> toy model MNIST</h3>
<div class="outline-text-3" id="text-13-41">
<p>
#+NAME <a href="https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras">https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras</a>
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">as</span> tf
<span style="color: #cae682;">mnist</span> = tf.keras.datasets.mnist

(x_train, y_train), (<span style="color: #cae682;">x_test</span>, <span style="color: #cae682;">y_test</span>) = mnist.load_data()
<span style="color: #cae682;">x_train</span>, <span style="color: #cae682;">x_test</span> = x_train / 255.0, x_test / 255.0
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- dataset</span>
<span style="color: #cae682;">batch_size</span>=16
<span style="color: #cae682;">train_dataset</span> = tf.data.Dataset.from_tensor_slices((x_train, y_train))
<span style="color: #cae682;">train_dataset</span> = train_dataset.shuffle(60000).repeat().batch(batch_size)
<span style="color: #cae682;">validation_dataset</span> = tf.data.Dataset.from_tensor_slices((x_test, y_test))
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- model</span>
<span style="color: #cae682;">model</span> = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation=<span style="color: #95e454;">'relu'</span>),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])

<span style="color: #cae682;">loss_fn</span> = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span style="color: #e5786d; font-weight: bold;">True</span>)
model.<span style="color: #e5786d;">compile</span>(optimizer=<span style="color: #95e454;">'adam'</span>,
              loss=loss_fn,
              metrics=[<span style="color: #95e454;">'accuracy'</span>])

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- train</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">model.fit(x_train, y_train, epochs=5)</span>
model.fit(train_dataset, epochs=5, steps_per_epoch=200)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- checks the model's performance</span>
model.evaluate(x_test,  y_test, verbose=2)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- inferece</span>
<span style="color: #cae682;">predictions</span> = model(x_train[:1]).numpy()
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #e5786d;">print</span>(np.argmax(predictions))
<span style="color: #e5786d;">print</span>(y_train[:1])
</pre>
</div>
</div>
</div>
<div id="outline-container-org6fab8e5" class="outline-3">
<h3 id="org6fab8e5"><span class="section-number-3">13.42.</span> logging</h3>
<div class="outline-text-3" id="text-13-42">
<p>
<a href="https://stackoverflow.com/questions/40559667/how-to-redirect-tensorflow-logging-to-a-file">https://stackoverflow.com/questions/40559667/how-to-redirect-tensorflow-logging-to-a-file</a>
</p>

<p>
tf.keras.utils.enable<sub>interactive</sub><sub>logging</sub>() When interactive logging is enabled, Keras displays logs via
 stdout. This provides the best experience when using Keras in an interactive environment such as a shell or a
 notebook.
</p>

<p>
tensor:
</p>
<ul class="org-ul">
<li>tf.debugging</li>
<li>tf.print</li>
</ul>

<p>
log:
</p>
<ul class="org-ul">
<li>tf.get<sub>logger</sub>() return logging.getLogger('tensorflow')</li>
</ul>
</div>

<div id="outline-container-orgcc8d148" class="outline-4">
<h4 id="orgcc8d148"><span class="section-number-4">13.42.1.</span> standard way</h4>
<div class="outline-text-4" id="text-13-42-1">
<p>
<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/tf_logging.py">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/tf_logging.py</a>
</p>
</div>
</div>

<div id="outline-container-org013b630" class="outline-4">
<h4 id="org013b630"><span class="section-number-4">13.42.2.</span> pipe</h4>
<div class="outline-text-4" id="text-13-42-2">
<p>
<b>script</b> allow get full output
</p>
<pre class="example">
script -c 'python -i &lt;&lt;&lt; "print \"test\""'
</pre>


<p>
freezing at tree: disable buffering:
</p>
<ul class="org-ul">
<li>sed -u</li>
<li>grep &#x2013;line-buffered</li>
<li>perl -ne 'use IO::Handle ; printf "%s %s",  scalar time(), $_ ; STDOUT-&gt;autoflush(1)'</li>
</ul>
</div>
</div>
<div id="outline-container-orgc5d0332" class="outline-4">
<h4 id="orgc5d0332"><span class="section-number-4">13.42.3.</span> logging</h4>
<div class="outline-text-4" id="text-13-42-3">
<p>
import logging
</p>

<p>
log = logging.getLogger('tensorflow')
log.setLevel(logging.DEBUG)
</p>

<p>
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
</p>

<p>
fh = logging.FileHandler('tensorflow.log')
fh.setLevel(logging.DEBUG)
fh.setFormatter(formatter)
log.addHandler(fh)
</p>
</div>
</div>

<div id="outline-container-orgb370170" class="outline-4">
<h4 id="orgb370170"><span class="section-number-4">13.42.4.</span> links</h4>
<div class="outline-text-4" id="text-13-42-4">
<p>
<a href="https://towardsdatascience.com/debugging-in-tensorflow-392b193d0b8?gi=05647b21a117">https://towardsdatascience.com/debugging-in-tensorflow-392b193d0b8?gi=05647b21a117</a>
</p>
</div>
</div>
</div>
<div id="outline-container-org521ea95" class="outline-3">
<h3 id="org521ea95"><span class="section-number-3">13.43.</span> callbacks for model.fit</h3>
</div>

<div id="outline-container-orgb0d82ec" class="outline-3">
<h3 id="orgb0d82ec"><span class="section-number-3">13.44.</span> USE CASES</h3>
<div class="outline-text-3" id="text-13-44">
</div>
<div id="outline-container-org2e84d9e" class="outline-4">
<h4 id="org2e84d9e"><span class="section-number-4">13.44.1.</span> TF 2.0 convert mode h5 to weight and arch</h4>
<div class="outline-text-4" id="text-13-44-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> tensorflow <span style="color: #8ac6f2; font-weight: bold;">import</span> keras
<span style="color: #8ac6f2; font-weight: bold;">from</span> tensorflow.keras.models <span style="color: #8ac6f2; font-weight: bold;">import</span> Model
<span style="color: #8ac6f2; font-weight: bold;">import</span> os
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">use CPU</span>
os.<span style="color: #cae682;">environ</span>[<span style="color: #95e454;">'CUDA_VISIBLE_DEVICES'</span>] = <span style="color: #95e454;">'-1'</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">parent_path = os.path.join(os.getcwd(), os.pardir)</span>
<span style="color: #cae682;">model_path</span> = <span style="color: #95e454;">'/mnt/hit4/hit4user/PycharmProjects/cnn/text_or_not/saved_models/cnn_trained_model2020-09-10 09:26:34.553480.h5'</span>
<span style="color: #e5786d;">print</span>(model_path)

<span style="color: #cae682;">model</span>: Model = keras.models.load_model(model_path)
<span style="color: #8ac6f2; font-weight: bold;">import</span> time

<span style="color: #cae682;">name</span> = <span style="color: #95e454;">'cnn_trained_model2020-09-10 09:26:34.553480'</span>
os.mkdir(name)


<span style="color: #8ac6f2; font-weight: bold;">with</span> <span style="color: #e5786d;">open</span>(<span style="color: #95e454;">"./"</span>+name+<span style="color: #95e454;">"/model_to_json.json"</span>, <span style="color: #95e454;">"w"</span>) <span style="color: #8ac6f2; font-weight: bold;">as</span> json_file:
    json_file.write(model.to_json(indent=4))

model.save_weights(<span style="color: #95e454;">'./'</span>+name+<span style="color: #95e454;">'/'</span>)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"ok"</span>)
time.sleep(1)
</pre>
</div>
</div>
</div>

<div id="outline-container-orgb192f3b" class="outline-4">
<h4 id="orgb192f3b"><span class="section-number-4">13.44.2.</span> imbalanced dataset</h4>
<div class="outline-text-4" id="text-13-44-2">
<p>
strategy:
</p>
<ul class="org-ul">
<li>oversample min to half of max</li>
<li>apply class<sub>weight</sub></li>
</ul>
</div>

<ol class="org-ol">
<li><a id="org069f8a7"></a>class<sub>weight</sub><br />
<div class="outline-text-5" id="text-13-44-2-1">
<p>
for binary:
</p>
<pre class="example">
weight_for_0 = (1 / neg) * (total / 2.0)
weight_for_1 = (1 / pos) * (total / 2.0)
class_weight = {0: weight_for_0, 1: weight_for_1}
</pre>


<p>
for n-classes:
</p>
<pre class="example">
n_samples / (n_classes * np.bincount(y))
</pre>

<ul class="org-ul">
<li>n<sub>samples</sub> is the total number of instances</li>
<li>n<sub>classes</sub> is the number of classes</li>
<li>np.bincount(y) is an array of the number of instances in each class</li>
</ul>

<p>
apply weights:
</p>
<div class="org-src-container">
<pre class="src src-python">
</pre>
</div>
<pre class="example">
n_classes = sorted(set(y))
n_samples = len(xy)
n_samples / (n_classes * np.bincount(y))
model.fit(class_weight=class_weight)
</pre>


<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">y</span> = [0]*5 + [1]*2 + [2]*5
<span style="color: #cae682;">y</span> = np.array(y)
<span style="color: #cae682;">x</span> = np.array(<span style="color: #e5786d;">list</span>(<span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(y))))
<span style="color: #cae682;">xy</span>= np.vstack([x,y]).transpose()
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(xy)</span>
<span style="color: #cae682;">classes</span> = <span style="color: #e5786d;">sorted</span>(<span style="color: #e5786d;">set</span>(y))
<span style="color: #cae682;">n_classes</span> = <span style="color: #e5786d;">len</span>(classes)
<span style="color: #cae682;">n_samples</span> = <span style="color: #e5786d;">len</span>(xy)
<span style="color: #e5786d;">print</span>(n_samples)
<span style="color: #e5786d;">print</span>(n_classes)
<span style="color: #e5786d;">print</span>(np.bincount(y))
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">y</span> = np.array(y)
<span style="color: #cae682;">weights</span> = n_samples / (n_classes * np.bincount(y))
<span style="color: #cae682;">class_weight</span> = {c:w <span style="color: #8ac6f2; font-weight: bold;">for</span> c,w <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">zip</span>(classes, weights)}
<span style="color: #e5786d;">print</span>(class_weight)
</pre>
</div>

<pre class="example">
12
3
[5 2 5]
{0: 0.8, 1: 2.0, 2: 0.8}
</pre>


<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">y</span> = [0]*100 + [1]*10 + [2]*300
<span style="color: #cae682;">u</span> = <span style="color: #e5786d;">sorted</span>(<span style="color: #e5786d;">set</span>(y))
<span style="color: #cae682;">n_classes</span>=3
<span style="color: #cae682;">n_samples</span>=<span style="color: #e5786d;">len</span>(y)
<span style="color: #cae682;">w</span> = n_samples / (n_classes * np.bincount(y))
<span style="color: #cae682;">class_weight</span> = {x:y <span style="color: #8ac6f2; font-weight: bold;">for</span> x, y <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">zip</span>(u, w)}
<span style="color: #e5786d;">print</span>(np.bincount(y), <span style="color: #95e454;">"- np.bincount(y) first sort ASC"</span>)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"unique"</span>, u)
<span style="color: #e5786d;">print</span>(class_weight)
</pre>
</div>

<pre class="example">
[100  10 300] - np.bincount(y) first sort ASC
unique [0, 1, 2]
{0: 1.3666666666666667, 1: 13.666666666666666, 2: 0.45555555555555555}
</pre>
</div>
</li>

<li><a id="org7537a8c"></a>numpy choose, oversampling<br />
<div class="outline-text-5" id="text-13-44-2-2">
<p>
<a href="https://stackoverflow.com/questions/23391608/balance-numpy-array-with-over-sampling">https://stackoverflow.com/questions/23391608/balance-numpy-array-with-over-sampling</a>
</p>
</div>
<ol class="org-ol">
<li><a id="orga2b985c"></a>1<br />
<div class="outline-text-6" id="text-13-44-2-2-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">y</span> = [0]*100 + [1]*10 + [2]*300
<span style="color: #cae682;">u</span> = <span style="color: #e5786d;">sorted</span>(<span style="color: #e5786d;">set</span>(y))
<span style="color: #e5786d;">print</span>(np.bincount(y), <span style="color: #95e454;">"- np.bincount(y) first sort ASC"</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- oversampling</span>
<span style="color: #cae682;">distrib</span> = np.bincount(y)
<span style="color: #cae682;">prob</span> = 1/distrib[y].astype(<span style="color: #e5786d;">float</span>)
<span style="color: #cae682;">prob</span> /= prob.<span style="color: #e5786d;">sum</span>()

<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"distrib ="</span>, distrib, distrib[y])
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"a ="</span>, np.arange(<span style="color: #e5786d;">len</span>(y)))
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"count after(size) ="</span>, np.count_nonzero(distrib)*distrib.<span style="color: #e5786d;">max</span>())
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"prob ="</span>, prob)
<span style="color: #cae682;">sel</span> = np.random.choice(np.arange(<span style="color: #e5786d;">len</span>(y)), size=np.count_nonzero(distrib)*distrib.<span style="color: #e5786d;">max</span>(), p=prob).astype(<span style="color: #e5786d;">int</span>)
<span style="color: #cae682;">y</span> = np.array(y)
<span style="color: #e5786d;">print</span>(y[np.random.choice(np.arange(<span style="color: #e5786d;">len</span>(y)), size=np.count_nonzero(distrib)*distrib.<span style="color: #e5786d;">max</span>(), p=prob)])
<span style="color: #e5786d;">print</span>(np.bincount(y[sel]))
</pre>
</div>

<pre class="example" id="orge143395">
[100  10 300] - np.bincount(y) first sort ASC
distrib = [100  10 300] [100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100
 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100
 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100
 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100
 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100
 100 100 100 100 100 100 100 100 100 100  10  10  10  10  10  10  10  10
  10  10 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300
 300 300 300 300 300 300 300 300 300 300 300 300 300 300]
a = [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409]
count after(size) = 900
prob = [0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333 0.00333333
 0.00333333 0.00333333 0.00333333 0.00333333 0.03333333 0.03333333
 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
 0.03333333 0.03333333 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111 0.00111111
 0.00111111 0.00111111]
[2 0 0 2 1 1 2 1 2 0 0 2 1 0 0 0 2 0 1 1 1 2 0 2 1 1 2 2 0 1 0 2 0 1 0 2 0
 2 1 1 0 1 1 1 1 0 2 2 2 1 0 2 0 1 0 0 1 2 1 0 2 1 2 1 0 0 1 1 2 1 2 2 1 2
 2 0 2 1 0 1 1 1 0 0 0 1 2 1 2 1 0 2 2 1 1 2 1 2 1 1 0 1 0 2 2 1 2 2 2 1 2
 0 0 0 0 2 1 2 1 0 0 1 2 2 2 1 2 1 0 0 1 2 1 2 0 0 0 0 2 0 2 1 2 2 2 2 0 2
 2 1 0 0 0 0 2 1 1 2 1 1 0 2 2 2 0 2 2 1 2 2 2 2 2 2 1 0 2 2 0 2 0 1 1 2 2
 2 1 2 1 2 0 1 1 1 1 1 2 0 0 0 1 2 2 2 1 2 2 1 2 1 2 1 2 0 0 0 2 1 2 1 1 2
 0 1 2 2 0 2 1 1 0 2 0 2 0 1 0 0 2 0 2 0 1 0 2 0 1 2 2 0 0 0 1 0 0 1 0 0 0
 2 1 0 2 0 1 2 0 0 1 0 1 1 0 1 2 2 1 0 0 1 0 2 2 2 0 0 2 2 1 2 0 2 1 0 2 0
 2 0 1 0 1 1 0 2 0 1 1 1 0 0 0 0 1 0 1 0 1 2 0 0 0 0 2 0 0 0 2 0 1 2 0 2 1
 1 1 0 1 0 2 1 0 2 1 0 2 1 2 2 0 2 0 1 2 0 1 1 1 2 2 0 0 2 0 1 1 0 2 1 2 1
 0 0 2 1 0 2 0 2 0 2 2 0 0 1 2 0 2 0 1 1 1 0 2 1 2 2 1 0 1 2 0 2 2 1 2 1 2
 0 1 1 2 2 2 1 1 1 1 2 1 0 0 1 1 1 2 2 1 0 0 0 2 1 1 2 0 1 2 1 0 0 2 1 0 2
 2 1 2 0 1 1 0 1 1 1 0 1 2 2 2 2 1 1 2 0 1 1 1 1 0 2 2 0 2 0 2 1 2 1 2 2 0
 1 2 1 0 0 0 0 1 1 1 0 2 0 2 0 2 1 1 2 2 1 1 2 2 1 2 2 1 1 0 2 1 2 0 1 0 1
 0 2 0 2 1 2 2 0 1 2 1 1 1 1 2 0 0 0 2 1 2 2 0 1 2 1 2 0 0 0 2 1 2 0 1 0 0
 0 1 0 2 1 0 0 2 1 1 1 1 0 1 2 2 2 1 2 2 2 0 0 0 0 0 1 1 2 0 2 0 1 0 0 0 1
 1 0 2 2 2 2 0 2 1 2 1 1 1 1 2 2 0 0 1 1 0 0 2 2 2 0 1 2 2 1 0 2 1 1 0 0 1
 0 1 2 2 1 1 0 0 1 0 2 1 2 2 1 1 2 1 2 2 2 2 0 2 1 1 0 1 1 2 1 1 1 0 0 0 0
 2 2 1 0 2 2 1 1 0 2 1 2 2 0 2 0 0 2 0 1 2 2 1 0 1 2 2 0 0 1 1 0 2 0 2 2 1
 0 2 2 2 0 0 1 0 2 2 1 1 1 2 0 1 2 0 0 1 2 0 1 0 2 1 0 1 1 2 0 1 2 2 2 2 2
 2 2 0 2 0 0 1 1 1 0 0 2 0 1 0 0 1 1 2 0 2 0 1 1 2 0 1 0 1 2 1 1 0 2 0 0 0
 0 0 1 2 0 0 1 0 0 0 1 0 1 0 0 1 1 0 2 2 2 2 2 0 1 0 0 0 1 2 2 0 0 1 1 0 1
 0 0 0 1 1 2 0 0 2 0 0 0 1 0 1 2 2 2 0 1 1 0 0 2 0 0 1 0 0 1 1 2 2 2 1 1 2
 1 1 2 2 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 2 0 2 1 1 1 0 0 2 1 2 1 1 2 0 1 0
 2 2 2 0 0 0 0 0 0 2 2 1]
[328 284 288]
</pre>
</div>
</li>
<li><a id="orgba8c4b3"></a>2<br />
<ol class="org-ol">
<li><a id="org8c2c901"></a>simple 1d arrays<br />
<div class="outline-text-7" id="text-13-44-2-2-2-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">y</span> = [0]*5 + [1]*2 + [2]*10
<span style="color: #cae682;">y</span> = np.array(y)
<span style="color: #cae682;">x</span> = np.array(<span style="color: #e5786d;">list</span>(<span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(y))))
<span style="color: #cae682;">xy</span>= np.vstack([x,y]).transpose()
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---------------------</span>
<span style="color: #cae682;">unq</span>, <span style="color: #cae682;">unq_idx</span> = np.unique(y, return_inverse=<span style="color: #e5786d; font-weight: bold;">True</span>)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"unq, unq_idx"</span>, unq, unq_idx)
<span style="color: #cae682;">unq_cnt</span> = np.bincount(unq_idx)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"unq_cnt"</span>, unq_cnt)
<span style="color: #e5786d;">min</span> = np.<span style="color: #e5786d;">min</span>(unq_cnt)
<span style="color: #e5786d;">max</span> = np.<span style="color: #e5786d;">max</span>(unq_cnt)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"max"</span>, <span style="color: #e5786d;">max</span>, <span style="color: #95e454;">"min"</span>, <span style="color: #e5786d;">min</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">cnt = round((max - min)/2 + min)</span>
<span style="color: #cae682;">cnt</span> = <span style="color: #e5786d;">max</span>
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cnt"</span>, cnt)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"y.shape[1:]"</span>, y.shape[1:])
<span style="color: #cae682;">out</span> = np.empty((cnt*<span style="color: #e5786d;">len</span>(unq) - <span style="color: #e5786d;">len</span>(y),), y.dtype)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;"># out = np.empty((cnt*len(unq) - len(xy),) + xy.shape[1:], xy.dtype)</span>
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"out.shape"</span>, out.shape, <span style="color: #95e454;">"xy.shape"</span>, xy.shape)
<span style="color: #cae682;">slices</span> = np.concatenate(([0], np.cumsum(cnt - unq_cnt)))
<span style="color: #e5786d;">print</span>(slices)
<span style="color: #8ac6f2; font-weight: bold;">for</span> j <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(unq)):
    <span style="color: #cae682;">indices</span> = np.random.choice(np.where(unq_idx==j)[0], cnt - unq_cnt[j])
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"indices"</span>, indices)
    out[slices[j]:slices[j+1]] = y[indices]
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"out"</span>, out)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">out = np.hstack((y, out))</span>
<span style="color: #e5786d;">print</span>(out)
<span style="color: #e5786d;">print</span>(np.bincount(out), <span style="color: #95e454;">"- np.bincount(out) first sort ASC"</span>)
</pre>
</div>

<pre class="example" id="org93dc197">
unq, unq_idx [0 1 2] [0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 2 2]
unq_cnt [ 5  2 10]
max 10 min 2
cnt 10
y.shape[1:] ()
out.shape (13,) xy.shape (17, 2)
[ 0  5 13 13]
indices [0 4 0 4 4]
out [                 0                  0                  0
                  0                  0    140160696704256
    140160713380912    140160696704416    140160696541680
     94915202709280                  0 172834964494878845
                240]
indices [6 6 5 6 5 5 5 6]
out [0 0 0 0 0 1 1 1 1 1 1 1 1]
indices []
out [0 0 0 0 0 1 1 1 1 1 1 1 1]
[0 0 0 0 0 1 1 1 1 1 1 1 1]
[5 8] - np.bincount(out) first sort ASC
</pre>
</div>
</li>

<li><a id="org6ab78ac"></a>simple xy<br />
<div class="outline-text-7" id="text-13-44-2-2-2-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">y</span> = [0]*5 + [1]*2 + [2]*10
<span style="color: #cae682;">y</span> = np.array(y)
<span style="color: #cae682;">x</span> = np.array(<span style="color: #e5786d;">list</span>(<span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(y))))
<span style="color: #cae682;">xy</span>= np.vstack([x,y]).transpose()
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---------------------</span>
<span style="color: #cae682;">unq</span>, <span style="color: #cae682;">unq_idx</span> = np.unique(y, return_inverse=<span style="color: #e5786d; font-weight: bold;">True</span>)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"unq, unq_idx"</span>, unq, unq_idx)
<span style="color: #cae682;">unq_cnt</span> = np.bincount(unq_idx)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"unq_cnt"</span>, unq_cnt)
<span style="color: #cae682;">cnt</span> = np.<span style="color: #e5786d;">max</span>(unq_cnt)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cnt"</span>, cnt)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"y.shape[1:]"</span>, y.shape[1:])
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">out = np.empty((cnt*len(unq) - len(y),), y.dtype)</span>
<span style="color: #cae682;">out</span> = np.empty((cnt*<span style="color: #e5786d;">len</span>(unq) - <span style="color: #e5786d;">len</span>(xy),) + xy.shape[1:], xy.dtype)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"out.shape"</span>, out.shape, <span style="color: #95e454;">"xy.shape"</span>, xy.shape)
<span style="color: #cae682;">slices</span> = np.concatenate(([0], np.cumsum(cnt - unq_cnt)))
<span style="color: #e5786d;">print</span>(slices)
<span style="color: #8ac6f2; font-weight: bold;">for</span> j <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(unq)):
    <span style="color: #cae682;">indices</span> = np.random.choice(np.where(unq_idx==j)[0], cnt - unq_cnt[j])
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"indices"</span>, indices)
    out[slices[j]:slices[j+1]] = xy[indices]
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"out"</span>, out)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">out = np.hstack((y, out))</span>
<span style="color: #e5786d;">print</span>(out)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(np.bincount(out), "- np.bincount(out) first sort ASC")</span>
</pre>
</div>

<pre class="example" id="org57349d2">
unq, unq_idx [0 1 2] [0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 2 2]
unq_cnt [ 5  2 10]
cnt 10
y.shape[1:] ()
out.shape (13, 2) xy.shape (17, 2)
[ 0  5 13 13]
indices [2 3 3 2 4]
out [[2 0]
 [3 0]
 [3 0]
 [2 0]
 [4 0]
 [0 0]
 [0 0]
 [0 0]
 [0 0]
 [0 0]
 [0 0]
 [0 0]
 [0 0]]
indices [6 6 6 5 5 5 5 6]
out [[2 0]
 [3 0]
 [3 0]
 [2 0]
 [4 0]
 [6 1]
 [6 1]
 [6 1]
 [5 1]
 [5 1]
 [5 1]
 [5 1]
 [6 1]]
indices []
out [[2 0]
 [3 0]
 [3 0]
 [2 0]
 [4 0]
 [6 1]
 [6 1]
 [6 1]
 [5 1]
 [5 1]
 [5 1]
 [5 1]
 [6 1]]
[[2 0]
 [3 0]
 [3 0]
 [2 0]
 [4 0]
 [6 1]
 [6 1]
 [6 1]
 [5 1]
 [5 1]
 [5 1]
 [5 1]
 [6 1]]
</pre>
</div>
</li>

<li><a id="org4eeb3a3"></a>full<br />
<div class="outline-text-7" id="text-13-44-2-2-2-3">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---------------------</span>
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">calc_oversampl</span>(xy):
    <span style="color: #cae682;">unq</span>, <span style="color: #cae682;">unq_idx</span> = np.unique(xy[:, -1], return_inverse=<span style="color: #e5786d; font-weight: bold;">True</span>)
    <span style="color: #cae682;">unq_cnt</span> = np.bincount(unq_idx)
    <span style="color: #cae682;">cnt</span> = np.<span style="color: #e5786d;">max</span>(unq_cnt)
    <span style="color: #cae682;">out</span> = np.empty((cnt*<span style="color: #e5786d;">len</span>(unq) - <span style="color: #e5786d;">len</span>(xy),) + xy.shape[1:], xy.dtype)
    <span style="color: #cae682;">slices</span> = np.concatenate(([0], np.cumsum(cnt - unq_cnt)))
    <span style="color: #8ac6f2; font-weight: bold;">for</span> j <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(unq)):
        <span style="color: #cae682;">indices</span> = np.random.choice(np.where(unq_idx==j)[0], cnt - unq_cnt[j])
        out[slices[j]:slices[j+1]] = xy[indices]
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(out)</span>
    <span style="color: #8ac6f2; font-weight: bold;">return</span> np.vstack((xy, v))

<span style="color: #cae682;">out</span> = [0]*5 + [1]*2 + [2]*1
<span style="color: #cae682;">v</span> = np.array(v)
<span style="color: #cae682;">x</span> = np.array(<span style="color: #e5786d;">list</span>(<span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(v))))
<span style="color: #cae682;">xy</span>= np.vstack([x,v]).transpose()
<span style="color: #e5786d;">print</span>(xy)
<span style="color: #e5786d;">print</span>(np.bincount(xy[:,1]))
<span style="color: #cae682;">out</span> = calc_oversampl(xy)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(out)</span>
<span style="color: #e5786d;">print</span>(np.bincount(out[:,1]))
</pre>
</div>

<pre class="example" id="org9df4c53">
[[0 0]
 [1 0]
 [2 0]
 [3 1]
 [4 0]
 [5 1]
 [6 2]
 [7 0]
 [8 0]
 [9 0]]
[7 2 1]
[7 7 7]
</pre>
</div>
</li>
<li><a id="orgf97acd1"></a>half<br />
<div class="outline-text-7" id="text-13-44-2-2-2-4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">oversample</span>(xy, maxc=<span style="color: #e5786d; font-weight: bold;">None</span>):
    <span style="color: #cae682;">unq</span>, <span style="color: #cae682;">unq_idx</span> = np.unique(xy[:, -1], return_inverse=<span style="color: #e5786d; font-weight: bold;">True</span>)
    <span style="color: #cae682;">unq_cnt</span> = np.bincount(unq_idx)
    <span style="color: #8ac6f2; font-weight: bold;">if</span> maxc:
        <span style="color: #cae682;">cnt</span> = maxc
    <span style="color: #8ac6f2; font-weight: bold;">else</span>:
        <span style="color: #cae682;">cnt</span> = np.<span style="color: #e5786d;">max</span>(unq_cnt)
    <span style="color: #cae682;">out</span> = np.empty((cnt*<span style="color: #e5786d;">len</span>(unq) - <span style="color: #e5786d;">len</span>(xy),) + xy.shape[1:], xy.dtype)
    <span style="color: #cae682;">slices</span> = np.concatenate(([0], np.cumsum(cnt - unq_cnt)))
    <span style="color: #8ac6f2; font-weight: bold;">for</span> j <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(<span style="color: #e5786d;">len</span>(unq)):
        <span style="color: #cae682;">indices</span> = np.random.choice(np.where(unq_idx==j)[0], cnt - unq_cnt[j])
        out[slices[j]:slices[j+1]] = xy[indices]
    <span style="color: #8ac6f2; font-weight: bold;">return</span> np.vstack((xy, out))


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">oversamples_half</span>(xy):
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- separate part of xy with classes which count of examples &gt; max(count of examples)//2</span>
    <span style="color: #cae682;">unq</span>, <span style="color: #cae682;">unq_idx</span> = np.unique(xy[:, -1].astype(<span style="color: #e5786d;">int</span>), return_inverse=<span style="color: #e5786d; font-weight: bold;">True</span>)
    <span style="color: #cae682;">unq_cnt</span> = np.bincount(unq_idx)
    <span style="color: #cae682;">cnt_half</span> = np.<span style="color: #e5786d;">max</span>(unq_cnt) //2
    <span style="color: #cae682;">use_u</span> = unq[unq_cnt&lt;cnt_half]
    <span style="color: #cae682;">use_i</span> = np.vectorize(<span style="color: #8ac6f2; font-weight: bold;">lambda</span> x: x <span style="color: #8ac6f2; font-weight: bold;">in</span> use_u)(xy[:,-1])
    <span style="color: #cae682;">use</span> = xy[use_i]
    <span style="color: #cae682;">not_use</span> = xy[~use_i]
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print("use", np.bincount(use[:,1].astype(int)))</span>
    <span style="color: #cae682;">out</span> = oversample(use, maxc=cnt_half)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print("out", np.bincount(out[:,1].astype(int)))</span>
    <span style="color: #8ac6f2; font-weight: bold;">return</span> np.vstack((out, not_use))

<span style="color: #cae682;">xy</span> = np.array(
[[0,0],
[1,0],
[2,0],
[3,1],
[4,0],
[5,1],
[6,3],
[7,0],
[8,0],
[9,0]]
)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">xy[:,1].astype(int)</span>
<span style="color: #e5786d;">print</span>(np.bincount(xy[:,1].astype(<span style="color: #e5786d;">int</span>)))
<span style="color: #cae682;">out</span> = calc_oversamples_half(xy)
<span style="color: #e5786d;">print</span>(np.bincount(out[:,1].astype(<span style="color: #e5786d;">int</span>)))
<span style="color: #e5786d;">print</span>(out)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(np.bincount(out[:,1].astype(int)))</span>
</pre>
</div>

<pre class="example" id="org4ec5f49">
[7 2 0 1]
use [0 2 0 1]
out [0 3 0 3]
[7 3 0 3]
[[3 1]
 [5 1]
 [6 3]
 [3 1]
 [6 3]
 [6 3]
 [0 0]
 [1 0]
 [2 0]
 [4 0]
 [7 0]
 [8 0]
 [9 0]]
</pre>
</div>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</div>
</div>

<div id="outline-container-org0d6f113" class="outline-3">
<h3 id="org0d6f113"><span class="section-number-3">13.45.</span> common errors:</h3>
<div class="outline-text-3" id="text-13-45">
<p>
ValueError: Input 0 of layer "model" is incompatible with the layer: expected shape=(None, 200, 60, 1), found shape=(None, 60, 1)
</p>
<ul class="org-ul">
<li>print(type(input))</li>
<li>input: class =</li>
<li>tf.expand<sub>dims</sub>(encsample["image"], axis=0)</li>
</ul>

<p>
tf.data.Dataset	data = next(iterator)	Cannot add tensor to the batch: number of elemets does not match. Shapes are: [tensor]: [4], [batch]: [5]
</p>
<ul class="org-ul">
<li>solutions:
<ul class="org-ul">
<li>.padded<sub>patch</sub></li>
<li>.apply(tf.data.experimental.dense<sub>to</sub><sub>ragged</sub><sub>batch</sub>(&#x2026;))</li>
</ul></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org2b60174" class="outline-2">
<h2 id="org2b60174"><span class="section-number-2">14.</span> PyTorch</h2>
<div class="outline-text-2" id="text-14">
<p>
<a href="data_science#MissingReference">data_science#MissingReference</a>
install: <a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>
examples <a href="https://github.com/pytorch/examples/">https://github.com/pytorch/examples/</a>
</p>
<ul class="org-ul">
<li>GPU Tensors, Dynamic Neural Networks and deep Python integration</li>
<li>This is closer to writing code in any language as a for loop in code will behave as a for loop inside the
graph structure as well.</li>
<li>TensorFlow doesn’t handle dynamic graphs very well though there are some not so flexible and frankly quite
limiting primitive dynamic constructs.</li>
<li>Intel MKL and NVIDIA (CuDNN, NCCL) support</li>
<li>have their own official model repositories,</li>
</ul>

<p>
PyTorch:
</p>
<ul class="org-ul">
<li>replacement for NumPy to use the power of GPUs</li>
<li>deep learning research platform</li>
</ul>

<p>
HuggingFace: most models Pytorch
</p>
</div>
<div id="outline-container-org8fc5231" class="outline-3">
<h3 id="org8fc5231"><span class="section-number-3">14.1.</span> install</h3>
<div class="outline-text-3" id="text-14-1">
<p>
May 8, 2023
</p>
<pre class="example">
pip3 install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118
</pre>


<p>
2024
</p>
<pre class="example">
emerge --ask sci-libs/pytorch
</pre>
</div>
</div>
<div id="outline-container-orga402dc2" class="outline-3">
<h3 id="orga402dc2"><span class="section-number-3">14.2.</span> history</h3>
<div class="outline-text-3" id="text-14-2">
<ul class="org-ul">
<li>2002 - Torch (picked up by Facebook AI Research). Lua + C. three key features:
<ul class="org-ul">
<li>ease the development of numerical algorithms.</li>
<li>easily extended</li>
<li>fast</li>
</ul></li>
<li>2017 PyTorch beta.</li>
<li>Caffe2 was merged into PyTorch at the end of March 2018</li>
<li>1.13
<ul class="org-ul">
<li>BetterTransformer supports fastpath execution for common Transformer models during Inference
out-of-the-box, without the need to modify the model.</li>
<li>Functorch now in PyTorch Core Library - composable vmap (vectorization) and autodiff transforms.</li>
</ul></li>
<li>PyTorch 2.0 has been released on 15 March 2023 (2-series)</li>
<li>PyTorch 2.2 SDPA FlashAttention-2, TorchInductor, device<sub>mesh</sub>, TORCH<sub>LOGS</sub>.</li>
</ul>
</div>
<div id="outline-container-org88f82b8" class="outline-4">
<h4 id="org88f82b8"><span class="section-number-4">14.2.1.</span> PyTorch 2.0</h4>
<div class="outline-text-4" id="text-14-2-1">
<ul class="org-ul">
<li>fundamentally changing and supercharging how PyTorch operates at compiler level under the hood.</li>
<li>faster performance and support for Dynamic Shapes and Distributed.</li>
<li>torch.compile -  from C++ back into Python - additive (and optional) feature</li>
<li>2.0 is 100% backward compatible</li>
</ul>

<p>
TorchDynamo
</p>

<p>
AOTAutograd
</p>

<p>
PrimTorch
</p>

<p>
TorchInductor
</p>

<p>
Compilation steps:
</p>
<ul class="org-ul">
<li>graph acquisition - TorchDynamo + AOTAutograd</li>
<li>graph lowering - ATen/ Prim IR</li>
<li>graph compilation - TorchInductor(default) powered by Triton. Features:
<ul class="org-ul">
<li>your own backend</li>
<li>nvFuser</li>
<li>TVM</li>
<li>XLA</li>
<li>AITemplate</li>
<li>TensorRT</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org5114d8c" class="outline-4">
<h4 id="org5114d8c"><span class="section-number-4">14.2.2.</span> FlashAttention-2 - approximate attention method</h4>
<div class="outline-text-4" id="text-14-2-2">
<p>
FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
</p>
<ul class="org-ul">
<li><a href="https://arxiv.org/abs/2205.14135">https://arxiv.org/abs/2205.14135</a></li>
</ul>

<p>
Transformers: time and memory complexity of <b>self-attention</b> are quadratic in sequence length.
</p>

<p>
FlashAttention trains Transformers faster than existing baselines: 15% end-to-end wall-clock speedup on BERT-large
</p>
</div>
</div>
</div>

<div id="outline-container-org7e36985" class="outline-3">
<h3 id="org7e36985"><span class="section-number-3">14.3.</span> deployment</h3>
<div class="outline-text-3" id="text-14-3">
<ul class="org-ul">
<li>TorchServe
<ul class="org-ul">
<li>endpoint specification, model archiving, and observing metrics</li>
<li>provide REST and gRPC APIs</li>
<li>still in its infancy</li>
</ul></li>
<li>PyTorch Live - build upon old PyTorch Mobile
<ul class="org-ul">
<li>uses JavaScript and React Native to create cross-platform iOS and Android AI-powered apps</li>
<li>focuses on mobile only</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgd7c393f" class="outline-3">
<h3 id="orgd7c393f"><span class="section-number-3">14.4.</span> ecosystem</h3>
<div class="outline-text-3" id="text-14-4">
<p>
<a href="https://pytorch.org/ecosystem/">https://pytorch.org/ecosystem/</a>
</p>

<ul class="org-ul">
<li>PyTorch Hub <a href="https://pytorch.org/docs/stable/hub.html">https://pytorch.org/docs/stable/hub.html</a>
<ul class="org-ul">
<li>sharing repositories with pre-trained models</li>
</ul></li>
<li>PyTorch-XLA <a href="https://pytorch.org/xla/release/1.9/index.html">https://pytorch.org/xla/release/1.9/index.html</a>
<ul class="org-ul">
<li>train PyTorch models on Google's Cloud TPUs</li>
</ul></li>
<li>TorchVision - Computer Vision library <a href="https://github.com/pytorch/vision">https://github.com/pytorch/vision</a> <a href="https://pytorch.org/vision">https://pytorch.org/vision</a>
<ul class="org-ul">
<li>example models TIMM (pyTorch IMage Models)  <a href="https://github.com/rwightman/pytorch-image-models">https://github.com/rwightman/pytorch-image-models</a></li>
</ul></li>
<li>TorchText - Natural Language Processing <a href="https://pytorch.org/text/stable/index.html">https://pytorch.org/text/stable/index.html</a>
<ul class="org-ul">
<li>utilities and datasets</li>
<li>Facebook AI Research Sequence-to-Sequence Toolkit <a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></li>
</ul></li>
<li>TorchAudio -  ASR - <a href="https://pytorch.org/audio/stable/index.html">https://pytorch.org/audio/stable/index.html</a> and <a href="https://github.com/pytorch/audio">https://github.com/pytorch/audio</a>
<ul class="org-ul">
<li>includes popular audio models like DeepSpeech and Wav2Vec</li>
<li><a href="https://pytorch.org/audio/stable/tutorials/speech_recognition_pipeline_tutorial.html">https://pytorch.org/audio/stable/tutorials/speech_recognition_pipeline_tutorial.html</a></li>
<li><a href="https://pytorch.org/audio/stable/pipelines.html">https://pytorch.org/audio/stable/pipelines.html</a></li>
</ul></li>
<li>SpeechBrain - speech toolkit for PyTorch
<ul class="org-ul">
<li>ASR, speaker recognition, verification and diarization, and more!</li>
</ul></li>
<li>ESPnet - toolkit for end-to-end speech processing.
<ul class="org-ul">
<li>speech recognition, translation, diarization,</li>
</ul></li>
<li>AllenNLP - open-source NLP research library</li>
<li></li>
</ul>
</div>
</div>
<div id="outline-container-orge66cc07" class="outline-3">
<h3 id="orge66cc07"><span class="section-number-3">14.5.</span> PyTorch 2.0</h3>
<div class="outline-text-3" id="text-14-5">
<p>
<a href="https://pytorch.org/get-started/pytorch-2.0">https://pytorch.org/get-started/pytorch-2.0</a>
</p>

<p>
features:
</p>
<ul class="org-ul">
<li>model compilation or <b>compiled mode</b> - wraps your model and returns a compiled model.
<ul class="org-ul">
<li>will allow models to be ahead-of-time compiled for lightning-fast execution.</li>
<li>compiles the forward function to a more optimized version.</li>
<li>When compiling the model, we give a few knobs to adjust it.</li>
<li>drop-in replacement for torch.jit.script()</li>
</ul></li>
<li>make distributed training simpler too</li>
<li>TorchDynamo allow access model attributes like weight and modify them.</li>
</ul>

<p>
famous models:
</p>
<ul class="org-ul">
<li>DALL-E 2</li>
<li>Stable Diffusion</li>
<li>ChatGPT.</li>
</ul>

<p>
torch.distributed
</p>
<ul class="org-ul">
<li>DistributedDataParallel (DDP) - relies on overlapping AllReduce communications with backwards computation</li>
<li>FullyShardedDataParallel (FSDP) - “beta”</li>
</ul>
</div>
</div>
<div id="outline-container-org9fe7310" class="outline-3">
<h3 id="org9fe7310"><span class="section-number-3">14.6.</span> device</h3>
<div class="outline-text-3" id="text-14-6">
</div>
<div id="outline-container-org9e74a73" class="outline-4">
<h4 id="org9e74a73"><span class="section-number-4">14.6.1.</span> HIP</h4>
<div class="outline-text-4" id="text-14-6-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">if</span> torch.cuda.is_available() <span style="color: #8ac6f2; font-weight: bold;">and</span> torch.version.hip:
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">do something specific for HIP</span>
<span style="color: #8ac6f2; font-weight: bold;">elif</span> torch.cuda.is_available() <span style="color: #8ac6f2; font-weight: bold;">and</span> torch.version.cuda:
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">do something specific for CUDA</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org5880c5a" class="outline-4">
<h4 id="org5880c5a"><span class="section-number-4">14.6.2.</span> cuda test</h4>
<div class="outline-text-4" id="text-14-6-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> torch

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Set the device</span>
<span style="color: #cae682;">device</span> = <span style="color: #95e454;">"cuda"</span> <span style="color: #8ac6f2; font-weight: bold;">if</span> torch.cuda.is_available() <span style="color: #8ac6f2; font-weight: bold;">else</span> <span style="color: #95e454;">"cpu"</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Set the device globally</span>
torch.set_default_device(device)

<span style="color: #8ac6f2; font-weight: bold;">if</span> device == <span style="color: #95e454;">"cuda"</span>:
    <span style="color: #cae682;">GPU_SCORE</span> = torch.cuda.get_device_capability()
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">optimization - perform faster matrix multiplications</span>
    <span style="color: #8ac6f2; font-weight: bold;">if</span> GPU_SCORE &gt;= (8, 0):
        <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"[INFO] Using GPU with score: </span>{GPU_SCORE}<span style="color: #95e454;">, enabling TensorFloat32 (TF32) computing (faster on new GPUs)"</span>)
        torch.backends.cuda.matmul.<span style="color: #cae682;">allow_tf32</span> = <span style="color: #e5786d; font-weight: bold;">True</span>
    <span style="color: #8ac6f2; font-weight: bold;">else</span>:
        <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"[INFO] Using GPU with score: </span>{GPU_SCORE}<span style="color: #95e454;">, TensorFloat32 (TF32) not available, to use it you need a GPU with score &gt;= (8, 0)"</span>)
        torch.backends.cuda.matmul.<span style="color: #cae682;">allow_tf32</span> = <span style="color: #e5786d; font-weight: bold;">False</span>


</pre>
</div>
</div>
</div>
<div id="outline-container-org5c036b1" class="outline-4">
<h4 id="org5c036b1"><span class="section-number-4">14.6.3.</span> TPU</h4>
<div class="outline-text-4" id="text-14-6-3">
<p>
torch<sub>xla</sub> - enable pytorch on XLA devices, like TPUs
</p>
</div>
</div>
</div>

<div id="outline-container-org7a966ab" class="outline-3">
<h3 id="org7a966ab"><span class="section-number-3">14.7.</span> models - torchvision.models</h3>
<div class="outline-text-3" id="text-14-7">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> torchvision.models <span style="color: #8ac6f2; font-weight: bold;">as</span> models
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">from torchvision.models import resnet50</span>
<span style="color: #cae682;">resnet</span> = models.resnet50(weights=<span style="color: #e5786d; font-weight: bold;">None</span>) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">random initialization</span>
</pre>
</div>


<p>
Torch Hub
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> torch

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Option 1: passing weights param as string</span>
<span style="color: #cae682;">model</span> = torch.hub.load(<span style="color: #95e454;">"pytorch/vision"</span>, <span style="color: #95e454;">"resnet50"</span>, weights=<span style="color: #95e454;">"IMAGENET1K_V2"</span>)

</pre>
</div>
</div>
</div>
<div id="outline-container-orga7e5224" class="outline-3">
<h3 id="orga7e5224"><span class="section-number-3">14.8.</span> nn.Module</h3>
<div class="outline-text-3" id="text-14-8">
<ul class="org-ul">
<li>model.parameters() - the learnable parameters (i.e. weights and biases</li>
<li>model.state<sub>dict</sub>() is simply a Python dictionary object that maps each layer to its parameter tensor.</li>
</ul>
</div>

<div id="outline-container-orga64eea5" class="outline-4">
<h4 id="orga64eea5"><span class="section-number-4">14.8.1.</span> nn.Linear</h4>
<div class="outline-text-4" id="text-14-8-1">
<p>
y = x*(A<sup>T</sup>) + b , idk why ^T
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #cae682;">m</span> = np.random.random((2,3)) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Linear(in_features=2, out_features=5)</span>
<span style="color: #e5786d;">input</span> = np.random.random((10,2))
<span style="color: #e5786d;">print</span>(np.matmul(<span style="color: #e5786d;">input</span>,m).shape)
</pre>
</div>

<pre class="example">
(10, 3)
</pre>
</div>
</div>
<div id="outline-container-orgdadea5b" class="outline-4">
<h4 id="orgdadea5b"><span class="section-number-4">14.8.2.</span> links</h4>
<div class="outline-text-4" id="text-14-8-2">
<p>
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">https://pytorch.org/docs/stable/generated/torch.nn.Module.html</a>
</p>
</div>
</div>
</div>

<div id="outline-container-org6e68f5f" class="outline-3">
<h3 id="org6e68f5f"><span class="section-number-3">14.9.</span> Dataset and DataLoader, transform</h3>
<div class="outline-text-3" id="text-14-9">
<ul class="org-ul">
<li><p>
Dataset - retrieves our dataset’s features and labels one sample at a time.
</p>
<ul class="org-ul">
<li>from torch.utils.data import Dataset (<b>must be created</b>)</li>
<li>Dataset - map-style datasets, - _<sub>getitem</sub>_<sub>()</sub> and _<sub>len</sub>_<sub>()</sub>, accessible with dataset[idx]</li>
<li>IterableDataset - iterable-style datasets. - _<sub>iter</sub>_<sub>()</sub> - when called iter(dataset), could return a stream</li>
</ul>
<p>
of data reading from a database, a remote server, or even logs generated in real time.
</p>
<ul class="org-ul">
<li>multi-process data loading.</li>
</ul></li>
<li>DataLoader - minibatches, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval.
<ul class="org-ul">
<li>Dataset -&gt; Sampler -&gt; BatchSampler + Dataset -&gt; Data batch</li>
<li>from torch.utils.data import DataLoader (<b>accept Dataset as constructor argument</b>)</li>
</ul></li>
</ul>


<p>
samplers is to determine how batches should be formed. they are passed to a PyTorch Dataloader
</p>
<ul class="org-ul">
<li>When the dataloader is initialized, the sampler is also passed to it ( RandomSampler by default) which first
create the sequence order in which the the samples in dataset is accessed using index.ie (1,2,3..N) where N =
size of the dataset.</li>
</ul>

<p>
test Dataset:
</p>
<pre class="example">
img, lab = train_dataset.__getitem__(0)
</pre>


<p>
test DataLoader:
</p>
<pre class="example">
img, lab = iter(train_loader).next()
</pre>


<p>
Trnasform - part of Dataset implementation, applyed in _<sub>getitem</sub>_<sub>()</sub>
</p>
<ul class="org-ul">
<li>from torchvision import transforms <a href="https://pytorch.org/vision/stable/transforms.html">https://pytorch.org/vision/stable/transforms.html</a></li>
</ul>
<pre class="example">
sample = self.transform(sample) ; return sample
</pre>


<p>
Approach 2):
</p>
<ul class="org-ul">
<li>train<sub>dataset</sub> = torchvision.datasets.ImageFolder(root='aa/train', transform=MyTransform)</li>
</ul>
</div>
<div id="outline-container-org9ed9628" class="outline-4">
<h4 id="org9ed9628"><span class="section-number-4">14.9.1.</span> code</h4>
<div class="outline-text-4" id="text-14-9-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> torch
<span style="color: #8ac6f2; font-weight: bold;">import</span> torchvision.models <span style="color: #8ac6f2; font-weight: bold;">as</span> models
<span style="color: #8ac6f2; font-weight: bold;">from</span> torch.utils.data <span style="color: #8ac6f2; font-weight: bold;">import</span> Dataset
<span style="color: #8ac6f2; font-weight: bold;">from</span> torch.utils.data <span style="color: #8ac6f2; font-weight: bold;">import</span> DataLoader
<span style="color: #8ac6f2; font-weight: bold;">from</span> torchvision.io <span style="color: #8ac6f2; font-weight: bold;">import</span> read_image
<span style="color: #8ac6f2; font-weight: bold;">from</span> torchvision <span style="color: #8ac6f2; font-weight: bold;">import</span> transforms

<span style="color: #cae682;">IMG_WIDTH</span> = 64
<span style="color: #cae682;">IMG_HEIGHT</span> = 64

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- image format</span>
<span style="color: #cae682;">default_float_dtype</span> = torch.get_default_dtype()


<span style="color: #8ac6f2; font-weight: bold;">class</span> <span style="color: #92a65e; font-weight: bold;">LandmarkDataset</span>(Dataset):
    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__init__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, paths, labels, transform=<span style="color: #e5786d; font-weight: bold;">None</span>, target_transform=<span style="color: #e5786d; font-weight: bold;">None</span>):
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">paths</span> = paths
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">labels</span> = labels
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">transform</span> = transform
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">target_transform</span> = target_transform

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__len__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>):
        <span style="color: #8ac6f2; font-weight: bold;">return</span> <span style="color: #e5786d;">len</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>.labels)

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__getitem__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, idx):
        <span style="color: #cae682;">image</span> = read_image(<span style="color: #8ac6f2; font-weight: bold;">self</span>.paths[idx])
        <span style="color: #cae682;">image</span> = image.to(dtype=default_float_dtype).div(255)
        <span style="color: #cae682;">label</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.labels[idx]
        <span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #8ac6f2; font-weight: bold;">self</span>.transform:
            <span style="color: #cae682;">image</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.transform(image)
        <span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #8ac6f2; font-weight: bold;">self</span>.target_transform:
            <span style="color: #cae682;">label</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.target_transform(label)
        <span style="color: #8ac6f2; font-weight: bold;">return</span> image, label

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">main</span>():
    <span style="color: #cae682;">x_train</span>, <span style="color: #cae682;">y_train</span> = get_dataset()
    <span style="color: #cae682;">data_transform</span> = transforms.Compose([
        transforms.RandomResizedCrop((IMG_HEIGHT, IMG_WIDTH)),
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">transforms.ToTensor()  # to [0.0, 1.0]</span>
        ])
    <span style="color: #cae682;">train_dataset</span>: Dataset = LandmarkDataset(x_train, y_train,
                                             transform=data_transform)
    <span style="color: #cae682;">train_loader</span>: DataLoader = DataLoader(train_dataset)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">img, lab = train_dataset.__getitem__(0)</span>
    <span style="color: #cae682;">img</span>, <span style="color: #cae682;">lab</span> = <span style="color: #e5786d;">next</span>(<span style="color: #e5786d;">iter</span>(train_loader))
    <span style="color: #e5786d;">print</span>(img, lab)

</pre>
</div>
</div>
</div>
<div id="outline-container-org1bdcc1e" class="outline-4">
<h4 id="org1bdcc1e"><span class="section-number-4">14.9.2.</span> links</h4>
<div class="outline-text-4" id="text-14-9-2">
<ul class="org-ul">
<li><a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">https://pytorch.org/tutorials/beginner/basics/data_tutorial.html</a></li>
<li><a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html">https://pytorch.org/tutorials/beginner/data_loading_tutorial.html</a></li>
<li><a href="https://pytorch.org/docs/stable/data.html">https://pytorch.org/docs/stable/data.html</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org96f515e" class="outline-3">
<h3 id="org96f515e"><span class="section-number-3">14.10.</span> Built-in datasets</h3>
<div class="outline-text-3" id="text-14-10">
<p>
all datasets return PIL Image: Image.fromarray(img.numpy(), mode="L")
</p>
<ul class="org-ul">
<li>from PIL import Image</li>
</ul>


<p>
training.pt We no longer cache the data in a custom binary, but simply read from the raw data directly.
</p>
</div>
</div>
<div id="outline-container-org9344d2c" class="outline-3">
<h3 id="org9344d2c"><span class="section-number-3">14.11.</span> train</h3>
<div class="outline-text-3" id="text-14-11">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> datetime <span style="color: #8ac6f2; font-weight: bold;">import</span> datetime
<span style="color: #8ac6f2; font-weight: bold;">import</span> torch
<span style="color: #8ac6f2; font-weight: bold;">import</span> torchvision.models <span style="color: #8ac6f2; font-weight: bold;">as</span> models
<span style="color: #8ac6f2; font-weight: bold;">from</span> torch.utils.data <span style="color: #8ac6f2; font-weight: bold;">import</span> Dataset
<span style="color: #8ac6f2; font-weight: bold;">from</span> torch.utils.data <span style="color: #8ac6f2; font-weight: bold;">import</span> DataLoader
<span style="color: #8ac6f2; font-weight: bold;">from</span> torchvision.io <span style="color: #8ac6f2; font-weight: bold;">import</span> read_image
<span style="color: #8ac6f2; font-weight: bold;">from</span> torchvision <span style="color: #8ac6f2; font-weight: bold;">import</span> transforms


<span style="color: #8ac6f2; font-weight: bold;">class</span> <span style="color: #92a65e; font-weight: bold;">LandmarkDataset</span>(Dataset):
    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__init__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, paths, labels, transform=<span style="color: #e5786d; font-weight: bold;">None</span>, target_transform=<span style="color: #e5786d; font-weight: bold;">None</span>):
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">paths</span> = paths
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">labels</span> = labels
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">transform</span> = transform
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">target_transform</span> = target_transform

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__len__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>):
        <span style="color: #8ac6f2; font-weight: bold;">return</span> <span style="color: #e5786d;">len</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>.labels)

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__getitem__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, idx):
        <span style="color: #cae682;">image</span> = read_image(<span style="color: #8ac6f2; font-weight: bold;">self</span>.paths[idx])
        <span style="color: #cae682;">image</span> = image.to(dtype=default_float_dtype).div(255)
        <span style="color: #cae682;">label</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.labels[idx]
        <span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #8ac6f2; font-weight: bold;">self</span>.transform:
            <span style="color: #cae682;">image</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.transform(image)
        <span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #8ac6f2; font-weight: bold;">self</span>.target_transform:
            <span style="color: #cae682;">label</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.target_transform(label)
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">return image, label</span>
        <span style="color: #8ac6f2; font-weight: bold;">return</span> image.to(device), torch.tensor(label, dtype=torch.<span style="color: #e5786d;">long</span>).to(device)

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">train_one_epoch</span>(epoch_index, training_loader, optimizer, model, loss_fn, tb_writer=<span style="color: #e5786d; font-weight: bold;">None</span>):
    <span style="color: #f08080; font-style: italic;">""" training_loader is (inputs, labels) """</span>
    <span style="color: #cae682;">running_loss</span> = 0.
    <span style="color: #cae682;">last_loss</span> = 0.
    <span style="color: #cae682;">avg_loss</span> = 0.

    <span style="color: #8ac6f2; font-weight: bold;">for</span> i, data <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">enumerate</span>(training_loader):
        <span style="color: #cae682;">inputs</span>, <span style="color: #cae682;">labels</span> = data
        optimizer.zero_grad()
        <span style="color: #cae682;">outputs</span> = model(inputs)
        <span style="color: #cae682;">loss</span> = loss_fn(outputs, labels)
        loss.backward()
        optimizer.step()

        <span style="color: #cae682;">running_loss</span> += loss.item()

        <span style="color: #8ac6f2; font-weight: bold;">if</span> i % 10 == 9:
            <span style="color: #cae682;">avg_loss</span> = running_loss / (1 <span style="color: #8ac6f2; font-weight: bold;">if</span> i // 10 == 0 <span style="color: #8ac6f2; font-weight: bold;">else</span> i // 10)
            <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">'  batch {} loss: {}'</span>.<span style="color: #e5786d;">format</span>(i + 1, <span style="color: #e5786d;">round</span>(avg_loss,2)))
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">tb_x = epoch_index * len(training_loader) + i + 1</span>
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">tb_writer.add_scalar('Loss/train', last_loss, tb_x)</span>
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">running_loss = 0.</span>

    <span style="color: #8ac6f2; font-weight: bold;">return</span> avg_loss

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">train</span>(model, training_loader, validation_loader, loss_fn, wirter=<span style="color: #e5786d; font-weight: bold;">None</span>): <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">require import datetime</span>
    <span style="color: #cae682;">timestamp</span> = datetime.now().strftime(<span style="color: #95e454;">'%Y%m%d_%H%M%S'</span>)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))</span>
    <span style="color: #cae682;">epoch_number</span> = 0
    <span style="color: #cae682;">EPOCHS</span> = 2
    <span style="color: #cae682;">best_vloss</span> = 1_000_000.

    <span style="color: #8ac6f2; font-weight: bold;">for</span> epoch <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(EPOCHS):
        <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">'EPOCH {}:'</span>.<span style="color: #e5786d;">format</span>(epoch_number + 1))
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- train ----</span>
        model.train(<span style="color: #e5786d; font-weight: bold;">True</span>)
        <span style="color: #cae682;">avg_loss</span> = train_one_epoch(epoch_number,
                                   training_loader=training_loader,
                                   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">optimizer=torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9),</span>
                                   optimizer=torch.optim.Adam(model.parameters()),
                                   model=model,
                                   loss_fn=loss_fn,
                                   tb_writer=<span style="color: #e5786d; font-weight: bold;">None</span>)

        <span style="color: #cae682;">running_vloss</span> = 0.0
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">---- validate ----</span>
        model.<span style="color: #e5786d;">eval</span>()

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- Disable gradient computation and reduce memory consumption.</span>
        <span style="color: #8ac6f2; font-weight: bold;">with</span> torch.no_grad():
            <span style="color: #8ac6f2; font-weight: bold;">for</span> i, vdata <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">enumerate</span>(validation_loader):
                <span style="color: #cae682;">vinputs</span>, <span style="color: #cae682;">vlabels</span> = vdata
                <span style="color: #cae682;">voutputs</span> = model(vinputs)
                <span style="color: #cae682;">vloss</span> = loss_fn(voutputs, vlabels)
                <span style="color: #cae682;">running_vloss</span> += vloss

        <span style="color: #cae682;">avg_vloss</span> = running_vloss / (i + 1)
        <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">'LOSS train {} valid {}'</span>.<span style="color: #e5786d;">format</span>(avg_loss, avg_vloss))

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">writer.add_scalars('Training vs. Validation Loss',</span>
        <span style="color: #fa8072;">#                 </span><span style="color: #99968b; font-style: italic;">{ 'Training' : avg_loss, 'Validation' : avg_vloss },</span>
        <span style="color: #fa8072;">#                 </span><span style="color: #99968b; font-style: italic;">epoch_number + 1)</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">writer.flush()</span>

        <span style="color: #8ac6f2; font-weight: bold;">if</span> avg_vloss &lt; best_vloss:
            <span style="color: #cae682;">best_vloss</span> = avg_vloss
            <span style="color: #cae682;">model_path</span> = <span style="color: #95e454;">'model_{}_{}'</span>.<span style="color: #e5786d;">format</span>(timestamp, epoch_number)
            torch.save(model.state_dict(), model_path)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">save the model's state</span>

        <span style="color: #cae682;">epoch_number</span> += 1

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">create_model</span>(classes) -&gt; torch.nn.Module:
    <span style="color: #cae682;">resnet</span> = models.resnet50(weights=<span style="color: #e5786d; font-weight: bold;">None</span>)
    <span style="color: #cae682;">num_ftrs</span> = resnet.fc.in_features
    resnet.<span style="color: #cae682;">fc</span> = torch.nn.Linear(num_ftrs, out_features=classes)
    <span style="color: #8ac6f2; font-weight: bold;">return</span> resnet


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">main</span>():
    <span style="color: #cae682;">x_train</span>, <span style="color: #cae682;">x_valid</span>, <span style="color: #cae682;">y_train</span>, <span style="color: #cae682;">y_valid</span>, <span style="color: #cae682;">OUTPUT_SIZE</span> = get_dataset()
    <span style="color: #cae682;">data_transform</span> = transforms.Compose([
        transforms.RandomResizedCrop((IMG_HEIGHT, IMG_WIDTH)),
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">transforms.ToTensor()  # to [0.0, 1.0]</span>
        ])
    <span style="color: #cae682;">train_dataset</span>: Dataset = LandmarkDataset(x_train, y_train,
                                             transform=data_transform)
    <span style="color: #8ac6f2; font-weight: bold;">from</span> torch.utils.data.dataloader <span style="color: #8ac6f2; font-weight: bold;">import</span> default_collate
    <span style="color: #cae682;">generator</span> = torch.Generator(device=device)
    <span style="color: #cae682;">train_loader</span>: DataLoader = DataLoader(train_dataset,
                                          shuffle=<span style="color: #e5786d; font-weight: bold;">True</span>, batch_size=BATCH_SIZE,
                                          generator=generator)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">, pin_memory_device=device, pin_memory=True</span>

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">collate_fn=lambda x: (default_collate(x[0]).to(device), default_collate(torch.from_numpy(x[1])).to(device))</span>
    <span style="color: #cae682;">valid_dataset</span>: Dataset = LandmarkDataset(x_valid, y_valid,
                                             transform=data_transform)
    <span style="color: #cae682;">valid_loader</span>: DataLoader = DataLoader(valid_dataset)
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">img, lab = train_dataset.__getitem__(0)</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">img, lab = next(iter(train_loader))</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(img, lab)</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- train</span>
    <span style="color: #cae682;">model</span>: torch.nn.Module = create_model(OUTPUT_SIZE)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">load model definition</span>
    <span style="color: #e5786d;">print</span>(model)
    train(model, training_loader=train_loader, validation_loader=valid_loader,
          loss_fn=torch.nn.CrossEntropyLoss())
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- save, load and inference</span>
    <span style="color: #8ac6f2; font-weight: bold;">import</span> os
    <span style="color: #cae682;">PATH</span> = os.path.join(os.getcwd(), <span style="color: #95e454;">'savedmodel'</span>)
    torch.save(model.state_dict(), PATH)
</pre>
</div>
</div>
<div id="outline-container-orgd46e1d6" class="outline-4">
<h4 id="orgd46e1d6"><span class="section-number-4">14.11.1.</span> links</h4>
<div class="outline-text-4" id="text-14-11-1">
<p>
<a href="https://pytorch.org/tutorials/beginner/introyt/trainingyt.html">https://pytorch.org/tutorials/beginner/introyt/trainingyt.html</a>
</p>
</div>
</div>
</div>
<div id="outline-container-orgc94d75e" class="outline-3">
<h3 id="orgc94d75e"><span class="section-number-3">14.12.</span> train (old)</h3>
<div class="outline-text-3" id="text-14-12">
<p>
data, target = data.to(device), target.to(device)
</p>

<p>
optimizer.zero<sub>grad</sub>()
</p>

<p>
output = model(data)
</p>

<p>
loss = F.nll<sub>loss</sub>(output, target)
</p>

<p>
loss.backward(retain<sub>graph</sub>=True)
</p>

<p>
optimizer.step()
</p>


<p>
When we call <b>loss.backward()</b> - all Tensors in the graph that has requires<sub>grad</sub>=True will have their .grad
Tensor accumulated with the gradient.
</p>
</div>
</div>
<div id="outline-container-orgaf74263" class="outline-3">
<h3 id="orgaf74263"><span class="section-number-3">14.13.</span> loss, inference, accuracy</h3>
<div class="outline-text-3" id="text-14-13">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> torch
<span style="color: #cae682;">loss</span> = torch.nn.CrossEntropyLoss()
<span style="color: #e5786d;">input</span> = torch.randn(3, 5, requires_grad=<span style="color: #e5786d; font-weight: bold;">True</span>)
<span style="color: #cae682;">target</span> = torch.empty(3, dtype=torch.<span style="color: #e5786d;">long</span>).random_(5)
<span style="color: #cae682;">output</span> = loss(<span style="color: #e5786d;">input</span>, target)
output.backward()
<span style="color: #e5786d;">print</span>(output)


<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">after save:</span>
<span style="color: #cae682;">model</span> = create_model(OUTPUT_SIZE)
model.load_state_dict(torch.load(PATH))
model.<span style="color: #e5786d;">eval</span>()
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- inference</span>
<span style="color: #cae682;">img</span>, <span style="color: #cae682;">lab</span> = <span style="color: #e5786d;">next</span>(<span style="color: #e5786d;">iter</span>(DataLoader(valid_dataset, shuffle=<span style="color: #e5786d; font-weight: bold;">True</span>, batch_size=1
                                ,generator=generator
                                )))  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">get random item</span>
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"lab"</span>, lab)
<span style="color: #cae682;">result</span>: torch.Tensor = model(img)
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"result"</span>, np.argmax(result.cpu().detach().numpy()))
</pre>
</div>

<p>
Accuracy:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> torch
<span style="color: #cae682;">target</span> = torch.tensor([0, 1, 1])
<span style="color: #cae682;">preds</span> = torch.tensor([[0.1, 0.9, 0], [0.3, 0.1, 0.6], [0.2, 0.5, 0.3]])
<span style="color: #cae682;">accuracy</span> = torch.metrics.Accuracy(task=<span style="color: #95e454;">"multiclass"</span>, num_classes=3, top_k=2)
<span style="color: #e5786d;">print</span>(accuracy(preds, target))

</pre>
</div>
</div>
</div>
<div id="outline-container-org97fbbdd" class="outline-3">
<h3 id="org97fbbdd"><span class="section-number-3">14.14.</span> numpy</h3>
<div class="outline-text-3" id="text-14-14">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> torch
<span style="color: #cae682;">x</span> = torch.empty(5, 3)
<span style="color: #e5786d;">print</span>(x)

<span style="color: #e5786d;">print</span>(x.size())
&gt;&gt; torch.Size([5, 3])
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Converting a Torch Tensor to a NumPy Array</span>
<span style="color: #cae682;">n</span> = torch.ones(5).numpy()
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Converting NumPy Array to Torch Tensor</span>
<span style="color: #cae682;">t</span> = torch.from_numpy(a)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">tensors on CUDA</span>
<span style="color: #8ac6f2; font-weight: bold;">if</span> torch.cuda.is_available():
    <span style="color: #cae682;">device</span> = torch.device(<span style="color: #95e454;">"cuda"</span>)          <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">a CUDA device object</span>
    <span style="color: #cae682;">y</span> = torch.ones_like(x, device=device)
    <span style="color: #cae682;">x</span> = x.to(device)
    <span style="color: #cae682;">z</span> = x + y
    <span style="color: #e5786d;">print</span>(z.to(<span style="color: #95e454;">"cpu"</span>, torch.double)) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">back to cpu</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">random</span>
<span style="color: #cae682;">x</span> = torch.randn(4, 4) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">from a normal distribution - mean 0 and variance 1</span>
<span style="color: #cae682;">x</span> = torch.rand(4, 4) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">on the interval [0,1)</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">resize/reshape</span>
<span style="color: #cae682;">y</span> = x.view(16) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">line</span>
<span style="color: #cae682;">z</span> = x.view(-1, 8) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">column:  torch.Size([2, 8])</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">torch.squeeze(input, dim=None, out=None) &#8594; Tensor</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">tensor(A&#215;1&#215;B&#215;C&#215;1&#215;D)</span>
&gt;&gt;&gt; <span style="color: #cae682;">x</span> = torch.zeros(2, 1, 2, 1, 2)
torch.Size([2, 1, 2, 1, 2])
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&#1074;&#1099;&#1078;&#1080;&#1084;&#1072;&#1090;&#1100; remove 1 size dimensions</span>
&gt;&gt;&gt; <span style="color: #cae682;">y</span> = torch.squeeze(x) <span style="color: #fa8072;">#</span>
torch.Size([2, 2, 2])
&gt;&gt;&gt; <span style="color: #cae682;">y</span> = torch.squeeze(x, 0)
torch.Size([2, 1, 2, 1, 2])
&gt;&gt;&gt; <span style="color: #cae682;">y</span> = torch.squeeze(x, 1)
torch.Size([2, 2, 1, 2])

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Concatenates sequence of tensors along a new dimension:</span>
torch.stack(tensors: <span style="color: #e5786d;">list</span>, dim=0, out=<span style="color: #e5786d; font-weight: bold;">None</span>) &#8594; Tensor

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">transpose</span>
<span style="color: #cae682;">t</span> = torch.tensor([[1,2,3],[4,5,6]])
torch.transpose(t,0,1)
&gt;tensor([[1, 4],
        [2, 5],
        [3, 6]])

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">add dimension</span>
&gt;&gt; torch.Size([1, 2])
a.unsqueeze(0).size()
&gt;&gt; torch.Size([1, 1, 2])
a.unsqueeze(-1).size()
&gt;&gt; torch.Size([1, 2, 1])
</pre>
</div>
</div>
</div>

<div id="outline-container-org295c39b" class="outline-3">
<h3 id="org295c39b"><span class="section-number-3">14.15.</span> layers</h3>
<div class="outline-text-3" id="text-14-15">
<pre class="example">
import torch.nn as nn
import torch.nn.functional as F # activation
</pre>


<ul class="org-ul">
<li>CNN
<ul class="org-ul">
<li>nn.Conv2d(1, 32, kernel<sub>size</sub>=(3, 3), stride=(1, 1)) -</li>
</ul></li>
<li></li>
</ul>
</div>
</div>
<div id="outline-container-org8dc1244" class="outline-3">
<h3 id="org8dc1244"><span class="section-number-3">14.16.</span> noise</h3>
<div class="outline-text-3" id="text-14-16">
<pre class="example">
       r = (0.1**0.9)*torch.randn(self.levels, batch, self.hidden_size//2, dtype=dtype, device=self.device)
self.hidden1 = (self.hidden1[0] + r, self.hidden1[1] + r)
</pre>
</div>
</div>
<div id="outline-container-org36d0014" class="outline-3">
<h3 id="org36d0014"><span class="section-number-3">14.17.</span> basic nn and gradient</h3>
<div class="outline-text-3" id="text-14-17">
<p>
input 32x32
</p>

<p>
torch.Size([64, 32, 26, 26]) - batch<sub>size</sub>, output<sub>channels</sub>, Height, Width
</p>

<p>
Trainable parameters:
</p>
<pre class="example">
params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"Trainable parameters: {params:,}")
</pre>


<p>
Recap:
</p>
<ul class="org-ul">
<li>torch.Tensor - A multi-dimensional array with support for autograd operations like backward(). Also holds
the gradient w.r.t. the tensor.
<ul class="org-ul">
<li>IF .requires<sub>grad</sub> as True - it starts to track all operations on it. accumulated into .grad</li>
<li>with torch.no<sub>grad</sub>(): - for testing</li>
</ul></li>
<li>nn.Module - Neural network module. Convenient way of encapsulating parameters, with helpers for moving them
to GPU, exporting, loading, etc.</li>
<li>nn.Parameter - A kind of Tensor, that is automatically registered as a parameter when assigned as an
attribute to a Module.</li>
<li>autograd.Function - Implements forward and backward definitions of an autograd operation. Every Tensor
operation creates at least a single Function node that connects to functions that created a Tensor and
encodes its history.</li>
</ul>
</div>
<div id="outline-container-org38a87f3" class="outline-4">
<h4 id="org38a87f3"><span class="section-number-4">14.17.1.</span> first</h4>
<div class="outline-text-4" id="text-14-17-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> torch
<span style="color: #8ac6f2; font-weight: bold;">import</span> torch.nn <span style="color: #8ac6f2; font-weight: bold;">as</span> nn <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">layer</span>
<span style="color: #8ac6f2; font-weight: bold;">import</span> torch.nn.functional <span style="color: #8ac6f2; font-weight: bold;">as</span> F <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">activation</span>


<span style="color: #8ac6f2; font-weight: bold;">class</span> <span style="color: #92a65e; font-weight: bold;">Net</span>(nn.Module):

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__init__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>):
        <span style="color: #e5786d;">super</span>(Net, <span style="color: #8ac6f2; font-weight: bold;">self</span>).__init__()
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">1 input image channel, 6 output channels, 3x3 square convolution</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">kernel</span>
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">conv1</span> = nn.Conv2d(1, 6, 3) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">input 1 image to 6, 3x3 kernel, stride=1 default</span>
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">conv2</span> = nn.Conv2d(6, 16, 3)
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">dropout1</span> = nn.Dropout2d(0.25)
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">an affine operation: y = Wx + b</span>
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">fc1</span> = nn.Linear(16 * 6 * 6, 120)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">6*6 from image dimension</span>
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">fc2</span> = nn.Linear(120, 84)
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">fc3</span> = nn.Linear(84, 10)

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">forward</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, x):
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Max pooling over a (2, 2) window</span>
        <span style="color: #cae682;">x</span> = F.max_pool2d(F.relu(<span style="color: #8ac6f2; font-weight: bold;">self</span>.conv1(x)), (2, 2))
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">If the size is a square you can only specify a single number</span>
        <span style="color: #cae682;">x</span> = F.max_pool2d(F.relu(<span style="color: #8ac6f2; font-weight: bold;">self</span>.conv2(x)), 2)
        <span style="color: #cae682;">x</span> = x.view(-1, <span style="color: #8ac6f2; font-weight: bold;">self</span>.num_flat_features(x))
        <span style="color: #cae682;">x</span> = F.relu(<span style="color: #8ac6f2; font-weight: bold;">self</span>.fc1(x))
        <span style="color: #cae682;">x</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.dropout1(x)
        <span style="color: #cae682;">x</span> = F.relu(<span style="color: #8ac6f2; font-weight: bold;">self</span>.fc2(x))
        <span style="color: #cae682;">x</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.fc3(x)
        <span style="color: #8ac6f2; font-weight: bold;">return</span> x

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">num_flat_features</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, x):
        <span style="color: #cae682;">size</span> = x.size()[1:]  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">all dimensions except the batch dimension</span>
        <span style="color: #cae682;">num_features</span> = 1
        <span style="color: #8ac6f2; font-weight: bold;">for</span> s <span style="color: #8ac6f2; font-weight: bold;">in</span> size:
            <span style="color: #cae682;">num_features</span> *= s
        <span style="color: #8ac6f2; font-weight: bold;">return</span> num_features


<span style="color: #cae682;">net</span> = Net()
<span style="color: #e5786d;">print</span>(net) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print all layers</span>
<span style="color: #cae682;">params</span> = <span style="color: #e5786d;">list</span>(net.parameters()) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">learnable parameters of a model</span>




<span style="color: #8ac6f2; font-weight: bold;">import</span> torch.optim <span style="color: #8ac6f2; font-weight: bold;">as</span> optim

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">create your optimizer</span>
<span style="color: #cae682;">optimizer</span> = optim.SGD(net.parameters(), lr=0.01)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">in your training loop:</span>
optimizer.zero_grad()   <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">zero the gradient buffers</span>
<span style="color: #cae682;">output</span> = net(<span style="color: #e5786d;">input</span>)
<span style="color: #cae682;">loss</span> = criterion(output, target)
loss.backward()
optimizer.step()    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Does the updatee</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org28060d1" class="outline-4">
<h4 id="org28060d1"><span class="section-number-4">14.17.2.</span> second</h4>
<div class="outline-text-4" id="text-14-17-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> argparse
<span style="color: #8ac6f2; font-weight: bold;">import</span> torch
<span style="color: #8ac6f2; font-weight: bold;">import</span> torch.nn <span style="color: #8ac6f2; font-weight: bold;">as</span> nn
<span style="color: #8ac6f2; font-weight: bold;">import</span> torch.nn.functional <span style="color: #8ac6f2; font-weight: bold;">as</span> F
<span style="color: #8ac6f2; font-weight: bold;">import</span> torch.optim <span style="color: #8ac6f2; font-weight: bold;">as</span> optim
<span style="color: #8ac6f2; font-weight: bold;">from</span> torchvision <span style="color: #8ac6f2; font-weight: bold;">import</span> datasets, transforms
<span style="color: #8ac6f2; font-weight: bold;">from</span> torch.optim.lr_scheduler <span style="color: #8ac6f2; font-weight: bold;">import</span> StepLR


<span style="color: #8ac6f2; font-weight: bold;">class</span> <span style="color: #92a65e; font-weight: bold;">Net</span>(nn.Module):
    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__init__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>):
        <span style="color: #e5786d;">super</span>(Net, <span style="color: #8ac6f2; font-weight: bold;">self</span>).__init__()
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">conv1</span> = nn.Conv2d(1, 32, 3, 1)
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">conv2</span> = nn.Conv2d(32, 64, 3, 1)

        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">dropout1</span> = nn.Dropout2d(0.25)
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">dropout2</span> = nn.Dropout2d(0.5)
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">fc1</span> = nn.Linear(9216, 128)
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">fc2</span> = nn.Linear(128, 10)

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">forward</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, x):
        <span style="color: #cae682;">x</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.conv1(x)
        <span style="color: #cae682;">x</span> = F.relu(x)
        <span style="color: #cae682;">x</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.conv2(x)
        <span style="color: #cae682;">x</span> = F.max_pool2d(x, 2)
        <span style="color: #cae682;">x</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.dropout1(x)
        <span style="color: #cae682;">x</span> = torch.flatten(x, 1)
        <span style="color: #cae682;">x</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.fc1(x)
        <span style="color: #cae682;">x</span> = F.relu(x)
        <span style="color: #cae682;">x</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.dropout2(x)
        <span style="color: #cae682;">x</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.fc2(x)
        <span style="color: #cae682;">output</span> = F.log_softmax(x, dim=1)
        <span style="color: #8ac6f2; font-weight: bold;">return</span> output


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">train</span>(args, model: nn.Module, device, train_loader, optimizer, epoch):
    model.train()
    <span style="color: #8ac6f2; font-weight: bold;">for</span> batch_idx, (data, target) <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">enumerate</span>(train_loader):
        <span style="color: #cae682;">data</span>, <span style="color: #cae682;">target</span> = data.to(device), target.to(device)
        optimizer.zero_grad()
        <span style="color: #cae682;">output</span> = model(data)
        <span style="color: #cae682;">loss</span> = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        <span style="color: #8ac6f2; font-weight: bold;">if</span> batch_idx % args.log_interval == 0:
            <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">'Train Epoch: {} [{}/{} ({:.0f}%)]</span><span style="color: #e5786d; font-weight: bold;">\t</span><span style="color: #95e454;">Loss: {:.6f}'</span>.<span style="color: #e5786d;">format</span>(
                epoch, batch_idx * <span style="color: #e5786d;">len</span>(data), <span style="color: #e5786d;">len</span>(train_loader.dataset),
                100. * batch_idx / <span style="color: #e5786d;">len</span>(train_loader), loss.item()))


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">test</span>(args, model: nn.Module, device, test_loader):
    model.<span style="color: #e5786d;">eval</span>()
    <span style="color: #cae682;">test_loss</span> = 0
    <span style="color: #cae682;">correct</span> = 0
    <span style="color: #8ac6f2; font-weight: bold;">with</span> torch.no_grad():
        <span style="color: #8ac6f2; font-weight: bold;">for</span> data, target <span style="color: #8ac6f2; font-weight: bold;">in</span> test_loader:
            <span style="color: #cae682;">data</span>, <span style="color: #cae682;">target</span> = data.to(device), target.to(device)
            <span style="color: #cae682;">output</span> = model(data)
            <span style="color: #cae682;">test_loss</span> += F.nll_loss(output, target, reduction=<span style="color: #95e454;">'sum'</span>).item()  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">sum up batch loss</span>
            <span style="color: #cae682;">pred</span> = output.argmax(dim=1, keepdim=<span style="color: #e5786d; font-weight: bold;">True</span>)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">get the index of the max log-probability</span>
            <span style="color: #cae682;">correct</span> += pred.eq(target.view_as(pred)).<span style="color: #e5786d;">sum</span>().item()

    <span style="color: #cae682;">test_loss</span> /= <span style="color: #e5786d;">len</span>(test_loader.dataset)

    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">'</span><span style="color: #e5786d; font-weight: bold;">\n</span><span style="color: #95e454;">Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)</span><span style="color: #e5786d; font-weight: bold;">\n</span><span style="color: #95e454;">'</span>.<span style="color: #e5786d;">format</span>(
        test_loss, correct, <span style="color: #e5786d;">len</span>(test_loader.dataset),
        100. * correct / <span style="color: #e5786d;">len</span>(test_loader.dataset)))


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">main</span>():
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Training settings</span>
    <span style="color: #cae682;">parser</span> = argparse.ArgumentParser(description=<span style="color: #95e454;">'PyTorch MNIST Example'</span>)
    parser.add_argument(<span style="color: #95e454;">'--batch-size'</span>, <span style="color: #e5786d;">type</span>=<span style="color: #e5786d;">int</span>, default=64, metavar=<span style="color: #95e454;">'N'</span>,
                        <span style="color: #e5786d;">help</span>=<span style="color: #95e454;">'input batch size for training (default: 64)'</span>)
    parser.add_argument(<span style="color: #95e454;">'--test-batch-size'</span>, <span style="color: #e5786d;">type</span>=<span style="color: #e5786d;">int</span>, default=1000, metavar=<span style="color: #95e454;">'N'</span>,
                        <span style="color: #e5786d;">help</span>=<span style="color: #95e454;">'input batch size for testing (default: 1000)'</span>)
    parser.add_argument(<span style="color: #95e454;">'--epochs'</span>, <span style="color: #e5786d;">type</span>=<span style="color: #e5786d;">int</span>, default=14, metavar=<span style="color: #95e454;">'N'</span>,
                        <span style="color: #e5786d;">help</span>=<span style="color: #95e454;">'number of epochs to train (default: 14)'</span>)
    parser.add_argument(<span style="color: #95e454;">'--lr'</span>, <span style="color: #e5786d;">type</span>=<span style="color: #e5786d;">float</span>, default=1.0, metavar=<span style="color: #95e454;">'LR'</span>,
                        <span style="color: #e5786d;">help</span>=<span style="color: #95e454;">'learning rate (default: 1.0)'</span>)
    parser.add_argument(<span style="color: #95e454;">'--gamma'</span>, <span style="color: #e5786d;">type</span>=<span style="color: #e5786d;">float</span>, default=0.7, metavar=<span style="color: #95e454;">'M'</span>,
                        <span style="color: #e5786d;">help</span>=<span style="color: #95e454;">'Learning rate step gamma (default: 0.7)'</span>)
    parser.add_argument(<span style="color: #95e454;">'--no-cuda'</span>, action=<span style="color: #95e454;">'store_true'</span>, default=<span style="color: #e5786d; font-weight: bold;">False</span>,
                        <span style="color: #e5786d;">help</span>=<span style="color: #95e454;">'disables CUDA training'</span>)
    parser.add_argument(<span style="color: #95e454;">'--seed'</span>, <span style="color: #e5786d;">type</span>=<span style="color: #e5786d;">int</span>, default=1, metavar=<span style="color: #95e454;">'S'</span>,
                        <span style="color: #e5786d;">help</span>=<span style="color: #95e454;">'random seed (default: 1)'</span>)
    parser.add_argument(<span style="color: #95e454;">'--log-interval'</span>, <span style="color: #e5786d;">type</span>=<span style="color: #e5786d;">int</span>, default=10, metavar=<span style="color: #95e454;">'N'</span>,
                        <span style="color: #e5786d;">help</span>=<span style="color: #95e454;">'how many batches to wait before logging training status'</span>)

    parser.add_argument(<span style="color: #95e454;">'--save-model'</span>, action=<span style="color: #95e454;">'store_true'</span>, default=<span style="color: #e5786d; font-weight: bold;">False</span>,
                        <span style="color: #e5786d;">help</span>=<span style="color: #95e454;">'For Saving the current Model'</span>)
    <span style="color: #cae682;">args</span> = parser.parse_args()
    <span style="color: #cae682;">use_cuda</span> = <span style="color: #8ac6f2; font-weight: bold;">not</span> args.no_cuda <span style="color: #8ac6f2; font-weight: bold;">and</span> torch.cuda.is_available()
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">random seed</span>
    torch.manual_seed(args.seed)

    <span style="color: #cae682;">device</span> = torch.device(<span style="color: #95e454;">"cuda"</span> <span style="color: #8ac6f2; font-weight: bold;">if</span> use_cuda <span style="color: #8ac6f2; font-weight: bold;">else</span> <span style="color: #95e454;">"cpu"</span>)

    <span style="color: #cae682;">kwargs</span> = {<span style="color: #95e454;">'num_workers'</span>: 1, <span style="color: #95e454;">'pin_memory'</span>: <span style="color: #e5786d; font-weight: bold;">True</span>} <span style="color: #8ac6f2; font-weight: bold;">if</span> use_cuda <span style="color: #8ac6f2; font-weight: bold;">else</span> {}
    <span style="color: #cae682;">train_loader</span> = torch.utils.data.DataLoader(
        datasets.MNIST(<span style="color: #95e454;">'../data'</span>, train=<span style="color: #e5786d; font-weight: bold;">True</span>, download=<span style="color: #e5786d; font-weight: bold;">True</span>,
                       transform=transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.1307,), (0.3081,))
                       ])),
        batch_size=args.batch_size, shuffle=<span style="color: #e5786d; font-weight: bold;">True</span>, **kwargs)
    <span style="color: #cae682;">test_loader</span> = torch.utils.data.DataLoader(
        datasets.MNIST(<span style="color: #95e454;">'../data'</span>, train=<span style="color: #e5786d; font-weight: bold;">False</span>, transform=transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.1307,), (0.3081,))
                       ])),
        batch_size=args.test_batch_size, shuffle=<span style="color: #e5786d; font-weight: bold;">True</span>, **kwargs)

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">load model to GPU</span>
    <span style="color: #cae682;">model</span>: nn.Module = Net()
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(model.shape)</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(model.parameters())</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">params = list(model.)</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print('params', params)</span>
    <span style="color: #cae682;">params</span> = <span style="color: #e5786d;">sum</span>(p.numel() <span style="color: #8ac6f2; font-weight: bold;">for</span> p <span style="color: #8ac6f2; font-weight: bold;">in</span> model.parameters() <span style="color: #8ac6f2; font-weight: bold;">if</span> p.requires_grad)
    <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"Trainable parameters: </span>{params:,}<span style="color: #95e454;">"</span>)
    <span style="color: #cae682;">model</span> = Net().to(device)

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">optimizer</span>
    <span style="color: #cae682;">optimizer</span> = optim.Adadelta(model.parameters(), lr=args.lr)

    <span style="color: #cae682;">scheduler</span> = StepLR(optimizer, step_size=1, gamma=args.gamma)
    <span style="color: #8ac6f2; font-weight: bold;">for</span> epoch <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(1, args.epochs + 1):
h        test(args, model, device, test_loader)
        scheduler.step()

    <span style="color: #8ac6f2; font-weight: bold;">if</span> args.save_model:
        torch.save(model.state_dict(), <span style="color: #95e454;">"mnist_cnn.pt"</span>)


<span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #e5786d;">__name__</span> == <span style="color: #95e454;">'__main__'</span>:
    main()

</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgea4f7fc" class="outline-3">
<h3 id="orgea4f7fc"><span class="section-number-3">14.18.</span> LSTM</h3>
<div class="outline-text-3" id="text-14-18">
<ul class="org-ul">
<li>tutor <a href="https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html">https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html</a></li>
<li>doc <a href="https://pytorch.org/docs/stable/nn.html#recurrent-layers">https://pytorch.org/docs/stable/nn.html#recurrent-layers</a></li>
<li>from Stratch <a href="https://mlexplained.com/2019/02/15/building-an-lstm-from-scratch-in-pytorch-lstms-in-depth-part-1/">https://mlexplained.com/2019/02/15/building-an-lstm-from-scratch-in-pytorch-lstms-in-depth-part-1/</a></li>
<li>article <a href="https://towardsdatascience.com/lstm-for-time-series-prediction-de8aeb26f2ca">https://towardsdatascience.com/lstm-for-time-series-prediction-de8aeb26f2ca</a></li>
<li>article <a href="https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/">https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/</a></li>
<li>github chinese <a href="https://github.com/TankZhouFirst/Pytorch-LSTM-Stock-Price-Predict/blob/master/LSTM%E5%AE%9E%E7%8E%B0%E8%82%A1%E7%A5%A8%E9%A2%84%E6%B5%8B--pytorch%20%E7%89%88%E6%9C%AC-V2.0.ipynb">https://github.com/TankZhouFirst/Pytorch-LSTM-Stock-Price-Predict/blob/master/LSTM%E5%AE%9E%E7%8E%B0%E8%82%A1%E7%A5%A8%E9%A2%84%E6%B5%8B--pytorch%20%E7%89%88%E6%9C%AC-V2.0.ipynb</a></li>
</ul>
</div>

<div id="outline-container-org6142a6c" class="outline-4">
<h4 id="org6142a6c"><span class="section-number-4">14.18.1.</span> nn.LSTM</h4>
<div class="outline-text-4" id="text-14-18-1">
<p>
expects all of its inputs to be 3D tensors:
</p>
<ul class="org-ul">
<li>sequence itself</li>
<li>indexes instances in the mini-batch</li>
<li>indexes elements of the input</li>
</ul>

<pre class="example">
rnn = nn.LSTM(input_size=10, hidden_size=20, num_layers=2)
input = torch.randn(5, 3, 10)
h0 = torch.randn(2, 3, 20) # layers, batch size, hidden
c0 = torch.randn(2, 3, 20)
output, (hn, cn) = rnn(input, (h0, c0))
</pre>


<p>
If the following conditions are satisfied, persistent algorithm can be selected to improve performance:
</p>
<ol class="org-ol">
<li>cudnn is enabled</li>
<li>input data is on the GPU</li>
<li>input data has dtype torch.float16</li>
<li>V100 GPU is used,</li>
<li>input data is not in PackedSequence format</li>
</ol>
</div>
</div>
<div id="outline-container-org320bbe3" class="outline-4">
<h4 id="org320bbe3"><span class="section-number-4">14.18.2.</span> nn.LSTMCell</h4>
<div class="outline-text-4" id="text-14-18-2">
<pre class="example">
rnn = nn.LSTMCell(input_size=10, hidden_size=20)
input = torch.randn(6, 3, 10) # 3=batch size
hx = torch.randn(3, 20) # batch_size, hidden_size
cx = torch.randn(3, 20)
output = []
for i in range(6):
  hx, cx = rnn(input[i], (hx, cx))
  output.append(hx)
</pre>
</div>
</div>

<div id="outline-container-org22ce181" class="outline-4">
<h4 id="org22ce181"><span class="section-number-4">14.18.3.</span> numbers of parameters</h4>
<div class="outline-text-4" id="text-14-18-3">
<pre class="example">
gate_size = 4 * hidden_size # = 4
w_ih = Parameter(torch.Tensor(gate_size, layer_input_size))
w_hh = Parameter(torch.Tensor(gate_size, hidden_size))
b_ih = Parameter(torch.Tensor(gate_size))
</pre>

<pre class="example">
b_hh = Parameter(torch.Tensor(gate_size))
layer_params = (w_ih, w_hh, b_ih, b_hh) # one lstm
</pre>

<p>
4*4 = 16 parameters
</p>
<pre class="example">
4*(4*is + 4*hs  + 4 + 4) # for first layer
</pre>
</div>
</div>
<div id="outline-container-orgd95f61b" class="outline-4">
<h4 id="orgd95f61b"><span class="section-number-4">14.18.4.</span> basic</h4>
<div class="outline-text-4" id="text-14-18-4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> torch
<span style="color: #8ac6f2; font-weight: bold;">import</span> torch.nn <span style="color: #8ac6f2; font-weight: bold;">as</span> nn

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">num_layers = 1, bias=True, bidirectional=False</span>
<span style="color: #cae682;">lstm</span> = nn.LSTM(input_size=1, hidden_size=1)
<span style="color: #cae682;">inputs</span> = [torch.randn(1, 1) <span style="color: #8ac6f2; font-weight: bold;">for</span> _ <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(5)]  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">make a sequence of length 5</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">initialize the hidden state.</span>
<span style="color: #cae682;">hidden</span> = (torch.randn(1, 1, 1),
          torch.randn(1, 1, 1))
<span style="color: #8ac6f2; font-weight: bold;">for</span> i <span style="color: #8ac6f2; font-weight: bold;">in</span> inputs:
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Step through the sequence one element at a time.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">after each step, hidden contains the hidden state.</span>
    <span style="color: #cae682;">out</span>, <span style="color: #cae682;">hidden</span> = lstm(i.view(1, 1, -1), hidden)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">alternatively, we can do the entire sequence all at once.</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">the first value returned by LSTM is all of the hidden states throughout</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">the sequence. the second is just the most recent hidden state</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">(compare the last slice of "out" with "hidden" below, they are the same)</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">The reason for this is that:</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">"out" will give you access to all hidden states in the sequence</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">"hidden" will allow you to continue the sequence and backpropagate,</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">by passing it as an argument  to the lstm at a later time</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Add the extra 2nd dimension</span>
<span style="color: #cae682;">inputs</span> = torch.cat(inputs).view(<span style="color: #e5786d;">len</span>(inputs), 1, -1)
<span style="color: #cae682;">hidden</span> = (torch.randn(1, 1, 1), torch.randn(1, 1, 1))  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">clean out hidden state</span>
out, (<span style="color: #cae682;">hn</span>, <span style="color: #cae682;">cn</span>) = lstm(inputs, hidden)
<span style="color: #cae682;">params</span> = <span style="color: #e5786d;">sum</span>(p.numel() <span style="color: #8ac6f2; font-weight: bold;">for</span> p <span style="color: #8ac6f2; font-weight: bold;">in</span> lstm.parameters())
<span style="color: #e5786d;">print</span>(<span style="color: #e5786d;">list</span>(lstm.parameters()))
<span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"Trainable parameters: </span>{params:,}<span style="color: #95e454;">"</span>)
<span style="color: #e5786d;">print</span>(out)
<span style="color: #e5786d;">print</span>(hn)
<span style="color: #e5786d;">print</span>(cn)

</pre>
</div>
</div>
</div>

<div id="outline-container-org0494bf2" class="outline-4">
<h4 id="org0494bf2"><span class="section-number-4">14.18.5.</span> tagging model</h4>
<div class="outline-text-4" id="text-14-18-5">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">class</span> <span style="color: #92a65e; font-weight: bold;">LSTMTagger</span>(nn.Module):

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__init__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, embedding_dim, hidden_dim, vocab_size, tagset_size):
        <span style="color: #e5786d;">super</span>(LSTMTagger, <span style="color: #8ac6f2; font-weight: bold;">self</span>).__init__()
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">hidden_dim</span> = hidden_dim

        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">word_embeddings</span> = nn.Embedding(vocab_size, embedding_dim)

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">The LSTM takes word embeddings as inputs, and outputs hidden states</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">with dimensionality hidden_dim.</span>
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">lstm</span> = nn.LSTM(embedding_dim, hidden_dim)

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">The linear layer that maps from hidden state space to tag space</span>
        <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #cae682;">hidden2tag</span> = nn.Linear(hidden_dim, tagset_size)

    <span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">forward</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, sentence):
        <span style="color: #cae682;">embeds</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.word_embeddings(sentence)
        <span style="color: #cae682;">lstm_out</span>, <span style="color: #cae682;">_</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.lstm(embeds.view(<span style="color: #e5786d;">len</span>(sentence), 1, -1))
        <span style="color: #cae682;">tag_space</span> = <span style="color: #8ac6f2; font-weight: bold;">self</span>.hidden2tag(lstm_out.view(<span style="color: #e5786d;">len</span>(sentence), -1))
        <span style="color: #cae682;">tag_scores</span> = F.log_softmax(tag_space, dim=1)
        <span style="color: #8ac6f2; font-weight: bold;">return</span> tag_scores

<span style="color: #cae682;">model</span> = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, <span style="color: #e5786d;">len</span>(word_to_ix), <span style="color: #e5786d;">len</span>(tag_to_ix))
<span style="color: #cae682;">loss_function</span> = nn.NLLLoss()
<span style="color: #cae682;">optimizer</span> = optim.SGD(model.parameters(), lr=0.1)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">See what the scores are before training</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Note that element i,j of the output is the score for tag j for word i.</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Here we don't need to train, so the code is wrapped in torch.no_grad()</span>
<span style="color: #8ac6f2; font-weight: bold;">with</span> torch.no_grad():
    <span style="color: #cae682;">inputs</span> = prepare_sequence(training_data[0][0], word_to_ix)
    <span style="color: #cae682;">tag_scores</span> = model(inputs)
    <span style="color: #e5786d;">print</span>(tag_scores)

<span style="color: #8ac6f2; font-weight: bold;">for</span> epoch <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(300):  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">again, normally you would NOT do 300 epochs, it is toy data</span>
    <span style="color: #8ac6f2; font-weight: bold;">for</span> sentence, tags <span style="color: #8ac6f2; font-weight: bold;">in</span> training_data:
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Step 1. Remember that Pytorch accumulates gradients.</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">We need to clear them out before each instance</span>
        model.zero_grad()

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Step 2. Get our inputs ready for the network, that is, turn them into</span>
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Tensors of word indices.</span>
        <span style="color: #cae682;">sentence_in</span> = prepare_sequence(sentence, word_to_ix)
        <span style="color: #cae682;">targets</span> = prepare_sequence(tags, tag_to_ix)

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Step 3. Run our forward pass.</span>
        <span style="color: #cae682;">tag_scores</span> = model(sentence_in)

        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Step 4. Compute the loss, gradients, and update the parameters by</span>
        <span style="color: #fa8072;">#  </span><span style="color: #99968b; font-style: italic;">calling optimizer.step()</span>
        <span style="color: #cae682;">loss</span> = loss_function(tag_scores, targets)
        loss.backward()
        optimizer.step()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">See what the scores are after training</span>
<span style="color: #8ac6f2; font-weight: bold;">with</span> torch.no_grad():
    <span style="color: #cae682;">inputs</span> = prepare_sequence(training_data[0][0], word_to_ix)
    <span style="color: #cae682;">tag_scores</span> = model(inputs)

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">The sentence is "the dog ate the apple".  i,j corresponds to score for tag j</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">for word i. The predicted tag is the maximum scoring tag.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Here, we can see the predicted sequence below is 0 1 2 0 1</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">since 0 is index of the maximum value of row 1,</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">1 is the index of maximum value of row 2, etc.</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Which is DET NOUN VERB DET NOUN, the correct sequence!</span>
    <span style="color: #e5786d;">print</span>(tag_scores)

</pre>
</div>
</div>
</div>
<div id="outline-container-org9c5b0e3" class="outline-4">
<h4 id="org9c5b0e3"><span class="section-number-4">14.18.6.</span> variable-sized mini-batches</h4>
<div class="outline-text-4" id="text-14-18-6">
<p>
<a href="https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e">https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e</a>
</p>
</div>
</div>
<div id="outline-container-org4b069a9" class="outline-4">
<h4 id="org4b069a9"><span class="section-number-4">14.18.7.</span> GPU CUDA</h4>
<div class="outline-text-4" id="text-14-18-7">
<p>
device = torch.device("cuda:0" if torch.cuda.is<sub>available</sub>() else "cpu")
if torch.cuda.is<sub>available</sub>():
    input = input.cuda()  # GPU
    target = target.cuda()  # GPU
    test<sub>input</sub> = test<sub>input.cuda</sub>()
    test<sub>target</sub> = test<sub>target.cuda</sub>()
</p>

<p>
seq: Model = Sequence()
seq.double()
seq = seq.to(device)  # GPU
</p>

<p>
self.hidden = (torch.rand(self.levels, input.size(0), 51, dtype=torch.double),  # layers, batch, hidden
		   torch.rand(self.levels, input.size(0), 51, dtype=torch.double))
if torch.cuda.is<sub>available</sub>():
    self.hidden = (self.hidden[0].cuda(), self.hidden[1].cuda())
</p>
</div>
</div>
<div id="outline-container-org17fb2c7" class="outline-4">
<h4 id="org17fb2c7"><span class="section-number-4">14.18.8.</span> SGD</h4>
<div class="outline-text-4" id="text-14-18-8">
<p>
optim = torch.optim.SGD(model.parameters(), lr=0.01)
lr = 0.5 * 1.2
    optimizer = torch.optim.SGD(seq.parameters(), lr=lr, momentum=0.2)
    for s in range(STEPS):
        lr = lr / 1.2
        print("lr", lr)
</p>

<p>
for g in optimizer.param<sub>groups</sub>:
    g['lr'] = lr
</p>
</div>
</div>
</div>
<div id="outline-container-org7f6369e" class="outline-3">
<h3 id="org7f6369e"><span class="section-number-3">14.19.</span> Distributed - torch.distributed</h3>
<div class="outline-text-3" id="text-14-19">
</div>
<div id="outline-container-org1796adc" class="outline-4">
<h4 id="org1796adc"><span class="section-number-4">14.19.1.</span> overview</h4>
<div class="outline-text-4" id="text-14-19-1">
<ul class="org-ul">
<li>DistributedDataParallel (DDP)
<ul class="org-ul">
<li>torch.nn.parallel.DistributedDataParallel</li>
</ul></li>
<li><p>
FullyShardedDataParallel (FSDP) - “beta”  higher level of complexity
</p>
<ul class="org-ul">
<li>indicate which submodules of their model to wrap together in an FSDP instance used for state sharding, or</li>
</ul>
<p>
manually wrap submodules in FSDP instances
</p>
<ul class="org-ul">
<li>If FSDP is used without wrapping submodules in separate instances, it falls back to operating similarly to</li>
</ul>
<p>
DDP, but without bucketing
</p>
<ul class="org-ul">
<li>torch.distributed.fsdp</li>
</ul></li>
</ul>


<p>
torch.distributed
</p>

<p>
Two approaches to run:
</p>
<ul class="org-ul">
<li>torch.distributed.launch</li>
<li>torchrun (elastic)</li>
</ul>

<p>
model is wrapped with DistributedDataParallel:
</p>
<ul class="org-ul">
<li>add hooks in forward() and backward() - for communicating</li>
</ul>

<p>
torch.distributed.launch
</p>
</div>
</div>
<div id="outline-container-orga01dbea" class="outline-4">
<h4 id="orga01dbea"><span class="section-number-4">14.19.2.</span> torch.distributed.rpc</h4>
<div class="outline-text-4" id="text-14-19-2">
</div>
<ol class="org-ol">
<li><a id="orgda2bef0"></a>links<br />
<div class="outline-text-5" id="text-14-19-2-1">
<ul class="org-ul">
<li>tutorial <a href="https://pytorch.org/tutorials/intermediate/rpc_tutorial.html">https://pytorch.org/tutorials/intermediate/rpc_tutorial.html</a></li>
<li>tutorial <a href="https://pytorch.org/tutorials/intermediate/dist_pipeline_parallel_tutorial.html">https://pytorch.org/tutorials/intermediate/dist_pipeline_parallel_tutorial.html</a></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgd9b7b28" class="outline-4">
<h4 id="orgd9b7b28"><span class="section-number-4">14.19.3.</span> FSDP</h4>
<div class="outline-text-4" id="text-14-19-3">
<p>
<a href="https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html">https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html</a>
<a href="https://github.com/pytorch/examples/blob/main/distributed/FSDP/T5_training.py">https://github.com/pytorch/examples/blob/main/distributed/FSDP/T5_training.py</a>
</p>

<p>
FSDP units - parts of model that will be sharded
</p>
</div>
<ol class="org-ol">
<li><a id="org3a39e8d"></a>performance optimizations<br />
<div class="outline-text-5" id="text-14-19-3-1">
<ul class="org-ul">
<li>Mixed Precision - with BFloat16 resulted in ~5x improvement versus FP32</li>
<li>Activation Checkpointing (AC) - reinvesting the freed memory from the checkpoints into larger batch size</li>
<li>Transformer Wrapping Policy vs default wrapping policy. 20-25%
slower! free 33-38% GPU memory! Freed up memory can be used to increase
batch size for speed.</li>
<li><p>
Full Shard Strategy versus zero2 (DDP) resulted in 1.5x improvement.
</p>

<p>
transformer wrapping policy and activation checkpointing - required for 3 nodes - T5 11B model
</p>

<p>
sharding<sub>strategy</sub> -
</p></li>
<li>FULL<sub>SHARD</sub> - default -</li>
<li>SHARD<sub>GRAD</sub><sub>OP</sub> - Zero2 mode - model parameters are not freed after forward pass, reducing communication needs</li>
<li>NO<sub>SHARD</sub> - DDP mode , just copy of model, only grad synch needed</li>
</ul>
</div>
</li>

<li><a id="org2949c33"></a>ex tutorial<br />
<div class="outline-text-5" id="text-14-19-3-2">
<div class="org-src-container">
<pre class="src src-python">
<span style="color: #8ac6f2; font-weight: bold;">import</span> torch.distributed <span style="color: #8ac6f2; font-weight: bold;">as</span> dist


<span style="color: #cae682;">world_size</span> = 2
<span style="color: #cae682;">rank</span> = 0 <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">per worker 0 ... ?</span>

fsdp_main(rank, world_size, batch_size, test_batch_size

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">fsdp_main</span>(rank, world_size, args):
    setup(rank, world_size)

    transform=transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])

    dataset1 = datasets.MNIST(<span style="color: #95e454;">'../data'</span>, train=<span style="color: #e5786d; font-weight: bold;">True</span>, download=<span style="color: #e5786d; font-weight: bold;">True</span>,
                        transform=transform)
    dataset2 = datasets.MNIST(<span style="color: #95e454;">'../data'</span>, train=<span style="color: #e5786d; font-weight: bold;">False</span>,
                        transform=transform)

    sampler1 = DistributedSampler(dataset1, rank=rank, num_replicas=world_size, shuffle=<span style="color: #e5786d; font-weight: bold;">True</span>)
    sampler2 = DistributedSampler(dataset2, rank=rank, num_replicas=world_size)

    train_kwargs = {<span style="color: #95e454;">'batch_size'</span>: args.batch_size, <span style="color: #95e454;">'sampler'</span>: sampler1}
    test_kwargs = {<span style="color: #95e454;">'batch_size'</span>: args.test_batch_size, <span style="color: #95e454;">'sampler'</span>: sampler2}
    cuda_kwargs = {<span style="color: #95e454;">'num_workers'</span>: 2,
                    <span style="color: #95e454;">'pin_memory'</span>: <span style="color: #e5786d; font-weight: bold;">True</span>,
                    <span style="color: #95e454;">'shuffle'</span>: <span style="color: #e5786d; font-weight: bold;">False</span>}
    train_kwargs.update(cuda_kwargs)
    test_kwargs.update(cuda_kwargs)

    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)
    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)
    my_auto_wrap_policy = functools.partial(
        size_based_auto_wrap_policy, min_num_params=100
    )
    torch.cuda.set_device(rank)


    init_start_event = torch.cuda.Event(enable_timing=<span style="color: #e5786d; font-weight: bold;">True</span>)
    init_end_event = torch.cuda.Event(enable_timing=<span style="color: #e5786d; font-weight: bold;">True</span>)

    model = Net().to(rank)

    model = FSDP(model,
                 fsdp_auto_wrap_policy=my_auto_wrap_policy,
                 cpu_offload=CPUOffload(offload_params=<span style="color: #e5786d; font-weight: bold;">True</span>))

    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)

    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)
    init_start_event.record()
    <span style="color: #8ac6f2; font-weight: bold;">for</span> epoch <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(1, args.epochs + 1):
        train(args, model, rank, world_size, train_loader, optimizer, epoch, sampler=sampler1)
        test(model, rank, world_size, test_loader)
        scheduler.step()

    init_end_event.record()

    <span style="color: #8ac6f2; font-weight: bold;">if</span> rank == 0:
        <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"CUDA event elapsed time: </span>{init_start_event.elapsed_time(init_end_event) / 1000}<span style="color: #95e454;">sec"</span>)
        <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"</span>{model}<span style="color: #95e454;">"</span>)

    <span style="color: #8ac6f2; font-weight: bold;">if</span> args.save_model:
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">use a barrier to make sure training is done on all ranks</span>
        dist.barrier()
        <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">state_dict for FSDP model is only available on Nightlies for now</span>
        states = model.state_dict()
        <span style="color: #8ac6f2; font-weight: bold;">if</span> rank == 0:
            torch.save(states, <span style="color: #95e454;">"mnist_cnn.pt"</span>)

    cleanup()
</pre>
</div>
</div>
</li>

<li><a id="org401139e"></a>ex t5<br />
<div class="outline-text-5" id="text-14-19-3-3">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> torch.distributed.fsdp <span style="color: #8ac6f2; font-weight: bold;">import</span> (
    FullyShardedDataParallel <span style="color: #8ac6f2; font-weight: bold;">as</span> FSDP,
    CPUOffload,
    MixedPrecision,
    BackwardPrefetch,
    ShardingStrategy,
    FullStateDictConfig,
    StateDictType,
)
<span style="color: #8ac6f2; font-weight: bold;">from</span> torch.utils.data.distributed <span style="color: #8ac6f2; font-weight: bold;">import</span> DistributedSampler

<span style="color: #8ac6f2; font-weight: bold;">class</span> <span style="color: #92a65e; font-weight: bold;">train_config</span>:
    <span style="color: #cae682;">model_name</span>: <span style="color: #e5786d;">str</span>=<span style="color: #95e454;">"t5-base"</span>
    <span style="color: #cae682;">run_validation</span>: <span style="color: #e5786d;">bool</span>=<span style="color: #e5786d; font-weight: bold;">True</span>
    <span style="color: #cae682;">batch_size_training</span>: <span style="color: #e5786d;">int</span>=4
    <span style="color: #cae682;">num_workers_dataloader</span>: <span style="color: #e5786d;">int</span>=2
    <span style="color: #cae682;">lr</span>: <span style="color: #e5786d;">float</span>=0.002
    <span style="color: #cae682;">weight_decay</span>: <span style="color: #e5786d;">float</span>=0.0
    <span style="color: #cae682;">gamma</span>: <span style="color: #e5786d;">float</span>= 0.85
    <span style="color: #cae682;">use_fp16</span>: <span style="color: #e5786d;">bool</span>=<span style="color: #e5786d; font-weight: bold;">False</span>
    <span style="color: #cae682;">mixed_precision</span>: <span style="color: #e5786d;">bool</span>=<span style="color: #e5786d; font-weight: bold;">True</span>
    <span style="color: #cae682;">save_model</span>: <span style="color: #e5786d;">bool</span>=<span style="color: #e5786d; font-weight: bold;">False</span>



<span style="color: #8ac6f2; font-weight: bold;">class</span> <span style="color: #92a65e; font-weight: bold;">fsdp_config</span>:
    <span style="color: #cae682;">mixed_precision</span>: <span style="color: #e5786d;">bool</span>=<span style="color: #e5786d; font-weight: bold;">True</span>
    <span style="color: #cae682;">use_fp16</span>: <span style="color: #e5786d;">bool</span>=<span style="color: #e5786d; font-weight: bold;">False</span>
    <span style="color: #cae682;">seed</span>: <span style="color: #e5786d;">int</span>=42
    <span style="color: #cae682;">fsdp_activation_checkpointing</span>: <span style="color: #e5786d;">bool</span>=<span style="color: #e5786d; font-weight: bold;">True</span>
    <span style="color: #cae682;">limit_all_gathers</span>: <span style="color: #e5786d;">bool</span>=<span style="color: #e5786d; font-weight: bold;">True</span>
    <span style="color: #cae682;">sharding_strategy</span>: ShardingStrategy = ShardingStrategy.FULL_SHARD <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">HYBRID_SHARD, SHARD_GRAD_OP</span>
    <span style="color: #cae682;">checkpoint_type</span>: StateDictType = StateDictType.FULL_STATE_DICT <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">alternatively can use SHARDED_STATE_DICT to avoid OOMs</span>
    <span style="color: #cae682;">save_optimizer</span>: <span style="color: #e5786d;">bool</span>=<span style="color: #e5786d; font-weight: bold;">False</span>


<span style="color: #8ac6f2; font-weight: bold;">from</span> torch.distributed.fsdp <span style="color: #8ac6f2; font-weight: bold;">import</span> (
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">FullyShardedDataParallel as FSDP,</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">CPUOffload,</span>
    MixedPrecision,
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">BackwardPrefetch,</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">ShardingStrategy,</span>
)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">requires grad scaler in main loop</span>
<span style="color: #cae682;">fpSixteen</span> = MixedPrecision(
    param_dtype=torch.float16,
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Gradient communication precision.</span>
    reduce_dtype=torch.float16,
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Buffer precision.</span>
    buffer_dtype=torch.float16,
)

<span style="color: #cae682;">bfSixteen</span> = MixedPrecision(
    param_dtype=torch.bfloat16,
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Gradient communication precision.</span>
    reduce_dtype=torch.bfloat16,
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Buffer precision.</span>
    buffer_dtype=torch.bfloat16,
)

<span style="color: #cae682;">bfSixteen_working</span> = MixedPrecision(
    param_dtype=torch.float32,
    reduce_dtype=torch.bfloat16,
    buffer_dtype=torch.bfloat16,
)

<span style="color: #cae682;">fp32_policy</span> = MixedPrecision(
    param_dtype=torch.float32,
    reduce_dtype=torch.float32,
    buffer_dtype=torch.float32,
)


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">get_policies</span>(cfg, rank):

    <span style="color: #f08080; font-style: italic;">"""establish current policies for mixed precision and fsdp wrapping"""</span>

    <span style="color: #cae682;">mixed_precision_policy</span> = <span style="color: #e5786d; font-weight: bold;">None</span>
    <span style="color: #cae682;">wrapping_policy</span> = <span style="color: #e5786d; font-weight: bold;">None</span>

    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">mixed precision -----</span>
    <span style="color: #8ac6f2; font-weight: bold;">if</span> cfg.mixed_precision:
        <span style="color: #cae682;">bfloat_available</span> = bfloat_support()
        <span style="color: #8ac6f2; font-weight: bold;">if</span> bfloat_available <span style="color: #8ac6f2; font-weight: bold;">and</span> <span style="color: #8ac6f2; font-weight: bold;">not</span> cfg.use_fp16:
            <span style="color: #cae682;">mixed_precision_policy</span> = policies.bfSixteen
            <span style="color: #8ac6f2; font-weight: bold;">if</span> rank == 0:
                <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"bFloat16 enabled for mixed precision - using bfSixteen policy"</span>)
        <span style="color: #8ac6f2; font-weight: bold;">elif</span> cfg.use_fp16:
            <span style="color: #cae682;">mixed_precision_policy</span> = policies.fpSixteen
            <span style="color: #8ac6f2; font-weight: bold;">if</span> rank == 0:
                <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"FP16 enabled. "</span>)
        <span style="color: #8ac6f2; font-weight: bold;">else</span>:
            <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">mixed_precision_policy = policies.fpSixteen</span>
            <span style="color: #e5786d;">print</span>(
                f<span style="color: #95e454;">"bFloat16 support not present. Will use FP32, and not mixed precision"</span>
            )

    <span style="color: #cae682;">wrapping_policy</span> = policies.get_t5_wrapper()

    <span style="color: #8ac6f2; font-weight: bold;">return</span> mixed_precision_policy, wrapping_policy


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">setup</span>():
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">initialize the process group</span>
    dist.init_process_group(<span style="color: #95e454;">"nccl"</span>)


<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">cleanup</span>():
    dist.destroy_process_group()

<span style="color: #cae682;">local_rank</span> = <span style="color: #e5786d;">int</span>(os.environ[<span style="color: #95e454;">'LOCAL_RANK'</span>])
<span style="color: #cae682;">rank</span> = <span style="color: #e5786d;">int</span>(os.environ[<span style="color: #95e454;">'RANK'</span>])
<span style="color: #cae682;">world_size</span> = <span style="color: #e5786d;">int</span>(os.environ[<span style="color: #95e454;">'WORLD_SIZE'</span>])

<span style="color: #cae682;">run_validation</span> = <span style="color: #e5786d; font-weight: bold;">True</span>
<span style="color: #cae682;">track_memory</span> = <span style="color: #e5786d; font-weight: bold;">True</span>
<span style="color: #cae682;">epochs</span> = 1
<span style="color: #cae682;">batch_size</span> = 1
<span style="color: #cae682;">test_batch_size</span> = 1

<span style="color: #cae682;">sampler1</span> = DistributedSampler(train_dataset, rank=rank, num_replicas=world_size, shuffle=<span style="color: #e5786d; font-weight: bold;">True</span>)
<span style="color: #cae682;">sampler2</span> = DistributedSampler(val_dataset, rank=rank, num_replicas=world_size)

setup()

<span style="color: #cae682;">train_kwargs</span> = {<span style="color: #95e454;">'batch_size'</span>: batch_size, <span style="color: #95e454;">'sampler'</span>: sampler1}
<span style="color: #cae682;">test_kwargs</span> = {<span style="color: #95e454;">'batch_size'</span>: test_batch_size, <span style="color: #95e454;">'sampler'</span>: sampler2}
<span style="color: #cae682;">cuda_kwargs</span> = {<span style="color: #95e454;">'num_workers'</span>: 2,
               <span style="color: #95e454;">'pin_memory'</span>: <span style="color: #e5786d; font-weight: bold;">True</span>,
               <span style="color: #95e454;">'shuffle'</span>: <span style="color: #e5786d; font-weight: bold;">False</span>}
train_kwargs.update(cuda_kwargs)
test_kwargs.update(cuda_kwargs)

<span style="color: #cae682;">train_loader</span> = torch.utils.data.DataLoader(train_dataset,**train_kwargs)
<span style="color: #cae682;">val_loader</span> = torch.utils.data.DataLoader(val_dataset, **test_kwargs)

torch.cuda.set_device(local_rank)

<span style="color: #cae682;">mixed_precision_policy</span>, <span style="color: #cae682;">t5_auto_wrap_policy</span> = get_policies(train_config, rank)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Apply FSDP wrapping to the model</span>
<span style="color: #cae682;">model</span> = FSDP(model,
        auto_wrap_policy=t5_auto_wrap_policy,
        mixed_precision=mixed_precision_policy,
        sharding_strategy=fsdp_config.sharding_strategy,
        device_id=torch.cuda.current_device(),
        limit_all_gathers=fsdp_config.limit_all_gathers)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">if fsdp_config.fsdp_activation_checkpointing:</span>
<span style="color: #fa8072;">#         </span><span style="color: #99968b; font-style: italic;">policies.apply_fsdp_checkpointing(model)</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Set up optimizer and scheduler</span>
<span style="color: #cae682;">optimizer</span> = optim.AdamW(model.parameters(), lr=train_config.lr)

<span style="color: #cae682;">scheduler</span> = StepLR(optimizer, step_size=1, gamma=train_config.gamma)

<span style="color: #cae682;">best_val_loss</span> = <span style="color: #e5786d;">float</span>(<span style="color: #95e454;">"inf"</span>)
<span style="color: #cae682;">curr_val_loss</span> = <span style="color: #e5786d;">float</span>(<span style="color: #95e454;">"inf"</span>)
<span style="color: #cae682;">file_save_name</span> = <span style="color: #95e454;">"T5-model-"</span>

<span style="color: #8ac6f2; font-weight: bold;">if</span> rank == 0:
    <span style="color: #cae682;">time_of_run</span> = get_date_of_run()
    <span style="color: #cae682;">dur</span> = []
    <span style="color: #cae682;">train_acc_tracking</span> = []
    <span style="color: #cae682;">val_acc_tracking</span> = []
    <span style="color: #cae682;">training_start_time</span> = time.time()

<span style="color: #8ac6f2; font-weight: bold;">if</span> rank == 0 <span style="color: #8ac6f2; font-weight: bold;">and</span> track_memory:
    <span style="color: #cae682;">mem_alloc_tracker</span> = []
    <span style="color: #cae682;">mem_reserved_tracker</span> = []


<span style="color: #8ac6f2; font-weight: bold;">for</span> epoch <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(1, epochs + 1):
    <span style="color: #cae682;">t0</span> = time.time()
    <span style="color: #cae682;">train_accuracy</span> = train(model, rank, world_size, train_loader, optimizer, epoch, sampler=sampler1)
    <span style="color: #8ac6f2; font-weight: bold;">if</span> run_validation:
        <span style="color: #cae682;">curr_val_loss</span> = validation(model, rank, world_size, val_loader)
    scheduler.step()

    <span style="color: #8ac6f2; font-weight: bold;">if</span> rank == 0:
        <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"--&gt; epoch </span>{epoch}<span style="color: #95e454;"> completed...entering save and stats zone"</span>)

       dur.append(time.time() - t0)
       train_acc_tracking.append(train_accuracy.item())

       <span style="color: #8ac6f2; font-weight: bold;">if</span> run_validation:
           val_acc_tracking.append(curr_val_loss.item())
</pre>
</div>
</div>
</li>
<li><a id="orgb305151"></a>troubleshooting<br />
<div class="outline-text-5" id="text-14-19-3-4">
<p>
RuntimeError: Expected a 'cuda' device type for generator but found 'cpu'
</p>
<ul class="org-ul">
<li>'cuda' is set with torch.set<sub>default</sub><sub>device</sub>("cuda")</li>
<li>shuffled Sampler always create generator = torch.Generator()</li>
<li>Solution: disable shuffle or set torch.set<sub>default</sub><sub>device</sub>("cpu")</li>
</ul>

<p>
RuntimeError: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned
</p>
<ul class="org-ul">
<li>solution: place everythin of CPU according to tutorial</li>
<li>save dataset items to CPU</li>
</ul>

<p>
CUDA error: invalid device ordinal
</p>
<ul class="org-ul">
<li>1694694477 worker-0: CUDA kernel errors might be asynchronously reported at some other API call, so the
stacktrace below might be incorrect.</li>
<li>1694694477 worker-0: For debugging consider passing CUDA<sub>LAUNCH</sub><sub>BLOCKING</sub>=1.</li>
<li>1694694477 worker-0: Compile with `TORCH<sub>USE</sub><sub>CUDA</sub><sub>DSA</sub>` to enable device-side assertions.</li>
<li>Solution: ? I forgot, set .to(device) not .to(rank)</li>
</ul>


<p>
Timed out initializing process group in store based barrier on rank
</p>
<ul class="org-ul">
<li>increase: torch.distributed.init<sub>process</sub><sub>group</sub>(timeout=datetime.timedelta(seconds=1800))</li>
</ul>

<p>
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
</p>
<ul class="org-ul">
<li>pickle.load problem with read<sub>image</sub> no problem</li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">try</span>:
    torch.multiprocessing.set_start_method(<span style="color: #95e454;">'spawn'</span>,force=<span style="color: #e5786d; font-weight: bold;">True</span>)
<span style="color: #8ac6f2; font-weight: bold;">except</span> <span style="color: #92a65e; font-weight: bold;">RuntimeError</span>:
    <span style="color: #8ac6f2; font-weight: bold;">pass</span>
</pre>
</div>
</div>
</li>
</ol>
</div>

<div id="outline-container-org27cc8c7" class="outline-4">
<h4 id="org27cc8c7"><span class="section-number-4">14.19.4.</span> elastic (launch)</h4>
<div class="outline-text-4" id="text-14-19-4">
<p>
torchrun -  superset of the functionality as <b>torch.distributed.launch</b>
</p>
</div>
</div>
<div id="outline-container-org2e67475" class="outline-4">
<h4 id="org2e67475"><span class="section-number-4">14.19.5.</span> torch.distributed.launch</h4>
<div class="outline-text-4" id="text-14-19-5">
<ol class="org-ol">
<li>dist.init<sub>process</sub><sub>group</sub>(backend, init<sub>method</sub>)</li>
</ol>

<p>
links
</p>
<ul class="org-ul">
<li><a href="https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide">https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide</a></li>
<li><a href="https://pytorch.org/tutorials/intermediate/dist_tuto.html">https://pytorch.org/tutorials/intermediate/dist_tuto.html</a></li>
<li><a href="https://pytorch.org/docs/2.0/distributed.html#initialization">https://pytorch.org/docs/2.0/distributed.html#initialization</a></li>
</ul>
</div>
</div>

<div id="outline-container-orgde523e1" class="outline-4">
<h4 id="orgde523e1"><span class="section-number-4">14.19.6.</span> KubeFlow PyTorchJob</h4>
<div class="outline-text-4" id="text-14-19-6">
<p>
$ env for pod/pytorch-simple-worker-0:
</p>
<div class="org-src-container">
<pre class="src src-sh"><span style="color: #cae682;">KUBERNETES_SERVICE_PORT_HTTPS</span>=443
<span style="color: #cae682;">NVIDIA_VISIBLE_DEVICES</span>=all
<span style="color: #cae682;">KUBERNETES_SERVICE_PORT</span>=443
<span style="color: #cae682;">PYTHONUNBUFFERED</span>=0
<span style="color: #cae682;">HOSTNAME</span>=pytorch-simple-worker-0
<span style="color: #cae682;">MASTER_PORT</span>=23456
<span style="color: #cae682;">PWD</span>=/workspace
<span style="color: #cae682;">NVIDIA_DRIVER_CAPABILITIES</span>=compute,utility
<span style="color: #cae682;">WORLD_SIZE</span>=2
<span style="color: #cae682;">HOME</span>=/root
<span style="color: #cae682;">KUBERNETES_PORT_443_TCP</span>=tcp://10.96.0.1:443
<span style="color: #cae682;">PYTORCH_VERSION</span>=2.0.1
<span style="color: #cae682;">MASTER_ADDR</span>=pytorch-simple-master-0
<span style="color: #cae682;">TERM</span>=xterm
<span style="color: #cae682;">SHLVL</span>=1
<span style="color: #cae682;">KUBERNETES_PORT_443_TCP_PROTO</span>=tcp
<span style="color: #cae682;">KUBERNETES_PORT_443_TCP_ADDR</span>=10.96.0.1
<span style="color: #cae682;">LD_LIBRARY_PATH</span>=/usr/local/nvidia/lib:/usr/local/nvidia/lib64
<span style="color: #cae682;">RANK</span>=1
<span style="color: #cae682;">KUBERNETES_SERVICE_HOST</span>=10.96.0.1
<span style="color: #cae682;">KUBERNETES_PORT</span>=tcp://10.96.0.1:443
<span style="color: #cae682;">KUBERNETES_PORT_443_TCP_PORT</span>=443
</pre>
</div>
</div>
</div>
<div id="outline-container-org3203cfd" class="outline-4">
<h4 id="org3203cfd"><span class="section-number-4">14.19.7.</span> investiage</h4>
<div class="outline-text-4" id="text-14-19-7">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> torch
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"distributed available"</span>, torch.distributed.is_available())
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"distributed initilized"</span>, torch.distributed.is_initialized())
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- CUDA</span>
torch.cuda.is_available() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">True</span>
torch.cuda.device_count() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">1</span>
torch.cuda.current_device() <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">0</span>
torch.cuda.device(0) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&lt;torch.cuda.device at 0x7efce0b03be0&gt;</span>
torch.cuda.get_device_name(0) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">'GeForce GTX 950M'</span>
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"cuda"</span>)
<span style="color: #e5786d;">print</span>(torch.cuda.is_available()) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">True</span>
<span style="color: #e5786d;">print</span>(torch.cuda.device_count()) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">1</span>
<span style="color: #e5786d;">print</span>(torch.cuda.current_device()) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">0</span>
<span style="color: #e5786d;">print</span>(torch.cuda.device(0)) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">&lt;torch.cuda.device at 0x7efce0b03be0&gt;</span>
<span style="color: #e5786d;">print</span>(torch.cuda.get_device_name(0)) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">'GeForce GTX 950M'</span>
<span style="color: #e5786d;">print</span>()
</pre>
</div>
</div>
</div>

<div id="outline-container-org031f06e" class="outline-4">
<h4 id="org031f06e"><span class="section-number-4">14.19.8.</span> links</h4>
<div class="outline-text-4" id="text-14-19-8">
<ul class="org-ul">
<li>main <a href="https://pytorch.org/docs/stable/distributed.html">https://pytorch.org/docs/stable/distributed.html</a></li>
<li>tutorial <a href="https://pytorch.org/tutorials/beginner/dist_overview.html">https://pytorch.org/tutorials/beginner/dist_overview.html</a></li>
<li><a href="https://pyimagesearch.com/2021/10/18/introduction-to-distributed-training-in-pytorch/">https://pyimagesearch.com/2021/10/18/introduction-to-distributed-training-in-pytorch/</a>
<ul class="org-ul">
<li><img src="https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/08/dp_gif.gif?size=650x265&amp;lossy=2&amp;strip=1&amp;webp=1" alt="dp_gif.gif?size=650x265&amp;lossy=2&amp;strip=1&amp;webp=1" /></li>
</ul></li>
<li>overview of torch.distributed <a href="https://pytorch.org/tutorials/beginner/dist_overview.html">https://pytorch.org/tutorials/beginner/dist_overview.html</a></li>
<li>2.0 news <a href="https://pytorch.org/get-started/pytorch-2.0/#distributed">https://pytorch.org/get-started/pytorch-2.0/#distributed</a></li>
<li>DDP <a href="https://pytorch.org/docs/stable/notes/ddp.html">https://pytorch.org/docs/stable/notes/ddp.html</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org797d153" class="outline-3">
<h3 id="org797d153"><span class="section-number-3">14.20.</span> retain<sub>graph</sub></h3>
<div class="outline-text-3" id="text-14-20">
<p>
<a href="https://pytorch.org/docs/stable/autograd.html">https://pytorch.org/docs/stable/autograd.html</a>
</p>

<pre class="example">
loss.backward(retain_graph=True)
</pre>


<p>
LSTM slowed becouse of hidden state saved between. Solutions:
</p>
<ul class="org-ul">
<li>detach/repackage the hidden state in between batches.
<ul class="org-ul">
<li>hidden.detach<sub>()</sub></li>
<li>hidden = hidden.detach()</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org5a7d733" class="outline-3">
<h3 id="org5a7d733"><span class="section-number-3">14.21.</span> memory management</h3>
<div class="outline-text-3" id="text-14-21">
<p>
if a is a tensor:
</p>
<ul class="org-ul">
<li>a.to(torch.device("cpu"/"cuda:0"))  - move tensor around</li>
</ul>

<p>
making sure t2 is on the same device as t2
</p>
<ul class="org-ul">
<li>a = t1.get<sub>device</sub>()</li>
<li>b = torch.tensor(a.shape).to(dev)</li>
</ul>

<p>
Using Multiple GPUs:
</p>
<ul class="org-ul">
<li>Data Parallelism, where we divide batches into smaller batches, and process these smaller batches in parallel on multiple GPU.</li>
<li>Model Parallelism, where we break the neural network into smaller sub networks and then execute these sub networks on different GPUs.</li>
</ul>

<pre class="example">
del out, loss - free tensor/model
torch.cuda.empy_cache() - empty garbage
</pre>


<p>
with torch.no<sub>grad</sub>(): - PyTorch, by default, will create a computational graph during the forward pass. During
creation of this graph, it will allocate buffers to store gradients and intermediate values which are used for
computing the gradient during the backward pass.
</p>


<p>
CuDNN can provided a lot of optimisation which can bring down your space usage,
</p>
<ul class="org-ul">
<li>torch.backends.cudnn.benchmark = True</li>
<li>torch.backends.cudnn.enabled = True</li>
</ul>

<p>
Using 16-bit Floats
</p>
<ul class="org-ul">
<li>model = model.half()     # convert a model to 16-bit</li>
<li>input = input.half()     # convert a model to 16-bit</li>
<li>issues:
<ul class="org-ul">
<li>batch-norm layers have convergence issues with half precision floats. If that's the case with you, make
sure that batch norm layers are float32</li>
<li>You can have overflow issues with 16-bit float. Once, I remember I had such an overflow while trying to
store the Union area of two bounding boxes (for computation of IoUs) in a float16.  So make sure you have
a realistic bound on the value you are trying to save in a float16.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgfa97200" class="outline-3">
<h3 id="orgfa97200"><span class="section-number-3">14.22.</span> troubleshooting</h3>
<div class="outline-text-3" id="text-14-22">
<p>
Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor)
</p>
<ul class="org-ul">
<li>dataset on CPU, model on GPU</li>
<li>solution: Dataset._<sub>getItem</sub>_<sub>(self, idx)</sub>: return image.to(device), torch.tensor(label, dtype=torch.long).to(device)</li>
</ul>


<p>
"RuntimeError: Expected a 'cuda' device type for generator but found 'cpu'"
</p>
<ul class="org-ul">
<li>solution:</li>
</ul>
<pre class="example">
generator = torch.Generator(device=device)
train_loader: DataLoader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, generator=generator)
</pre>


<p>
AttributeError: 'collections.OrderedDict' object has no attribute 'eval'
</p>
<pre class="example">
model = TempModel()
model.load_state_dict(torch.load(file_path))
</pre>


<p>
torch.cuda.OutOfMemoryError: CUDA out of memory. If reserved memory is &gt;&gt; allocated memory try setting max<sub>split</sub><sub>size</sub><sub>mb</sub> to avoid fragmentation.
</p>
<pre class="example">
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:256"
</pre>
</div>
</div>
<div id="outline-container-orge5dcb63" class="outline-3">
<h3 id="orge5dcb63"><span class="section-number-3">14.23.</span> plot learning curve</h3>
<div class="outline-text-3" id="text-14-23">
<div class="org-src-container">
<pre class="src src-sh"><span style="color: #cae682;">LOGFILE</span>=torch/logs/log-2023-09-10-local.txt
cat $<span style="color: #cae682;">LOGFILE</span> | grep <span style="color: #95e454;">"loss"</span> | cut -d <span style="color: #95e454;">' '</span> -f 4 | cut -d <span style="color: #95e454;">','</span> -f 1 &gt; /tmp/loss
cat $<span style="color: #cae682;">LOGFILE</span> | grep <span style="color: #95e454;">"loss"</span> | cut -d <span style="color: #95e454;">' '</span> -f 7 | cut -d <span style="color: #95e454;">','</span> -f 1 &gt; /tmp/acc

python -c <span style="color: #95e454;">"</span>
<span style="color: #95e454;">acc = [float(x[:-1]) for x in open('/tmp/acc', 'r').readlines()]</span>
<span style="color: #95e454;">loss = [float(x[:-1]) for x in open('/tmp/loss', 'r').readlines()]</span>
<span style="color: #95e454;">import numpy as np</span>
<span style="color: #95e454;">acc = np.array(acc)</span>
<span style="color: #95e454;">loss = np.array(loss)</span>
<span style="color: #95e454;">acc = (acc - np.min(acc)) / (np.max(acc) - np.min(acc))</span>
<span style="color: #95e454;">loss = (loss - np.min(loss)) / (np.max(loss) - np.min(loss))</span>
<span style="color: #95e454;">import matplotlib.pyplot as plt</span>
<span style="color: #95e454;">plt.plot(list(range(len(acc))), acc, label='accuracy')</span>
<span style="color: #95e454;">plt.plot(list(range(len(loss))), loss, label='loss')</span>
<span style="color: #95e454;">plt.legend()</span>
<span style="color: #95e454;">plt.title('Scaled accuracy and loss')</span>
<span style="color: #95e454;">plt.savefig('/tmp/a.png')</span>
<span style="color: #95e454;">"</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org479ddbc" class="outline-3">
<h3 id="org479ddbc"><span class="section-number-3">14.24.</span> Finetuning</h3>
<div class="outline-text-3" id="text-14-24">
<p>
You should not rely on the order returned by the model.parameters() method as it does not necessarily match
 the order of the layers in your model. Instead, you should use it on specific part of your models:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">modules</span> = [model.embeddings, model.encoder.layer[:5]] <span style="color: #fa8072;">#</span><span style="color: #99968b; font-style: italic;">Replace 5 by what you want</span>
<span style="color: #8ac6f2; font-weight: bold;">for</span> module <span style="color: #8ac6f2; font-weight: bold;">in</span> modules:
    <span style="color: #8ac6f2; font-weight: bold;">for</span> param <span style="color: #8ac6f2; font-weight: bold;">in</span> module.parameters():
        param.<span style="color: #cae682;">requires_grad</span> = <span style="color: #e5786d; font-weight: bold;">False</span>
</pre>
</div>

<p>
explore:
</p>
<pre class="example">
print(model)
print(list(model.modules()[0:4]))
</pre>
</div>
</div>

<div id="outline-container-orgb179cb2" class="outline-3">
<h3 id="orgb179cb2"><span class="section-number-3">14.25.</span> links</h3>
<div class="outline-text-3" id="text-14-25">
<ul class="org-ul">
<li>docs <a href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a>
<ul class="org-ul">
<li>Module <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">https://pytorch.org/docs/stable/generated/torch.nn.Module.html</a></li>
</ul></li>
<li>tutorial <a href="https://pytorch.org/tutorials/">https://pytorch.org/tutorials/</a></li>

<li>examples <a href="https://github.com/pytorch/examples/">https://github.com/pytorch/examples/</a></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgf89cc21" class="outline-2">
<h2 id="orgf89cc21"><span class="section-number-2">15.</span> ONNX</h2>
<div class="outline-text-2" id="text-15">
</div>
<div id="outline-container-org138e30e" class="outline-3">
<h3 id="org138e30e"><span class="section-number-3">15.1.</span> Terms</h3>
<div class="outline-text-3" id="text-15-1">
<ul class="org-ul">
<li>graph - (IR) internal replresentation of neural network computational flow
<ul class="org-ul">
<li>graph have: inputs, output, and initializer (set inputs which never changes - constants)</li>
</ul></li>
<li>ONNX interpreter (or runtime) - can be implemented, to make it easier to deploy a machine learning model in production. to
evaluate ONNX <b>models</b> and to evaluate ONNX <b>ops</b>.</li>
<li><b>onnx</b> implements a <b>python runtime</b> - not intended to be used for production and performance is not a goal</li>
<li>learning framework - used to build the model, without runtime.</li>
<li>ONNX Operators - a functions that is units of graph.</li>
<li>Operators domains - set of operators: ai.onnx and ai.onnx.ml (tree bases models, preprocessing, SVM, imputer)</li>
<li><b>protobuf</b> - used to serialize the graph into one single block, programming language independant. It aims at
optimizing the model size as much as possible.</li>
<li><p>
Tensor - multidimensional array (dense full array with no stride) with:
</p>
<ul class="org-ul">
<li>type - element type, the same for all elements in the tensor.  <b>strongly typed</b> and its definition does</li>
</ul>
<p>
not support implicit cast.
</p>
<ul class="org-ul">
<li>shape - array with all dimension</li>
<li>contiguous array - represents all the values</li>
</ul></li>
<li>Sparse Tensor - dims, indices (int64) and values.</li>
<li>SequenceProto, MapProto - sequences of tensors, map of tensors, sequences of map of tensors</li>
<li>External data - storing large tensors in separate files, rather than within the main ONNX model file. This
is particularly useful for models larger than 2GB, which cannot be stored in a single file due to size
limitations.</li>
<li><b>Shape Inference</b> - analyzing the model's architecture and the shapes of the input tensors to infer the
shapes of the output tensors.  automatic determination of tensor shapes within a model. Shape inference only
with constants and simple variables.</li>
<li>onnx.onnx<sub>ml</sub><sub>pb2.ModelProto</sub> - main class for model</li>
<li>onnx.onnx<sub>ml</sub><sub>pb2.NodeProto</sub> - main class of graph.node[0:10]</li>
</ul>
</div>
</div>
<div id="outline-container-org2536c4a" class="outline-3">
<h3 id="org2536c4a"><span class="section-number-3">15.2.</span> CASE: Get version</h3>
<div class="outline-text-3" id="text-15-2">
<p>
also attached to every ONNX graphs
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> onnx
<span style="color: #8ac6f2; font-weight: bold;">import</span> numpy <span style="color: #8ac6f2; font-weight: bold;">as</span> np
<span style="color: #8ac6f2; font-weight: bold;">from</span> onnx <span style="color: #8ac6f2; font-weight: bold;">import</span> numpy_helper
<span style="color: #8ac6f2; font-weight: bold;">from</span> onnx <span style="color: #8ac6f2; font-weight: bold;">import</span> helper
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- current</span>
<span style="color: #8ac6f2; font-weight: bold;">from</span> onnx <span style="color: #8ac6f2; font-weight: bold;">import</span> __version__, IR_VERSION
<span style="color: #8ac6f2; font-weight: bold;">from</span> onnx.defs <span style="color: #8ac6f2; font-weight: bold;">import</span> onnx_opset_version
<span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"onnx.__version__=</span>{__version__!r}<span style="color: #95e454;">, opset=</span>{onnx_opset_version()}<span style="color: #95e454;">, IR_VERSION=</span>{IR_VERSION}<span style="color: #95e454;">"</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- path</span>
<span style="color: #cae682;">mp</span> = <span style="color: #95e454;">"/var/tmp/u/t5-encoder/t5-encoder.onnx"</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- checking</span>
onnx.checker.check_model(mp)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- loading</span>
<span style="color: #cae682;">m</span> = onnx.load(mp)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"Model type:"</span>, <span style="color: #e5786d;">type</span>(m))
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"**Opset Version**.</span><span style="color: #e5786d; font-weight: bold;">\n</span><span style="color: #95e454;">"</span>,
      f<span style="color: #95e454;">"- model_opset=</span>{m.opset_import}<span style="color: #e5786d; font-weight: bold;">\n</span><span style="color: #95e454;">"</span>,
      f<span style="color: #95e454;">"- opset=</span>{onnx_opset_version()}<span style="color: #95e454;">"</span>)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"**IR versions**.</span><span style="color: #e5786d; font-weight: bold;">\n</span><span style="color: #95e454;">"</span>,
      f<span style="color: #95e454;">"- model=</span>{m.ir_version}<span style="color: #e5786d; font-weight: bold;">\n</span><span style="color: #95e454;">"</span>,
      f<span style="color: #95e454;">"- current=</span>{onnx.IR_VERSION}<span style="color: #95e454;">"</span>)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"Model: doc_string=</span>{m.doc_string}<span style="color: #95e454;">, domain=</span>{m.domain}<span style="color: #95e454;">, metadata_props=</span>{m.metadata_props}<span style="color: #95e454;">"</span>)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"producer_name=</span>{m.producer_name}<span style="color: #95e454;">"</span>)
<span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"producer_version=</span>{m.producer_version}<span style="color: #95e454;">"</span>)

<span style="color: #cae682;">graph</span> = m.graph
<span style="color: #8ac6f2; font-weight: bold;">for</span> node <span style="color: #8ac6f2; font-weight: bold;">in</span> graph.node[0:10]:
    <span style="color: #e5786d;">print</span>(<span style="color: #e5786d;">type</span>(node))
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;"># -</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;"># node inputs</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">for idx, node_input_name in enumerate(node.input):</span>
    <span style="color: #fa8072;">#     </span><span style="color: #99968b; font-style: italic;">print(idx, node_input_name)</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;"># node outputs</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">for idx, node_output_name in enumerate(node.output):</span>
    <span style="color: #fa8072;">#     </span><span style="color: #99968b; font-style: italic;">print(idx, node_output_name)</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;"># -</span>
    <span style="color: #e5786d;">print</span>(helper.printable_node(node))
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(f"Node Name, type: {node.name}, {node.op_type}")</span>
    <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">print(f"- Inputs/output: {node.input}, {node.output}")</span>

<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"----------- Graph --------"</span>)

<span style="color: #cae682;">total_parameters</span> = 0
<span style="color: #8ac6f2; font-weight: bold;">for</span> initializer <span style="color: #8ac6f2; font-weight: bold;">in</span> m.graph.initializer:
    <span style="color: #cae682;">total_parameters</span> += np.prod(numpy_helper.to_array(initializer).shape)

<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"Total Parameters:"</span>, total_parameters)
<span style="color: #e5786d;">print</span>()
<span style="color: #e5786d;">print</span>([<span style="color: #e5786d;">input</span>.name <span style="color: #8ac6f2; font-weight: bold;">for</span> <span style="color: #e5786d;">input</span> <span style="color: #8ac6f2; font-weight: bold;">in</span> m.graph.<span style="color: #e5786d;">input</span>])
<span style="color: #e5786d;">print</span>([output.name <span style="color: #8ac6f2; font-weight: bold;">for</span> output <span style="color: #8ac6f2; font-weight: bold;">in</span> m.graph.output])
<span style="color: #e5786d;">print</span>()

<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"----------- Graph detailed 1 --------"</span>)
<span style="color: #8ac6f2; font-weight: bold;">from</span> onnx <span style="color: #8ac6f2; font-weight: bold;">import</span> shape_inference
<span style="color: #cae682;">inferred_model</span> = shape_inference.infer_shapes(m)
<span style="color: #e5786d;">print</span>(inferred_model.graph.value_info)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"----------- Graph detailed 2 --------"</span>)
<span style="color: #e5786d;">print</span>(<span style="color: #95e454;">'Model :</span><span style="color: #e5786d; font-weight: bold;">\n\n</span><span style="color: #95e454;">{}'</span>.<span style="color: #e5786d;">format</span>(onnx.helper.printable_graph(m.graph)))

</pre>
</div>

<p>
<a href="https://www.programmersought.com/article/639110832206/">https://www.programmersought.com/article/639110832206/</a>
</p>
</div>
</div>
<div id="outline-container-orgb72eb77" class="outline-3">
<h3 id="orgb72eb77"><span class="section-number-3">15.3.</span> Usage</h3>
<div class="outline-text-3" id="text-15-3">
<p>
If model larger than 2G:
</p>
<ul class="org-ul">
<li>(If the external data is under the same directory of the model, simply use</li>
</ul>
<pre class="example">
onnx.load()
</pre>

<ul class="org-ul">
<li>If the external data is under another director:</li>
</ul>
<pre class="example">
from onnx.external_data_helper import load_external_data_for_model
onnx_model = onnx.load("path/to/the/model.onnx", load_external_data=False)
load_external_data_for_model(onnx_model, "data/directory/path/")
</pre>


<p>
Saving an ONNX Model:
</p>
<pre class="example">
import onnx
# onnx_model is an in-memory ModelProto
onnx_model = ...
onnx.save(onnx_model, "path/to/the/model.onnx")
</pre>


<pre class="example">
onnx.checker.check_model(onnx_model)
</pre>


<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> onnx
onnx.checker.check_model(<span style="color: #95e454;">"path/to/the/model.onnx"</span>) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">will fail if given &gt;2GB model</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org481f269" class="outline-3">
<h3 id="org481f269"><span class="section-number-3">15.4.</span> Visualization - netron</h3>
</div>
<div id="outline-container-org8e1c1ce" class="outline-3">
<h3 id="org8e1c1ce"><span class="section-number-3">15.5.</span> ONNX format</h3>
</div>
<div id="outline-container-orgba42f11" class="outline-3">
<h3 id="orgba42f11"><span class="section-number-3">15.6.</span> doc:</h3>
<div class="outline-text-3" id="text-15-6">
<ul class="org-ul">
<li>doc <a href="https://github.com/onnx/onnx/tree/main/docs">https://github.com/onnx/onnx/tree/main/docs</a></li>
<li>doc <a href="https://onnx.ai/onnx/">https://onnx.ai/onnx/</a></li>
<li>python <a href="https://github.com/onnx/onnx/blob/main/docs/PythonAPIOverview.md">https://github.com/onnx/onnx/blob/main/docs/PythonAPIOverview.md</a></li>
<li>model zoo <a href="https://github.com/onnx/models/">https://github.com/onnx/models/</a></li>
<li>tutorial for ONNX models <a href="https://github.com/onnx/tutorials">https://github.com/onnx/tutorials</a></li>
<li>huggingface <a href="https://onnxruntime.ai/docs/tutorials/huggingface.html">https://onnxruntime.ai/docs/tutorials/huggingface.html</a></li>
<li>main usage of NN in ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.9.1/onnx/examples/Protobufs.ipynb">https://github.com/onnx/onnx/blob/rel-1.9.1/onnx/examples/Protobufs.ipynb</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org7c66337" class="outline-2">
<h2 id="org7c66337"><span class="section-number-2">16.</span> LangChain</h2>
<div class="outline-text-2" id="text-16">
<p>
<a href="https://github.com/gkamradt/langchain-tutorials/blob/main/chatapi/ChatAPI%20%2B%20LangChain%20Basics.ipynb">https://github.com/gkamradt/langchain-tutorials/blob/main/chatapi/ChatAPI%20%2B%20LangChain%20Basics.ipynb</a>
</p>
</div>
<div id="outline-container-orge1c99cc" class="outline-3">
<h3 id="orge1c99cc"><span class="section-number-3">16.1.</span> terms</h3>
<div class="outline-text-3" id="text-16-1">
<ul class="org-ul">
<li>LLMs: Definition: Pure text completion models.  Input/Output: Take a text string as input and return a text
string as output.</li>
<li>Chat Models - Definition: Models that use a language model as a base but differ in input and output formats.
Input/Output: Accept a list of chat messages as input and return a Chat Message.</li>
<li>Prompts: Templatize, dynamically select, and manage model inputs. Allows for the creation of flexible and
context-specific prompts that guide the language model's responses.</li>
<li>Output Parsers: Extract and format information from model outputs. Useful for converting the raw output of
language models into structured data or specific formats needed by the application.</li>
</ul>
</div>
</div>
<div id="outline-container-org4e633d5" class="outline-3">
<h3 id="org4e633d5"><span class="section-number-3">16.2.</span> GigaChat</h3>
<div class="outline-text-3" id="text-16-2">
<ul class="org-ul">
<li><a href="https://pypi.org/project/gigachat/">https://pypi.org/project/gigachat/</a></li>
<li>langchain module <a href="https://python.langchain.com/v0.1/docs/integrations/chat/gigachat/">https://python.langchain.com/v0.1/docs/integrations/chat/gigachat/</a></li>
</ul>
</div>
</div>
<div id="outline-container-org091b4db" class="outline-3">
<h3 id="org091b4db"><span class="section-number-3">16.3.</span> Chat Models</h3>
<div class="outline-text-3" id="text-16-3">
<p>
LLMs are stateless by nature, meaning they do not maintain the state of the conversation. So, if you want to
 support multi-turn conversations, you should take care of managing the state of the conversation.
</p>

<ul class="org-ul">
<li>HumanMessage: A message sent from the perspective of the human</li>
<li>AIMessage: A message sent from the perspective of the AI the human is interacting with</li>
<li>SystemMessage: A message setting the objectives the AI should follow</li>
<li>ChatMessage: A message allowing for arbitrary setting of role. You won’t be using this too much</li>
</ul>
</div>
</div>
<div id="outline-container-orgb6d6197" class="outline-3">
<h3 id="orgb6d6197"><span class="section-number-3">16.4.</span> messages and batch messages</h3>
<div class="outline-text-3" id="text-16-4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">messages</span> = [
    SystemMessage(content=<span style="color: #95e454;">"Say the opposite of what the user says"</span>),
    HumanMessage(content=<span style="color: #95e454;">"I love programming."</span>),
    AIMessage(content=<span style="color: #95e454;">'I hate programming.'</span>),
    HumanMessage(content=<span style="color: #95e454;">"What is the first thing that I said?"</span>)
]
chat(messages)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">batch_messages</span> = [
    [
        SystemMessage(content=<span style="color: #95e454;">"You are a helpful word machine that creates an alliteration using a base word"</span>),
        HumanMessage(content=<span style="color: #95e454;">"Base word: Apple"</span>)
    ],
    [
        SystemMessage(content=<span style="color: #95e454;">"You are a helpful word machine that creates an alliteration using a base word"</span>),
        HumanMessage(content=<span style="color: #95e454;">"Base word: Dog"</span>)
    ],
]
chat.generate(batch_messages)
</pre>
</div>
</div>
</div>

<div id="outline-container-org581c073" class="outline-3">
<h3 id="org581c073"><span class="section-number-3">16.5.</span> Prompt Templates</h3>
<div class="outline-text-3" id="text-16-5">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Make SystemMessagePromptTemplate</span>
<span style="color: #cae682;">prompt</span>=PromptTemplate(
    template=<span style="color: #95e454;">"Propose creative ways to incorporate {food_1} and {food_2} in the cuisine of the users choice."</span>,
    input_variables=[<span style="color: #95e454;">"food_1"</span>, <span style="color: #95e454;">"food_2"</span>]
)

<span style="color: #cae682;">system_message_prompt</span> = SystemMessagePromptTemplate(prompt=prompt)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Output of system_message_prompt</span>
system_message_prompt.<span style="color: #e5786d;">format</span>(food_1=<span style="color: #95e454;">"Bacon"</span>, food_2=<span style="color: #95e454;">"Shrimp"</span>)


</pre>
</div>


<p>
Make HumanMessagePromptTemplate
</p>
<div class="org-src-container">
<pre class="src src-python">
<span style="color: #cae682;">human_template</span>=<span style="color: #95e454;">"{text}"</span>
<span style="color: #cae682;">human_message_prompt</span> = HumanMessagePromptTemplate.from_template(human_template)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Create ChatPromptTemplate: Combine System + Human</span>
<span style="color: #cae682;">chat_prompt</span> = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])

<span style="color: #cae682;">chat_prompt_with_values</span> = chat_prompt.format_prompt(food_1=<span style="color: #95e454;">"Bacon"</span>, \
                                                   food_2=<span style="color: #95e454;">"Shrimp"</span>, \
                                                   text=<span style="color: #95e454;">"I really like food from Germany."</span>)

chat_prompt_with_values.to_messages()

<span style="color: #cae682;">response</span> = chat(chat_prompt_with_values.to_messages()).content
<span style="color: #e5786d;">print</span> (response)
</pre>
</div>
</div>
</div>

<div id="outline-container-orgd8019b2" class="outline-3">
<h3 id="orgd8019b2"><span class="section-number-3">16.6.</span> Memory Types in Langchain</h3>
<div class="outline-text-3" id="text-16-6">
<p>
<a href="https://nanonets.com/blog/langchain/#module-v-memory">https://nanonets.com/blog/langchain/#module-v-memory</a>
</p>
<ul class="org-ul">
<li>Conversation Buffer Memory</li>
<li>Conversation Buffer Window Memory</li>
<li>Conversation Entity Memory</li>
<li>Conversation Knowledge Graph Memory</li>
<li>Conversation Summary Memory</li>
<li>Conversation Summary Buffer Memory</li>
<li>Conversation Token Buffer Memory</li>
<li>VectorStoreRetrieverMemory</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgde4c615" class="outline-2">
<h2 id="orgde4c615"><span class="section-number-2">17.</span> MLFlow - experiment tracking</h2>
<div class="outline-text-2" id="text-17">
</div>
<div id="outline-container-orgc666b95" class="outline-3">
<h3 id="orgc666b95"><span class="section-number-3">17.1.</span> features</h3>
<div class="outline-text-3" id="text-17-1">
<ul class="org-ul">
<li><b>centralized repository</b> -  parameters, metrics, artifacts, data, and environment
configurations, giving teams insight into their models’ evolution over time.
<ul class="org-ul">
<li>logging of results either to local files or a server - to compare multiple runs across different users.</li>
</ul></li>
<li><b>Model Registry</b> - model store,  UI to collaboratively manage - model lineage, versioning, aliasing, tagging, and annotations</li>
<li><b>LLM</b> - offers a common set of APIs for prominent LLMs.</li>
</ul>

<p>
for
</p>
<ul class="org-ul">
<li>Experiment Tracking</li>
<li>Model Selection and Deployment</li>
<li>Model Performance Monitoring (in production)</li>
<li>"MLflow Project." - format for sharing and parameter modifications</li>
</ul>

<p>
distributed
</p>
<ul class="org-ul">
<li>Apache Spark, Databricks.</li>
<li>Interoperability with Distributed Storage - Azure ADLS, Azure Blob Storage, AWS S3, Cloudflare R2 and DBFS</li>
</ul>
</div>
</div>
<div id="outline-container-org4ba099d" class="outline-3">
<h3 id="org4ba099d"><span class="section-number-3">17.2.</span> terms</h3>
<div class="outline-text-3" id="text-17-2">
<dl class="org-dl">
<dt>Runs</dt><dd>executions of some piece of data science code (python train.py), Each run records metadata and artifacts
<dl class="org-dl">
<dt>metadata</dt><dd>metrics, parameters, start and end times.</dd>
<dt>artifacts</dt><dd>output files from the run such as model weights, images, etc</dd>
</dl></dd>
<dt>Experiments</dt><dd>group of runs</dd>
<dt>MLflow Tracking APIs</dt><dd>mlflow.start<sub>run</sub>(), mlflow.log<sub>param</sub>(), mlflow.log<sub>metric</sub>()</dd>
<dt>Auto-logging</dt><dd>Tracking APIs variat that don't require any command</dd>
<dt>Tracking Datasets</dt><dd>mlflow.log<sub>input</sub>()</dd>
<dt>Tracking UI</dt><dd>local "mlflow ui &#x2013;port 5000" or with "MLflow Tracking Server" <a href="http://">http://</a>&lt;IP address of your MLflow tracking server&gt;:5000</dd>
<dt>MlflowClient</dt><dd>library to access Tracking UI functions.</dd>
<dt>Dataset</dt><dd>abstraction is a metadata tracking object that holds the information about a given logged
dataset.  features, targets, and predictions</dd>
<dt>Backend Store</dt><dd>main storage. can be file-system-based like local files and database-based like PostgreSQL. By default in ./mlruns</dd>
<dt>Artifact Store</dt><dd>Another compotent for storage. By default in ./mlruns</dd>
<dt>tracking URI</dt><dd>path to save Backend Store and Artifact Store</dd>
</dl>
</div>
</div>
<div id="outline-container-orgff90b4f" class="outline-3">
<h3 id="orgff90b4f"><span class="section-number-3">17.3.</span> installation</h3>
<div class="outline-text-3" id="text-17-3">
<pre class="example">
pip install mlflow
mlflow ui  - test by starting web server
</pre>
</div>
</div>
<div id="outline-container-orgc330bea" class="outline-3">
<h3 id="orgc330bea"><span class="section-number-3">17.4.</span> framework styles:</h3>
<div class="outline-text-3" id="text-17-4">
<ul class="org-ul">
<li>high-level “fluent” API</li>
<li>Context manager syntax</li>
<li>Auto-logging: mlflow.autolog()</li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">high-level &#8220;fluent&#8221; API</span>
<span style="color: #8ac6f2; font-weight: bold;">import</span> mlflow

mlflow.start_run()
mlflow.log_param(<span style="color: #95e454;">"my"</span>, <span style="color: #95e454;">"param"</span>)
mlflow.log_metric(<span style="color: #95e454;">"score"</span>, 100)
mlflow.end_run()

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">context manager syntax</span>
<span style="color: #8ac6f2; font-weight: bold;">with</span> mlflow.start_run() <span style="color: #8ac6f2; font-weight: bold;">as</span> run:
    mlflow.log_param(<span style="color: #95e454;">"my"</span>, <span style="color: #95e454;">"param"</span>)
    mlflow.log_metric(<span style="color: #95e454;">"score"</span>, 100)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Auto-logging</span>
mlflow.autolog()
</pre>
</div>
</div>
</div>

<div id="outline-container-org8c71de9" class="outline-3">
<h3 id="org8c71de9"><span class="section-number-3">17.5.</span> Usage</h3>
<div class="outline-text-3" id="text-17-5">
</div>
<div id="outline-container-org3bcdf8b" class="outline-4">
<h4 id="org3bcdf8b"><span class="section-number-4">17.5.1.</span> monitor experiment locally</h4>
<div class="outline-text-4" id="text-17-5-1">
<pre class="example">
mlflow ui
</pre>


<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> mlflow

mlflow.set_tracking_uri(<span style="color: #95e454;">"http://localhost:5000"</span>)
mlflow.set_experiment(<span style="color: #95e454;">"check-localhost-connection"</span>)

<span style="color: #8ac6f2; font-weight: bold;">with</span> mlflow.start_run():
    mlflow.log_metric(<span style="color: #95e454;">"foo"</span>, 1)
    mlflow.log_metric(<span style="color: #95e454;">"bar"</span>, 2)
</pre>
</div>
</div>
</div>

<div id="outline-container-org0616019" class="outline-4">
<h4 id="org0616019"><span class="section-number-4">17.5.2.</span> store first locally</h4>
<div class="outline-text-4" id="text-17-5-2">
<p>
By default, MLflow stores artifacts in a local directory named mlruns.
</p>

<ol class="org-ol">
<li>export MLFLOW<sub>TRACKING</sub><sub>URI</sub>=sqlite:///mlruns.db</li>
<li>mlflow.autolog() in Python</li>
<li>mlflow ui &#x2013;port 8080 &#x2013;backend-store-uri $MLFLOW<sub>TRACKING</sub><sub>URI</sub></li>
</ol>

<p>
Alternative:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> mlflow
<span style="color: #cae682;">experiment_name</span> = <span style="color: #95e454;">"your_experiment_name"</span>
mlflow.create_experiment(experiment_name, artifact_location=<span style="color: #95e454;">"s3://your-bucket"</span>)
mlflow.set_experiment(experiment_name)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org5d3e0ae" class="outline-3">
<h3 id="org5d3e0ae"><span class="section-number-3">17.6.</span> tracking URI</h3>
<div class="outline-text-3" id="text-17-6">
<ul class="org-ul">
<li><a href="file:///my/local/dir">file:///my/local/dir</a></li>
<li>A Database, encoded as
&lt;dialect&gt;+&lt;driver&gt;://&lt;username&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;database&gt;. <a href="https://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls">https://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls</a></li>
<li>HTTP server <a href="https://my-server:5000">https://my-server:5000</a></li>
<li>Databricks workspace  databricks://&lt;profileName&gt;</li>
</ul>
</div>
</div>
<div id="outline-container-org74dc3ea" class="outline-3">
<h3 id="org74dc3ea"><span class="section-number-3">17.7.</span> tracking API</h3>
<div class="outline-text-3" id="text-17-7">
<p>
start<sub>run</sub>
</p>
<ul class="org-ul">
<li>calling one of the logging functions with no active run automatically starts a new one.</li>
</ul>

<p>
mlflow.end<sub>run</sub>() - required with autolog too.
</p>

<p>
<a href="https://mlflow.org/docs/latest/tracking/tracking-api.html">https://mlflow.org/docs/latest/tracking/tracking-api.html</a>
</p>
</div>
</div>
<div id="outline-container-orgdb47ccf" class="outline-3">
<h3 id="orgdb47ccf"><span class="section-number-3">17.8.</span> MlflowClient</h3>
<div class="outline-text-3" id="text-17-8">
</div>
<div id="outline-container-orge678669" class="outline-4">
<h4 id="orge678669"><span class="section-number-4">17.8.1.</span> model registry - list models, register model</h4>
<div class="outline-text-4" id="text-17-8-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> mlflow.exceptions <span style="color: #8ac6f2; font-weight: bold;">import</span> MlflowException

<span style="color: #8ac6f2; font-weight: bold;">from</span> mlflow.tracking <span style="color: #8ac6f2; font-weight: bold;">import</span> MlflowClient
<span style="color: #cae682;">client</span> = MlflowClient()

<span style="color: #8ac6f2; font-weight: bold;">try</span>:
    <span style="color: #e5786d;">list</span> = client.list_registered_models()
<span style="color: #8ac6f2; font-weight: bold;">except</span> MlflowException:
    <span style="color: #e5786d;">print</span>(<span style="color: #95e454;">"It's not possible to access the model registry :("</span>)


<span style="color: #cae682;">run_id</span> = client.list_run_infos(experiment_id=<span style="color: #95e454;">'1'</span>)[0].run_id
mlflow.register_model(
    model_uri=f<span style="color: #95e454;">"runs:/</span>{run_id}<span style="color: #95e454;">/models"</span>,
    name=<span style="color: #95e454;">'iris-classifier'</span>
)
</pre>
</div>
</div>
</div>

<div id="outline-container-orgf7cd8d4" class="outline-4">
<h4 id="orgf7cd8d4"><span class="section-number-4">17.8.2.</span> model registry - search<sub>runs</sub></h4>
<div class="outline-text-4" id="text-17-8-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">runs</span> = client.search_runs(
    experiment_ids=<span style="color: #95e454;">'1'</span>,
    filter_string=<span style="color: #95e454;">"metrics.rmse &lt; 7"</span>,
    run_view_type=ViewType.ACTIVE_ONLY,
    max_results=5,
    order_by=[<span style="color: #95e454;">"metrics.rmse ASC"</span>]
)

<span style="color: #8ac6f2; font-weight: bold;">for</span> run <span style="color: #8ac6f2; font-weight: bold;">in</span> runs:
    <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"run id: </span>{run.info.run_id}<span style="color: #95e454;">, rmse: </span>{run.data.metrics['rmse']:.4f}<span style="color: #95e454;">"</span>)
</pre>
</div>

<p>
bbest active run
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> mlflow <span style="color: #8ac6f2; font-weight: bold;">import</span> MlflowClient
<span style="color: #8ac6f2; font-weight: bold;">from</span> mlflow.entities <span style="color: #8ac6f2; font-weight: bold;">import</span> ViewType

<span style="color: #cae682;">run</span> = MlflowClient().search_runs(
    experiment_ids=<span style="color: #95e454;">"0"</span>,
    filter_string=<span style="color: #95e454;">""</span>,
    run_view_type=ViewType.ACTIVE_ONLY,
    max_results=1,
    order_by=[<span style="color: #95e454;">"metrics.accuracy DESC"</span>],
)[0]
</pre>
</div>
</div>
</div>


<div id="outline-container-orgf881762" class="outline-4">
<h4 id="orgf881762"><span class="section-number-4">17.8.3.</span> runs</h4>
<div class="outline-text-4" id="text-17-8-3">
<ul class="org-ul">
<li></li>

<li>run.data: RunData
<ul class="org-ul">
<li>metrics: dict</li>
<li>params: dict</li>
<li>tags: dict</li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> mlflow.entities <span style="color: #8ac6f2; font-weight: bold;">import</span> ViewType

<span style="color: #cae682;">runs</span> = client.search_runs(
    experiment_ids=<span style="color: #95e454;">'1'</span>,
    filter_string=<span style="color: #95e454;">"metrics.rmse &lt; 7"</span>,
    run_view_type=ViewType.ACTIVE_ONLY,
    max_results=5,
    order_by=[<span style="color: #95e454;">"metrics.rmse ASC"</span>]
)
<span style="color: #8ac6f2; font-weight: bold;">for</span> run <span style="color: #8ac6f2; font-weight: bold;">in</span> runs:
    <span style="color: #e5786d;">print</span>(f<span style="color: #95e454;">"run id: </span>{run.info.run_id}<span style="color: #95e454;">, rmse: </span>{run.data.metrics['rmse']:.4f}<span style="color: #95e454;">"</span>)
</pre>
</div>
</div>
</div>
</div>


<div id="outline-container-org4205961" class="outline-3">
<h3 id="org4205961"><span class="section-number-3">17.9.</span> MLflow Tracing - @mlflow.trace</h3>
<div class="outline-text-3" id="text-17-9">
<p>
For
</p>
<ul class="org-ul">
<li>enabling better debugging</li>
<li>performance monitoring</li>
<li>insights into complex workflow</li>
</ul>

<p>
What is captured?
</p>
<ul class="org-ul">
<li>Inputs</li>
<li>Response</li>
<li>Trace Name</li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> mlflow

mlflow.set_experiment(<span style="color: #95e454;">"Tracing Demo"</span>)

<span style="color: #92a65e; font-weight: bold;">@mlflow.trace</span>
<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">my_function</span>(x, y):
    <span style="color: #8ac6f2; font-weight: bold;">return</span> x + y
</pre>
</div>

<p>
This is equivalent to:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> mlflow

mlflow.set_experiment(<span style="color: #95e454;">"Tracing Demo"</span>)

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">my_function</span>(x, y):
    <span style="color: #8ac6f2; font-weight: bold;">return</span> x + y

<span style="color: #8ac6f2; font-weight: bold;">with</span> mlflow.start_span(<span style="color: #95e454;">"my_function"</span>) <span style="color: #8ac6f2; font-weight: bold;">as</span> span:
    <span style="color: #cae682;">x</span> = 1
    <span style="color: #cae682;">y</span> = 2
    span.set_inputs({<span style="color: #95e454;">"x"</span>: x, <span style="color: #95e454;">"y"</span>: y})
    <span style="color: #cae682;">result</span> = my_function(x, y)
    span.set_outputs({<span style="color: #95e454;">"output"</span>: result})
</pre>
</div>
</div>
</div>
<div id="outline-container-orgd8c09f2" class="outline-3">
<h3 id="orgd8c09f2"><span class="section-number-3">17.10.</span> Not supported:</h3>
<div class="outline-text-3" id="text-17-10">
<ul class="org-ul">
<li>Security - impossible to restrict access to server, you should use VPS or other tools</li>
<li>Scalability - limited - AWS Fargate</li>
<li>Isolation - you should use own standards and naming rules. To restrict access to artifacts use s3 buckets
living in different AWS account.</li>
<li>Data versioning - require for full reproducibility. Ways?</li>
<li>Model/Data monitoring &amp; Alerting</li>
</ul>

<p>
Alternatives: Neptune, Comet, Weights &amp; Biases
</p>

<p>
Metrics to select experiment tracking tool:
</p>
<ul class="org-ul">
<li>Focus - main features</li>
<li>Price - Free or license</li>
<li>Standalone component or a part of a broader ML platform?</li>
<li>Commercial, open-source or managed cloud service software?</li>
<li>Hosted version or deployd on-premise? Which part where hosted?</li>
<li>How much do you have to change in your training process? Lines of code</li>
<li>Web UI or console-based?</li>
<li>Features: custom dashboards, table format diff, comparing experiments and metadata,
<ul class="org-ul">
<li>reproducibility and traceability
<ul class="org-ul">
<li>one-command experiment re-run</li>
<li>Experiment lineage</li>
<li>experiment versioning</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgede5daa" class="outline-2">
<h2 id="orgede5daa"><span class="section-number-2">18.</span> Perfect</h2>
<div class="outline-text-2" id="text-18">
<p>
Prefect server instance
</p>

<p>
require - Self-hosted Prefect server instance
</p>
</div>

<div id="outline-container-org0a941df" class="outline-3">
<h3 id="org0a941df"><span class="section-number-3">18.1.</span> terms</h3>
<div class="outline-text-3" id="text-18-1">
<dl class="org-dl">
<dt>@task</dt><dd>function. the smallest unit of observed and orchestrated work in Prefect.</dd>
<dt>flow run</dt><dd>function, bigges unit of ovservation</dd>
<dt>Results</dt><dd>The data returned by a flow or a task.</dd>
<dt>Artifacts</dt><dd>ormatted outputs rendered in the Prefect UI, such as markdown, tables, or links.</dd>
<dt>Deployments</dt><dd>A server-side concept that encapsulates flow metadata, allowing it to be scheduled and triggered via API.</dd>
</dl>
</div>
</div>
<div id="outline-container-orgf7b1bdd" class="outline-3">
<h3 id="orgf7b1bdd"><span class="section-number-3">18.2.</span> links</h3>
<div class="outline-text-3" id="text-18-2">
<ul class="org-ul">
<li><a href="https://docs.prefect.io">https://docs.prefect.io</a></li>
<li><a href="https://docs.prefect.io/latest/getting-started/quickstart/">https://docs.prefect.io/latest/getting-started/quickstart/</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org26d32d2" class="outline-2">
<h2 id="org26d32d2"><span class="section-number-2">19.</span> <span class="todo TODO">TODO</span> PaddlePaddle 飞桨</h2>
<div class="outline-text-2" id="text-19">
<p>
PArallel Distributed Deep LEarning
<a href="https://www.paddlepaddle.org.cn/">https://www.paddlepaddle.org.cn/</a>
</p>
</div>
</div>
<div id="outline-container-orgb3a802f" class="outline-2">
<h2 id="orgb3a802f"><span class="section-number-2">20.</span> huggingface.co</h2>
<div class="outline-text-2" id="text-20">
<ul class="org-ul">
<li><a href="https://github.com/huggingface">https://github.com/huggingface</a></li>
</ul>

<p>
goal of democratising AI, collection of models and datasets
</p>
</div>
<div id="outline-container-org4270cee" class="outline-3">
<h3 id="org4270cee"><span class="section-number-3">20.1.</span> Dateset</h3>
<div class="outline-text-3" id="text-20-1">
</div>
<div id="outline-container-org3ec71eb" class="outline-4">
<h4 id="org3ec71eb"><span class="section-number-4">20.1.1.</span> load</h4>
<div class="outline-text-4" id="text-20-1-1">
<p>
from datasets import load<sub>dataset</sub>
</p>

<p>
dataset = load<sub>dataset</sub>("username/my<sub>dataset</sub>")
</p>

<p>
optional:
</p>
<ul class="org-ul">
<li>split="train"<i>"validation"</i>"test"</li>
</ul>
</div>
</div>
<div id="outline-container-orgde1b4da" class="outline-4">
<h4 id="orgde1b4da"><span class="section-number-4">20.1.2.</span> explore</h4>
<div class="outline-text-4" id="text-20-1-2">
<ul class="org-ul">
<li>print(dataset)</li>
<li>print(dataset.info) - detailed</li>
<li>print(dataset.column<sub>names</sub>) - names and types</li>
<li>print(dataset.data)</li>
<li>print(dataset.data['train'].table) # ConcatenatedTable, pyarrow.lib.Table</li>
<li>df = dataset.data['train'].table.to<sub>pandas</sub>() # no copying</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org3fd7d8e" class="outline-3">
<h3 id="org3fd7d8e"><span class="section-number-3">20.2.</span> pip packages</h3>
<div class="outline-text-3" id="text-20-2">
<p>
<a href="https://github.com/orgs/huggingface/repositories?q=sort%3Astars">https://github.com/orgs/huggingface/repositories?q=sort%3Astars</a>
</p>
</div>
<div id="outline-container-org24e2afd" class="outline-4">
<h4 id="org24e2afd"><span class="section-number-4">20.2.1.</span> huggingface-hub</h4>
<div class="outline-text-4" id="text-20-2-1">
<ul class="org-ul">
<li>pypi.org/project/huggingface-hub/
<ul class="org-ul">
<li>The Hugging Face Hub is a platform with over 90K models, 14K datasets, and 12K demos</li>
<li>use Cloudfront (a CDN) to geo-replicate downloads</li>
<li>Inference API - require API<sub>TOKEN</sub></li>
<li>Repository class - wrapper around the git command</li>
<li>HfApi client -  HTTP requests</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orge8580d6" class="outline-4">
<h4 id="orge8580d6"><span class="section-number-4">20.2.2.</span> transformers <a id="orgef06f01"></a></h4>
<div class="outline-text-4" id="text-20-2-2">
<p>
for Pytorch, TensorFlow, and JAX.
</p>

<pre class="example">
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install transformers[torch] --user
pip install transformers[tf-cpu] --user
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('I hate you'))"
</pre>


<p>
Transformers is natural language processing library to all ML models, with support from libraries like Flair,
 Asteroid, ESPnet, Pyannote, and more to come.
</p>

<p>
Inference API ( free tier is rate-limited and supports models up to 10GB in size.)
</p>
<ul class="org-ul">
<li>A service-level agreement (SLA) is a contract between two companies or internal teams.</li>
<li>Use the Inference API shared infrastructure for free, or switch to dedicated Inference Endpoints for production</li>
<li>plans:
<ul class="org-ul">
<li>free - up to 1M input characters /mo, up to 2 hours of audio. Shared resources, no auto-scaling, standard latency</li>
<li>Enterprise support for Inference Endpoints. Custom pricing based on volume commit. Starts at $2k/mo, annual contracts</li>
</ul></li>
<li>API that allow the programmer to engage with the library at various levels of abstraction.</li>
<li><b>pipeline</b>, which handles everything for us, namely converting raw text into a set of predictions from a fine-tuned model.</li>
</ul>
</div>
</div>

<div id="outline-container-org060cd7a" class="outline-4">
<h4 id="org060cd7a"><span class="section-number-4">20.2.3.</span> pytorch-image-models</h4>
<div class="outline-text-4" id="text-20-2-3">
<p>
PyTorch image encoders / backbones
</p>
</div>
</div>
<div id="outline-container-org9eb382f" class="outline-4">
<h4 id="org9eb382f"><span class="section-number-4">20.2.4.</span> diffusers</h4>
<div class="outline-text-4" id="text-20-2-4">
<p>
diffusion models for image and audio generation in PyTorch and FLAX.
</p>
</div>
</div>
<div id="outline-container-org8b8f49a" class="outline-4">
<h4 id="org8b8f49a"><span class="section-number-4">20.2.5.</span> datasets</h4>
</div>
<div id="outline-container-orgef61daf" class="outline-4">
<h4 id="orgef61daf"><span class="section-number-4">20.2.6.</span> peft - Parameter-Efficient Fine-Tuning</h4>
</div>
<div id="outline-container-orgb0a1886" class="outline-4">
<h4 id="orgb0a1886"><span class="section-number-4">20.2.7.</span> candle - ML framework for Rust</h4>
</div>
<div id="outline-container-org5924789" class="outline-4">
<h4 id="org5924789"><span class="section-number-4">20.2.8.</span> trl - reinforcement learning for Transformers.</h4>
</div>
<div id="outline-container-org5dbb56c" class="outline-4">
<h4 id="org5dbb56c"><span class="section-number-4">20.2.9.</span> tokenizers</h4>
</div>
<div id="outline-container-orgdce3c3a" class="outline-4">
<h4 id="orgdce3c3a"><span class="section-number-4">20.2.10.</span> text-generation-inference - LLMs</h4>
<div class="outline-text-4" id="text-20-2-10">
<p>
A Rust, Python and gRPC server
</p>
</div>
</div>
<div id="outline-container-org48aba8c" class="outline-4">
<h4 id="org48aba8c"><span class="section-number-4">20.2.11.</span> accelerate</h4>
<div class="outline-text-4" id="text-20-2-11">
<p>
utomatic mixed precision (including fp8), and easy-to-configure FSDP and DeepSpeed support
</p>

<p>
Accelerate - is a library that enables the same PyTorch code to be run across any distributed configuration
</p>
</div>
</div>
<div id="outline-container-org89b8d63" class="outline-4">
<h4 id="org89b8d63"><span class="section-number-4">20.2.12.</span> lerobot - Learning for Real-World Robotics in Pytorch</h4>
</div>
<div id="outline-container-org2112899" class="outline-4">
<h4 id="org2112899"><span class="section-number-4">20.2.13.</span> text-embeddings-inference</h4>
<div class="outline-text-4" id="text-20-2-13">
<p>
deploying and serving open source text embeddings and sequence classification models
</p>

<p>
features such as:
</p>
<ul class="org-ul">
<li>No model graph compilation step</li>
<li>Metal support for local execution on Macs</li>
<li>Small docker images and fast boot times. Get ready for true serverless!</li>
<li>Token based dynamic batching</li>
<li>Optimized transformers code for inference using Flash Attention, Candle and cuBLASLt</li>
<li>Safetensors weight loading</li>
<li>Production ready (distributed tracing with Open Telemetry, Prometheus metrics)</li>
</ul>

<p>
<a href="https://huggingface.co/docs/text-embeddings-inference/en/local_cpu">https://huggingface.co/docs/text-embeddings-inference/en/local_cpu</a>
</p>
</div>
</div>
</div>

<div id="outline-container-org8a01b73" class="outline-3">
<h3 id="org8a01b73"><span class="section-number-3">20.3.</span> pages</h3>
<div class="outline-text-3" id="text-20-3">
<p>
huggingface.co/models -
</p>

<p>
huggingface.co/datasets
</p>

<p>
huggingface.co/spaces
</p>

<p>
huggingface.co/collections - allows users to group and curate repositories from the Hub, including models,
 datasets, Spaces, and papers, on a dedicated page.
</p>
<ul class="org-ul">
<li>Organization</li>
</ul>
</div>
</div>
<div id="outline-container-orgc8a3541" class="outline-3">
<h3 id="orgc8a3541"><span class="section-number-3">20.4.</span> reduce inference</h3>
<div class="outline-text-3" id="text-20-4">
</div>
<div id="outline-container-orga443010" class="outline-4">
<h4 id="orga443010"><span class="section-number-4">20.4.1.</span> quantization</h4>
<div class="outline-text-4" id="text-20-4-1">
<p>
Discrete quantization: Going beyond 16-bit down to 8 or 4 bits
</p>

<p>
quantize transformers model from scratch: ~5 min on a Google colab for facebook/opt-350m model
</p>
<ul class="org-ul">
<li>load models that has been already quantized by other users</li>
<li></li>
</ul>
</div>

<ol class="org-ol">
<li><a id="org368ef0a"></a>links<br />
<div class="outline-text-5" id="text-20-4-1-1">
<ul class="org-ul">
<li><a href="https://huggingface.co/docs/transformers/main_classes/quantization">https://huggingface.co/docs/transformers/main_classes/quantization</a></li>
<li><a href="https://arxiv.org/abs/2210.17323">https://arxiv.org/abs/2210.17323</a></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org98e9bfa" class="outline-4">
<h4 id="org98e9bfa"><span class="section-number-4">20.4.2.</span> <span class="todo TODO">TODO</span> pruning</h4>
<div class="outline-text-4" id="text-20-4-2">
<p>
removing weights, filters, neurons or even layers that are not necessary after learning.
</p>

<p>
model distilation: original network teach another shallow network.
</p>

<p>
magnitude pruning - unstructured pruning method
</p>
</div>
<ol class="org-ol">
<li><a id="org9cbfd1c"></a>links<br />
<div class="outline-text-5" id="text-20-4-2-1">
<ul class="org-ul">
<li>model distillation [Hinton et al., 2015] <a href="https://doi.org/10.1126/science.1127647">https://doi.org/10.1126/science.1127647</a></li>
<li>Knowledge Distillation [Gou et al., 2020] <a href="https://arxiv.org/abs/2006.05525">https://arxiv.org/abs/2006.05525</a></li>
<li><a href="https://pytorch.org/tutorials/intermediate/pruning_tutorial.html">https://pytorch.org/tutorials/intermediate/pruning_tutorial.html</a></li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-org9458abe" class="outline-3">
<h3 id="org9458abe"><span class="section-number-3">20.5.</span> transformers</h3>
<div class="outline-text-3" id="text-20-5">
<p>
see <a href="#orgef06f01">20.2.2</a>
</p>
</div>
<div id="outline-container-orge2b3412" class="outline-4">
<h4 id="orge2b3412"><span class="section-number-4">20.5.1.</span> theory</h4>
<div class="outline-text-4" id="text-20-5-1">
<p>
Configuration Class - configuration of the model, including hyperparameter
</p>
<pre class="example">
from transformers import AutoConfig
config = AutoConfig.from_pretrained("bert-base-uncased")
</pre>


<p>
Model Class -  represents the pre-trained model itself
</p>
<pre class="example">
from transformers import AutoModelForSequenceClassification
model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
</pre>


<p>
Tokenizer Class - preprocessing text data into a format that the model can understand.
</p>
<pre class="example">
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
</pre>


<p>
Pipeline Class - NLP tasks: text classification, named entity recognition, and sentiment analysis.
</p>
<pre class="example">
from transformers import pipeline
classifier = pipeline("sentiment-analysis")
result = classifier("I've been waiting for a HuggingFace course my whole life.")
</pre>



<p>
steps modes (other ways with pipeline):
</p>
<pre class="example">
inputs = tokenizer("I've been waiting for a HuggingFace course my whole life.", return_tensors="pt")
outputs = model(**inputs)
logits = outputs.logits
</pre>
</div>
</div>
<div id="outline-container-org4bc44cc" class="outline-4">
<h4 id="org4bc44cc"><span class="section-number-4">20.5.2.</span> base</h4>
<div class="outline-text-4" id="text-20-5-2">
<p>
pipeline -  easiest and fastest way to use a pretrained model
</p>

<p>
AutoClass - automatically infer and load the correct architecture from a given checkpoint
</p>
<ul class="org-ul">
<li>work under hood</li>
<li>There is one class of AutoModel for each task, and for each backend (PyTorch, TensorFlow, or Flax).</li>
</ul>

<p>
AutoModel
</p>
<ul class="org-ul">
<li>for text: AutoModelForSequenceClassification or TFAutoModelForSequenceClassification</li>
<li>TFAutoModel for TF</li>
</ul>

<p>
transformers.Trainer
</p>
<ul class="org-ul">
<li>supports distributed training and mixed precision,</li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> torch
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- pipeline:</span>
<span style="color: #8ac6f2; font-weight: bold;">from</span> transformers <span style="color: #8ac6f2; font-weight: bold;">import</span> pipeline
<span style="color: #cae682;">speech_recognizer</span> = pipeline(<span style="color: #95e454;">"automatic-speech-recognition"</span>, model=<span style="color: #95e454;">"facebook/wav2vec2-base-960h"</span>)

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- AutoModel</span>
<span style="color: #8ac6f2; font-weight: bold;">from</span> transformers <span style="color: #8ac6f2; font-weight: bold;">import</span> AutoModelForSequenceClassification
<span style="color: #cae682;">model_name</span> = <span style="color: #95e454;">"nlptown/bert-base-multilingual-uncased-sentiment"</span>
<span style="color: #cae682;">pt_model</span> = AutoModelForSequenceClassification.from_pretrained(model_name)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- ?</span>
<span style="color: #8ac6f2; font-weight: bold;">from</span> transformers <span style="color: #8ac6f2; font-weight: bold;">import</span> AutoTokenizer
<span style="color: #cae682;">model_name</span> = <span style="color: #95e454;">"nlptown/bert-base-multilingual-uncased-sentiment"</span>
<span style="color: #cae682;">tokenizer</span> = AutoTokenizer.from_pretrained(model_name)
<span style="color: #cae682;">pt_batch</span> = tokenizer(
    [<span style="color: #95e454;">"We are very happy to show you the &#129303; Transformers library."</span>, <span style="color: #95e454;">"We hope you don't hate it."</span>],
    padding=<span style="color: #e5786d; font-weight: bold;">True</span>,
    truncation=<span style="color: #e5786d; font-weight: bold;">True</span>,
    max_length=512,
    return_tensors=<span style="color: #95e454;">"pt"</span>,
)
<span style="color: #cae682;">pt_outputs</span> = pt_model(**pt_batch) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">preprocessed batch of inputs</span>
<span style="color: #cae682;">pt_predictions</span> = nn.functional.softmax(pt_outputs.logits, dim=-1) <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">probobilitices for classes</span>

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- Train</span>
<span style="color: #cae682;">model</span> = AutoModelForSequenceClassification.from_pretrained(model_name)
<span style="color: #8ac6f2; font-weight: bold;">from</span> transformers <span style="color: #8ac6f2; font-weight: bold;">import</span> TrainingArguments, Trainer
<span style="color: #cae682;">training_args</span> = TrainingArguments(output_dir=<span style="color: #95e454;">"test_trainer"</span>)  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">where to save the checkpoints from your training:</span>
<span style="color: #cae682;">trainer</span> = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)
trainer.train()


<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- Fine-tuning:</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org105d4da" class="outline-4">
<h4 id="org105d4da"><span class="section-number-4">20.5.3.</span> scipts</h4>
<div class="outline-text-4" id="text-20-5-3">
<p>
<a href="https://huggingface.co/docs/transformers/run_scripts">https://huggingface.co/docs/transformers/run_scripts</a>
</p>
<ul class="org-ul">
<li><a href="https://github.com/huggingface/transformers/examples/pytorch/summarization/run_summarization.py">https://github.com/huggingface/transformers/examples/pytorch/summarization/run_summarization.py</a></li>
</ul>

<p>
<b>TensorFlow</b> scripts utilize a <b>MirroredStrategy</b> for distributed training
</p>

<p>
Accelerate:
</p>
<ul class="org-ul">
<li>pip install git+<a href="https://github.com/huggingface/accelerate">https://github.com/huggingface/accelerate</a></li>
<li>$ accelerate config</li>
<li>$ accelerate test</li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- single</span>
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config <span style="color: #95e454;">"3.0.0"</span> \
    --source_prefix <span style="color: #95e454;">"summarize: "</span> \
    --output_dir /tmp/tst-summarization \
    --<span style="color: #cae682;">per_device_train_batch_size</span>=4 \
    --<span style="color: #cae682;">per_device_eval_batch_size</span>=4 \
    --overwrite_output_dir \
    --predict_with_generate

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- distributed</span>
python -m torch.distributed.launch \
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \
    --fp16 \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config <span style="color: #95e454;">"3.0.0"</span> \
    --source_prefix <span style="color: #95e454;">"summarize: "</span> \
    --output_dir /tmp/tst-summarization \
    --<span style="color: #cae682;">per_device_train_batch_size</span>=4 \
    --<span style="color: #cae682;">per_device_eval_batch_size</span>=4 \
    --overwrite_output_dir \
    --predict_with_generate

<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">- acelerate</span>
accelerate launch run_summarization_no_trainer.py \
    --model_name_or_path t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config <span style="color: #95e454;">"3.0.0"</span> \
    --source_prefix <span style="color: #95e454;">"summarize: "</span> \
    --output_dir ~/tmp/tst-summarization
</pre>
</div>
</div>
</div>

<div id="outline-container-orgc75aab6" class="outline-4">
<h4 id="orgc75aab6"><span class="section-number-4">20.5.4.</span> installation log</h4>
<div class="outline-text-4" id="text-20-5-4">
<div class="org-src-container">
<pre class="src src-text">pip3 install transformers==4.24.0 --user
/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead
  from cryptography.utils import int_from_bytes
/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead
  from cryptography.utils import int_from_bytes
Collecting transformers==4.24.0
  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)
     &#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473;&#9473; 5.5/5.5 MB 349.8 kB/s eta 0:00:00
Requirement already satisfied: tqdm&gt;=4.27 in ./.local/lib/python3.8/site-packages (from transformers==4.24.0) (4.48.2)
Requirement already satisfied: packaging&gt;=20.0 in ./.local/lib/python3.8/site-packages (from transformers==4.24.0) (22.0)
Requirement already satisfied: tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 in ./.local/lib/python3.8/site-packages (from transformers==4.24.0) (0.12.1)
Requirement already satisfied: requests in ./.local/lib/python3.8/site-packages (from transformers==4.24.0) (2.28.1)
Requirement already satisfied: numpy&gt;=1.17 in ./.local/lib/python3.8/site-packages (from transformers==4.24.0) (1.24.0)
Requirement already satisfied: filelock in ./.local/lib/python3.8/site-packages (from transformers==4.24.0) (3.0.12)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.10.0 in ./.local/lib/python3.8/site-packages (from transformers==4.24.0) (0.10.0)
Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.8/site-packages (from transformers==4.24.0) (2022.9.13)
Requirement already satisfied: pyyaml&gt;=5.1 in ./.local/lib/python3.8/site-packages (from transformers==4.24.0) (5.4.1)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in ./.local/lib/python3.8/site-packages (from huggingface-hub&lt;1.0,&gt;=0.10.0-&gt;transformers==4.24.0) (4.4.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in ./.local/lib/python3.8/site-packages (from requests-&gt;transformers==4.24.0) (3.4)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in ./.local/lib/python3.8/site-packages (from requests-&gt;transformers==4.24.0) (2.1.1)
Requirement already satisfied: certifi&gt;=2017.4.17 in ./.local/lib/python3.8/site-packages (from requests-&gt;transformers==4.24.0) (2022.12.7)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in ./.local/lib/python3.8/site-packages (from requests-&gt;transformers==4.24.0) (1.26.13)
Installing collected packages: transformers
  Attempting uninstall: transformers
    Found existing installation: transformers 4.22.2
    Uninstalling transformers-4.22.2:
      Successfully uninstalled transformers-4.22.2
Successfully installed transformers-4.24.0
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org63465e1" class="outline-3">
<h3 id="org63465e1"><span class="section-number-3">20.6.</span> accelerate - DISTRIBUTED <a id="org1168f04"></a></h3>
<div class="outline-text-3" id="text-20-6">
<ol class="org-ol">
<li>accelerator.prepare(</li>
<li>replace   loss.backward() with accelerator.backward(loss)</li>
</ol>

<p>
The "correct" way to launch multi-node training is running $ accelerate launch my<sub>script.py</sub>
 &#x2013;accelerate<sub>config.yml</sub> on each machine
</p>
</div>
<div id="outline-container-orgb91d464" class="outline-4">
<h4 id="orgb91d464"><span class="section-number-4">20.6.1.</span> hello world</h4>
<div class="outline-text-4" id="text-20-6-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> accelerate <span style="color: #8ac6f2; font-weight: bold;">import</span> Accelerator

<span style="color: #cae682;">accelerator</span> = Accelerator()

<span style="color: #cae682;">train_dataloader</span>, <span style="color: #cae682;">eval_dataloader</span>, <span style="color: #cae682;">model</span>, <span style="color: #cae682;">optimizer</span> = accelerator.prepare(
    train_dataloader, eval_dataloader, model, optimizer
)

<span style="color: #8ac6f2; font-weight: bold;">for</span> epoch <span style="color: #8ac6f2; font-weight: bold;">in</span> <span style="color: #e5786d;">range</span>(num_epochs):
    <span style="color: #8ac6f2; font-weight: bold;">for</span> batch <span style="color: #8ac6f2; font-weight: bold;">in</span> train_dataloader:
        <span style="color: #cae682;">outputs</span> = model(**batch)
        <span style="color: #cae682;">loss</span> = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">-- replace the typical loss.backward() in your training loop with &#129303; Accelerate&#8217;s backwardmethod:</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org3222be8" class="outline-4">
<h4 id="org3222be8"><span class="section-number-4">20.6.2.</span> links</h4>
<div class="outline-text-4" id="text-20-6-2">
<ul class="org-ul">
<li><a href="https://huggingface.co/docs/transformers/accelerate">https://huggingface.co/docs/transformers/accelerate</a></li>
<li><a href="https://huggingface.co/blog/accelerate-large-models">https://huggingface.co/blog/accelerate-large-models</a></li>
<li><a href="https://huggingface.co/docs/accelerate/usage_guides/big_modeling">https://huggingface.co/docs/accelerate/usage_guides/big_modeling</a></li>
<li>multi-GPU <a href="https://huggingface.co/docs/accelerate/v0.12.0/en/basic_tutorials/notebook">https://huggingface.co/docs/accelerate/v0.12.0/en/basic_tutorials/notebook</a></li>
<li><a href="https://github.com/huggingface/accelerate/issues/1242">https://github.com/huggingface/accelerate/issues/1242</a></li>
<li><a href="https://github.com/huggingface/accelerate/issues/1185">https://github.com/huggingface/accelerate/issues/1185</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org45a63ee" class="outline-3">
<h3 id="org45a63ee"><span class="section-number-3">20.7.</span> PEFT - DISTRIBUTED</h3>
<div class="outline-text-3" id="text-20-7">
<p>
Parameter-Efficient Fine Tuning
methods freeze the pretrained model parameters during fine-tuning and add a small number of trainable
 parameters (the adapters) on top of it
</p>
<ul class="org-ul">
<li>very memory-efficient with lower compute usage while producing results comparable to a fully fine-tuned model.</li>
<li>leveraging DeepSpeed and Big Model Inference</li>
</ul>

<p>
severl Methods
</p>

<p>
integrated with <b>Accelerate</b> for large scale models leveraging <b>DeepSpeed</b> and Accelerate's Big Model Inferencing capabilities.
</p>
</div>

<div id="outline-container-org49c36f5" class="outline-4">
<h4 id="org49c36f5"><span class="section-number-4">20.7.1.</span> links</h4>
<div class="outline-text-4" id="text-20-7-1">
<ul class="org-ul">
<li><a href="https://huggingface.co/docs/peft/index">https://huggingface.co/docs/peft/index</a></li>
<li><a href="https://github.com/huggingface/peft">https://github.com/huggingface/peft</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org7c11d4d" class="outline-3">
<h3 id="org7c11d4d"><span class="section-number-3">20.8.</span> TRL <a id="orgf0c5b84"></a></h3>
<div class="outline-text-3" id="text-20-8">
<p>
Transformer Reinforcement Learning
</p>

<p>
train transformer language models and stable diffusion models with Reinforcement Learning, from the Supervised
</p>
<ul class="org-ul">
<li>Fine-tuning step (SFT)</li>
<li>Reward Modeling step (RM)</li>
<li>Proximal Policy Optimization (PPO)</li>
</ul>
<p>
see [[<a href="data_science#MissingReference">data_science#MissingReference</a>]]
</p>

<p>
also to fine-tune a model to
</p>
<ul class="org-ul">
<li>generate positive movie reviews, <a href="https://huggingface.co/docs/trl/sentiment_tuning">https://huggingface.co/docs/trl/sentiment_tuning</a></li>
<li>do controlled generation <a href="https://github.com/lvwerra/trl/blob/main/examples/sentiment/notebooks/gpt2-sentiment-control.ipynb">https://github.com/lvwerra/trl/blob/main/examples/sentiment/notebooks/gpt2-sentiment-control.ipynb</a></li>
<li>make the model less toxic. <a href="https://huggingface.co/docs/trl/detoxifying_a_lm">https://huggingface.co/docs/trl/detoxifying_a_lm</a></li>
</ul>

<p>
<b>Allow distributed</b> - leverage accelerate from the Hugging Face ecosystem to make this possible
</p>
</div>

<div id="outline-container-org6190699" class="outline-4">
<h4 id="org6190699"><span class="section-number-4">20.8.1.</span> links</h4>
<div class="outline-text-4" id="text-20-8-1">
<ul class="org-ul">
<li><a href="https://pypi.org/project/trl/">https://pypi.org/project/trl/</a></li>
<li><a href="https://huggingface.co/docs/trl/main/en/index">https://huggingface.co/docs/trl/main/en/index</a></li>
<li><a href="https://huggingface.co/blog/trl-peft">https://huggingface.co/blog/trl-peft</a></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org5a04bb5" class="outline-3">
<h3 id="org5a04bb5"><span class="section-number-3">20.9.</span> Spaces</h3>
<div class="outline-text-3" id="text-20-9">
<p>
showcase your work in the form of self contained ML demo apps
</p>

<p>
you can choose any licence type
</p>

<p>
SDK. At the time of writing you can pick from two Python based frameworks for hosting apps: Gradio or
Streamlit. Alternatively you can just use custom HTML.
</p>
</div>
</div>
<div id="outline-container-org2bbda99" class="outline-3">
<h3 id="org2bbda99"><span class="section-number-3">20.10.</span> cache and offline mode</h3>
<div class="outline-text-3" id="text-20-10">
</div>
<div id="outline-container-org6eac56b" class="outline-4">
<h4 id="org6eac56b"><span class="section-number-4">20.10.1.</span> transformers</h4>
<div class="outline-text-4" id="text-20-10-1">
<ul class="org-ul">
<li>~/.cache/huggingface/hub <a href="https://huggingface.co/docs/transformers/installation?highlight=transformers_cache#cache-setup">https://huggingface.co/docs/transformers/installation?highlight=transformers_cache#cache-setup</a></li>
</ul>

<p>
offline
</p>
<ol class="org-ol">
<li>env: TRANSFORMERS<sub>OFFLINE</sub>=1 HF<sub>DATASETS</sub><sub>OFFLINE</sub>=1.</li>
</ol>
<pre class="example">
HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...
</pre>

<ol class="org-ol">
<li>save<sub>pretrainde</sub> and from<sub>pretrained</sub>
<ul class="org-ul">
<li>default with download:</li>
</ul></li>
</ol>
<pre class="example">
AutoTokenizer.from_pretrained("bigscience/T0_3B") ; AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0_3B")
</pre>

<ul class="org-ul">
<li>save:</li>
</ul>
<pre class="example">
.save_pretrained("./your/path/bigscience_t0") ; .save_pretrained("./your/path/bigscience_t0")
</pre>

<ul class="org-ul">
<li>offline use:</li>
</ul>
<pre class="example">
.from_pretrained("./your/path/bigscience_t0") ; .from_pretrained("./your/path/bigscience_t0")
</pre>

<ol class="org-ol">
<li>huggingface<sub>hub</sub>
<ol class="org-ol">
<li>python -m pip install huggingface<sub>hub</sub></li>
<li>from huggingface<sub>hub</sub> import hf<sub>hub</sub><sub>download</sub></li>
<li>hf<sub>hub</sub><sub>download</sub>(repo<sub>id</sub>="bigscience/T0<sub>3B</sub>", filename="config.json", cache<sub>dir</sub>="./your/path/bigscience<sub>t0</sub>")</li>
</ol></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orge8563c5" class="outline-3">
<h3 id="orge8563c5"><span class="section-number-3">20.11.</span> Main concepts</h3>
<div class="outline-text-3" id="text-20-11">
<p>
<b>Model classes</b>
</p>
<ul class="org-ul">
<li>PyTorch models (torch.nn.Module</li>
<li>Keras models (tf.keras.Model)</li>
<li>JAX/Flax models (flax.linen.Module)</li>
</ul>

<p>
<b>Configuration classes</b> - store the hyperparameters required to build a model (such as the number of layers
  and hidden size).
</p>
<ul class="org-ul">
<li>pretrained model has Configuration class inside</li>
</ul>

<p>
<b>Preprocessing classes</b> - convert the raw data into a format accepted by the model.
</p>
<ul class="org-ul">
<li>tokenizer - strings</li>
<li>Image processors - vision inputs</li>
<li>feature extractors - audio inputs</li>
<li>processor - multimodal inputs</li>
</ul>
</div>
</div>
<div id="outline-container-org4b48c56" class="outline-3">
<h3 id="org4b48c56"><span class="section-number-3">20.12.</span> problems:</h3>
<div class="outline-text-3" id="text-20-12">
<p>
requests.exceptions.SSLError: HTTPSConnectioPool(host='huggingface.co', port=443): Max retries exceeded with url
</p>
</div>
</div>

<div id="outline-container-orgfc91bde" class="outline-3">
<h3 id="orgfc91bde"><span class="section-number-3">20.13.</span> pip install gradio<sub>client</sub></h3>
<div class="outline-text-3" id="text-20-13">
<p>
to quickly build a demo or web application for your machine learning model
</p>

<p>
<a href="https://github.com/gradio-app/gradio">https://github.com/gradio-app/gradio</a>
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">import</span> sys
<span style="color: #8ac6f2; font-weight: bold;">import</span> time
<span style="color: #8ac6f2; font-weight: bold;">from</span> gradio_client <span style="color: #8ac6f2; font-weight: bold;">import</span> Client

<span style="color: #cae682;">client</span> = Client(<span style="color: #95e454;">"ysharma/Explore_llamav2_with_TGI"</span>, hf_token=<span style="color: #95e454;">"hf_..."</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">client = Client("abidlabs/my-private-space", hf_token="...")</span>
<span style="color: #cae682;">result</span> = client.predict(
                                <span style="color: #95e454;">"Howdy!"</span>,       <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">str in 'parameter_6' Textbox component</span>
                                api_name=<span style="color: #95e454;">"/chat"</span>
)
<span style="color: #cae682;">job</span> = client.submit(<span style="color: #e5786d;">str</span>(sys.argv[1:]), api_name=<span style="color: #95e454;">"/chat"</span>)
<span style="color: #8ac6f2; font-weight: bold;">while</span> <span style="color: #8ac6f2; font-weight: bold;">not</span> job.done():
    time.sleep(0.5)
    <span style="color: #e5786d;">print</span>(job.outputs()[-1])
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">info about api:</span>
client.view_api(return_format=<span style="color: #95e454;">"dict"</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">not working:</span>
<span style="color: #cae682;">result</span> = client.predict(<span style="color: #95e454;">"How are you, I am fine, can you cum?"</span>)
<span style="color: #e5786d;">print</span>(result)
</pre>
</div>

<ul class="org-ul">
<li>upload<sub>url</sub> = self.src, utils.UPLOAD<sub>URL</sub>)</li>
<li>reset<sub>url</sub> = self.src, utils.RESET<sub>URL</sub>)</li>
<li>api<sub>url</sub> = self.src, utils.API<sub>URL</sub></li>
<li>api<sub>info</sub><sub>url</sub> = self.src, API<sub>INFO</sub><sub>URL</sub> or utils.RAW<sub>API</sub><sub>INFO</sub><sub>URL</sub></li>
</ul>
</div>
</div>

<div id="outline-container-org78c7815" class="outline-3">
<h3 id="org78c7815"><span class="section-number-3">20.14.</span> sci-libs/huggingface<sub>hub</sub></h3>
<div class="outline-text-3" id="text-20-14">
<p>
pip install huggingface<sub>hub</sub>[inference] An async version of the client is also provided, based on asyncio and aiohttp. You can either install aiohttp directly or use the [inference].
</p>

<div class="org-src-container">
<pre class="src src-sh">pip install huggingface_hub[inference]
<span style="color: #e5786d;">export</span> <span style="color: #cae682;">HUGGINGFACE_TOKEN</span>=?? <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">not password</span>
huggingface-cli login --token $<span style="color: #cae682;">HUGGINGFACE_TOKEN</span>
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">Your token has been saved to ~/.cache/huggingface/token</span>
</pre>
</div>

<p>
text-generation-inference backend (TGI) - ? <a href="https://github.com/huggingface/text-generation-inference">https://github.com/huggingface/text-generation-inference</a>.
</p>

<p>
 transformers + api-inference solution is still in use. - ?
from huggingface<sub>hub</sub> import <b>InferenceClient</b> access to:
</p>
<ul class="org-ul">
<li>Inference API -  Hugging Face’s infrastructure for free &gt;10GB</li>
<li>Inference Endpoints -  a cloud provider of your choice.</li>
</ul>

<p>
tasks:
</p>
<ul class="org-ul">
<li>question-answering</li>
<li>text-generation</li>
</ul>

<p>
<b>client.text<sub>generation</sub></b> calls <b>client.post</b>
</p>
</div>
<ol class="org-ol">
<li><a id="org098edb9"></a>tasks<br />
<div class="outline-text-5" id="text-20-14-0-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> huggingface_hub <span style="color: #8ac6f2; font-weight: bold;">import</span> InferenceClient
<span style="color: #cae682;">client</span> = InferenceClient()
[<span style="color: #e5786d;">print</span>(x) <span style="color: #8ac6f2; font-weight: bold;">for</span> x <span style="color: #8ac6f2; font-weight: bold;">in</span> client.list_deployed_models()]
</pre>
</div>

<pre class="example" id="org7ccbe54">
image-to-image
text-to-image
automatic-speech-recognition
fill-mask
feature-extraction
summarization
translation
text-to-audio
text-to-speech
text-generation
image-classification
image-segmentation
image-to-text
object-detection
question-answering
text2text-generation
token-classification
table-question-answering
text-classification
zero-shot-classification
zero-shot-image-classification
image-text-to-text
sentence-similarity
</pre>
</div>
</li>

<li><a id="org9c71ad8"></a>tasks-model <a id="org705817f"></a><br />
<div class="outline-text-5" id="text-20-14-0-2">
<div class="org-src-container">
<pre class="src src-bash"><span style="color: #e5786d;">alias</span> <span style="color: #cae682;">curl</span>=<span style="color: #95e454;">"proxychains -f /home/u/proxychains.conf curl 2&gt;/dev/null"</span>
curl https://huggingface.co/api/tasks |jq -M
</pre>
</div>
</div>
</li>

<li><a id="org7762ee7"></a>url from model and task:<br />
<div class="outline-text-5" id="text-20-14-0-3">
<p>
_HF<sub>DEFAULT</sub><sub>ENDPOINT</sub> = "<a href="https://huggingface.co">https://huggingface.co</a>"
</p>

<p>
INFERENCE<sub>ENDPOINT</sub> <a href="https://api-inference.huggingface.co">https://api-inference.huggingface.co</a>
</p>

<p>
if task in ("feature-extraction", "sentence-similarity")
</p>
<ul class="org-ul">
<li>f"{INFERENCE<sub>ENDPOINT</sub>}/pipeline/{task}/{model}"</li>
<li>else f"{INFERENCE<sub>ENDPOINT</sub>}/models/{model}"</li>
</ul>
</div>
</li>
<li><a id="orga2dd0c2"></a>InferenceClient<br />
<div class="outline-text-5" id="text-20-14-0-4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> huggingface_hub <span style="color: #8ac6f2; font-weight: bold;">import</span> InferenceClient
<span style="color: #cae682;">client</span> = InferenceClient()
<span style="color: #cae682;">image</span> = client.text_to_image(<span style="color: #95e454;">"An astronaut riding a horse on the moon."</span>)
image.save(<span style="color: #95e454;">"astronaut.png"</span>)
</pre>
</div>
</div>
</li>
<li><a id="org3a3dc52"></a>InferenceClient my<br />
<div class="outline-text-5" id="text-20-14-0-5">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> huggingface_hub <span style="color: #8ac6f2; font-weight: bold;">import</span> InferenceClient
<span style="color: #cae682;">client</span> = InferenceClient(model=<span style="color: #95e454;">"upstage/llama-30b-instruct-2048"</span>, token=<span style="color: #e5786d; font-weight: bold;">True</span>, timeout=25, headers={}, cookies={})
<span style="color: #cae682;">o</span> = client.text_generation(prompt=<span style="color: #95e454;">"An astronaut riding a horse on the moon?"</span>)

</pre>
</div>
</div>
</li>

<li><a id="org3fd5c50"></a>InferenceClient Async my<br />
<div class="outline-text-5" id="text-20-14-0-6">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> huggingface_hub <span style="color: #8ac6f2; font-weight: bold;">import</span> AsyncInferenceClient
<span style="color: #cae682;">client</span> = AsyncInferenceClient(model=<span style="color: #95e454;">"upstage/llama-30b-instruct-2048"</span>, token=<span style="color: #e5786d; font-weight: bold;">True</span>, timeout=25, headers={}, cookies={})
<span style="color: #cae682;">o</span> = <span style="color: #8ac6f2; font-weight: bold;">await</span> client.text_generation(prompt=<span style="color: #95e454;">"An astronaut riding a horse on the moon?"</span>)

</pre>
</div>
</div>
</li>
<li><a id="org1f69e2e"></a>InferenceClient post<br />
<div class="outline-text-5" id="text-20-14-0-7">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">from</span> huggingface_hub <span style="color: #8ac6f2; font-weight: bold;">import</span> InferenceClient
<span style="color: #cae682;">client</span> = InferenceClient(model=<span style="color: #95e454;">"meta-llama/Meta-Llama-3-8B"</span>, token=<span style="color: #e5786d; font-weight: bold;">True</span>, timeout=25, headers={}, cookies={})
<span style="color: #cae682;">o</span> = client.text_generation(prompt=<span style="color: #95e454;">"An astronaut riding a horse on the moon?"</span>)
<span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">response = client.post(json={"inputs": "An astronaut riding a horse on the moon."}, model="stabilityai/stable-diffusion-2-1")</span>
response.content

</pre>
</div>
</div>
</li>
<li><a id="org2bb89cb"></a>curl<br />
<div class="outline-text-5" id="text-20-14-0-8">
<p>
curl -X POST
-H “Authorization: Bearer api<sub>xxxxxxxxxxxxxxxxxxxxxxx</sub>”
-H “Content-Type: application/json”
-d ‘“My name is Mariama, my favorite”’
<a href="https://api-inference.huggingface.co/models/gpt2">https://api-inference.huggingface.co/models/gpt2</a>
</p>

<p>
" curl -X POST
-H “Authorization: Bearer api<sub>xxxxxxxxxxxxxxxxxxxxxxx</sub>”
-H “Content-Type: application/json”
-d ‘“My name is Mariama, my favorite”’
-d “max<sub>length</sub> = 30”
htt/api-inference.huggingface.co/models/gpt2 "
</p>

<p>
curl -N 127.0.0.1:8080/generate<sub>stream</sub> \
    -X POST \
    -d '{"inputs":"What is Deep Learning?","parameters":{"max<sub>new</sub><sub>tokens</sub>":20}}' \
    -H 'Content-Type: application/json'
</p>

<p>
import requests
</p>

<p>
def query(payload, model<sub>id</sub>, api<sub>token</sub>):
	headers = {"Authorization": f"Bearer {api<sub>token</sub>}"}
	API<sub>URL</sub> = f"<a href="https://api-inference.huggingface.co/models/%7Bmodel_id">https://api-inference.huggingface.co/models/%7Bmodel_id</a>}"
	response = requests.post(API<sub>URL</sub>, headers=headers, json=payload)
	return response.json()
</p>

<p>
model<sub>id</sub> = "distilbert-base-uncased"
api<sub>token</sub> = "hf<sub>XXXXXXXX</sub>" # get yours at hf.co/settings/tokens
data = query("The goal of life is [MASK].", model<sub>id</sub>, api<sub>token</sub>)
</p>


<p>
GET "<a href="https://huggingface.co/api/tasks">https://huggingface.co/api/tasks</a>"
</p>
</div>
</li>

<li><a id="org8efb89a"></a>links<br />
<div class="outline-text-5" id="text-20-14-0-9">
<ul class="org-ul">
<li><a href="file:///var/db/repos/gentoo/sci-libs/huggingface_hub/huggingface_hub-0.15.1.ebuild">file:///var/db/repos/gentoo/sci-libs/huggingface_hub/huggingface_hub-0.15.1.ebuild</a></li>
<li><a href="https://huggingface.co/docs/huggingface_hub/v0.16.3/en/package_reference/inference_client">https://huggingface.co/docs/huggingface_hub/v0.16.3/en/package_reference/inference_client</a></li>
<li><a href="https://huggingface.co/docs/huggingface_hub/v0.16.3/en/guides/inference">https://huggingface.co/docs/huggingface_hub/v0.16.3/en/guides/inference</a></li>
<li><a href="https://github.com/huggingface/huggingface_hub/blob/v0.16.3/src/huggingface_hub/inference/_client.py#L239">https://github.com/huggingface/huggingface_hub/blob/v0.16.3/src/huggingface_hub/inference/_client.py#L239</a></li>
</ul>
</div>
</li>
</ol>
<div id="outline-container-org47842c2" class="outline-4">
<h4 id="org47842c2"><span class="section-number-4">20.14.1.</span> links</h4>
<div class="outline-text-4" id="text-20-14-1">
<p>
free inference with spaces:
</p>
<ul class="org-ul">
<li><a href="https://huggingface.co/spaces">https://huggingface.co/spaces</a></li>
<li><a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard">https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard</a></li>
<li>.local/lib/python3.11/site-packages/huggingface<sub>hub</sub>/inference/<sub>client.py</sub></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgadad17b" class="outline-3">
<h3 id="orgadad17b"><span class="section-number-3">20.15.</span> autotrain</h3>
<div class="outline-text-3" id="text-20-15">
<ol class="org-ol">
<li><a href="https://huggingface.co/autotrain">https://huggingface.co/autotrain</a></li>
<li><a href="https://ui.autotrain.huggingface.co/">https://ui.autotrain.huggingface.co/</a></li>
</ol>

<p>
workflow
</p>
<ol class="org-ol">
<li>Task
<ul class="org-ul">
<li>Vision
<ul class="org-ul">
<li>Image Classification - 	is the task of classifying images into an arbitrary number of groups.</li>
</ul></li>
<li>Text
<ul class="org-ul">
<li>Text Classification (Binary) -  is the task of classifying texts into two distinct groups.</li>
<li>Text Classification (Multi-class) - 	is the task of classifying texts into an arbitrary number of groups, each sample belonging to only one group</li>
<li>Token Classification - is the task of classifying certain entities (persons, locations, nouns, verbs&#x2026;) present in a text into a given number of groups.</li>
<li>Question Answering (Extractive) - 	is the task of retrieving the answer to a question from a context</li>
<li>Translation - 	is the task of translating a text from a language to another</li>
<li>Summarization - 	is the task of summarizing a document or an article into a shorter text.</li>
<li>Text Regression - 	is the task of attributing a score to a text.</li>
</ul></li>
<li>Tabular
<ul class="org-ul">
<li>Tabular Data Classification (Binary)  is the task of classifying tabular data into an arbitrary number of groups, each sample belonging to only one group.</li>
<li>Tabular Data Classification (Multi-class) 	is the task of classifying tabular data into an arbitrary number of groups, and each sample can belong to several groups.</li>
<li>Tabular Data Regression 	is the task of attributing a score to tabular data.</li>
</ul></li>
</ul></li>
<li>Model choice (Automatic, Manual)</li>
<li>Data
<ul class="org-ul">
<li>Method 1: Pre-arranged folders</li>
<li>Method 2: CSV/JSONL with associated images</li>
</ul></li>
</ol>
</div>
</div>

<div id="outline-container-org5a21c40" class="outline-3">
<h3 id="org5a21c40"><span class="section-number-3">20.16.</span> AutoTokenizer.from<sub>pretrained</sub></h3>
<div class="outline-text-3" id="text-20-16">
<pre class="example">
from transformers import AutoTokenizer, AutoModel
</pre>

<p>
Vocabulary Loading: Load the vocabulary from vocab.json.
Merges Loading: Load the merges file if applicable (e.g., for WordPiece tokenizers).
Configuration Loading: Load the tokenizer configuration from tokenizer<sub>config.json</sub>.
Encoding Logic: Implement the encoding logic within the encode method. This example is simplified and may need additional handling for special tokens, padding, and other edge cases.
</p>
</div>
</div>
<div id="outline-container-org0034747" class="outline-3">
<h3 id="org0034747"><span class="section-number-3">20.17.</span> AutoModel.from<sub>pretrained</sub></h3>
</div>
<div id="outline-container-org83914ae" class="outline-3">
<h3 id="org83914ae"><span class="section-number-3">20.18.</span> gentoo transformers installation</h3>
<div class="outline-text-3" id="text-20-18">
<p>
emerge &#x2013;ask sci-libs/transformers
</p>

<div class="org-src-container">
<pre class="src src-conf">[<span style="color: #92a65e; font-weight: bold;">ebuild  N    ~</span>] sci-libs/transformers-4.37.2  USE=<span style="color: #95e454;">"-test"</span> PYTHON_SINGLE_TARGET=<span style="color: #95e454;">"python3_12 -python3_10 -python3_11"</span>
[<span style="color: #92a65e; font-weight: bold;">ebuild  N    ~</span>]  sci-libs/safetensors-0.4.3  USE=<span style="color: #95e454;">"-debug -test"</span> PYTHON_TARGETS=<span style="color: #95e454;">"python3_12 -python3_10 -python3_11"</span>
[<span style="color: #92a65e; font-weight: bold;">ebuild  N    ~</span>]  sci-libs/tokenizers-0.15.2-r1  USE=<span style="color: #95e454;">"-debug -test"</span> PYTHON_SINGLE_TARGET=<span style="color: #95e454;">"python3_12 -python3_10 -python3_11"</span>
[<span style="color: #92a65e; font-weight: bold;">ebuild  N    ~</span>]  sci-libs/huggingface_hub-0.21.4  USE=<span style="color: #95e454;">"-test"</span> PYTHON_TARGETS=<span style="color: #95e454;">"python3_12 -python3_10 -python3_11"</span>
[<span style="color: #92a65e; font-weight: bold;">ebuild  N     </span>]   dev-python/filelock-3.15.4  USE=<span style="color: #95e454;">"-test"</span> PYTHON_TARGETS=<span style="color: #95e454;">"python3_12 (-pypy3) -python3_10 -python3_11 (-python3_13)"</span>
[<span style="color: #92a65e; font-weight: bold;">ebuild  N     </span>]   dev-python/tqdm-4.66.4  USE=<span style="color: #95e454;">"-examples -test"</span> PYTHON_TARGETS=<span style="color: #95e454;">"python3_12 (-pypy3) -python3_10 -python3_11 (-python3_13)"</span>
[<span style="color: #92a65e; font-weight: bold;">ebuild  N     </span>]  dev-python/regex-2024.7.24  USE=<span style="color: #95e454;">"-debug -doc -test"</span> PYTHON_TARGETS=<span style="color: #95e454;">"python3_12 -python3_10 -python3_11 (-python3_13)"</span>
</pre>
</div>

<p>
^0.2.143 - at least the specified version but can be any version that does not break backward compatibility.
</p>

<p>
<a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a>
</p>
<ul class="org-ul">
<li>safetensors <a href="https://github.com/huggingface/safetensors">https://github.com/huggingface/safetensors</a>
<ul class="org-ul">
<li>store and distribute tensors</li>
<li>Big amount of Rust Carge open-source dependencies.</li>
<li><a href="https://github.com/huggingface/safetensors/blob/main/safetensors/Cargo.toml">https://github.com/huggingface/safetensors/blob/main/safetensors/Cargo.toml</a>
<ul class="org-ul">
<li>numpy&gt;=1.21.6</li>
<li>torch&gt;=1.10</li>
<li>pyo3 version = "0.21.1", features = ["extension-module"] c v0.22.2 <a href="https://github.com/PyO3/pyo3/blob/v0.21.1/Cargo.toml">https://github.com/PyO3/pyo3/blob/v0.21.1/Cargo.toml</a>
<ul class="org-ul">
<li>pyo3-build-config v0.21.1
<ul class="org-ul">
<li>target-lexicon ^0.12 c v0.12.16</li>
<li>once<sub>cell</sub> ^1 c v1.19.0</li>
</ul></li>
<li>cfg-if ^1.0 c v1.0.0</li>
<li>libc ^0.2.62 c v0.2.158</li>
<li>memoffset ^0.9 c v0.9.1
<ul class="org-ul">
<li>autocfg ^1 c v1.3.0</li>
</ul></li>
<li>parking<sub>lot</sub> &gt;=0.11 &lt;0.13 (for old) c v0.12.3
<ul class="org-ul">
<li>lock<sub>api</sub> ^0.4.6 c v0.4.12
<ul class="org-ul">
<li>scopeguard ^1.1.0 c v1.2.0</li>
</ul></li>
<li>parking<sub>lot</sub><sub>core</sub> ^0.9.0 c v0.9.10 <a href="https://github.com/Amanieu/parking_lot/tree/master/core">https://github.com/Amanieu/parking_lot/tree/master/core</a>
<ul class="org-ul">
<li>cfg-if ^1.0.0 c v1.0.0</li>
<li>libc</li>
<li>redox<sub>syscall</sub> ^0.5 c v0.5.3
<ul class="org-ul">
<li>bitflags ^2.4</li>
</ul></li>
<li>smallvec ^1.6.1 c v1.13.2</li>
<li>windows-targets ^0.52.0 c v0.52.6</li>
</ul></li>
</ul></li>
<li>(once<sub>cell</sub> for new version ^1.13 c v1.19.0)</li>
<li>portable-atomic ^1.0 c v1.7.0</li>
<li>pyo3-ffi =0.21.1 c =0.22.2 (it is features = ["extension-module"])</li>
<li>indexmap (optional) c &gt;=1.6 &lt;3</li>
</ul></li>
<li>memmap2 "0.9" c v0.9.4https://crates.io/crates/memmap2
<ul class="org-ul">
<li>libc ^0.2.143 c v0.2.158</li>
</ul></li>
<li>serde  ="1.0", features = ["derive"]} c v1.0.209 l v1.0.197 <a href="https://github.com/serde-rs/serde">https://github.com/serde-rs/serde</a>  <a href="https://crates.io/crates/serde">https://crates.io/crates/serde</a>
<ul class="org-ul">
<li>serde<sub>derive</sub> ="1.0" (optional) <a href="https://crates.io/crates/serde_derive">https://crates.io/crates/serde_derive</a>
<ul class="org-ul">
<li>proc-macro2 (for new version) ^1.0.74 v1.0.86
<ul class="org-ul">
<li>unicode-ident ^1.0 c v1.0.12</li>
</ul></li>
<li>quote ^0.3.8 c v0.3.15</li>
<li>serde<sub>derive</sub><sub>internals</sub> = v0.15.0 (for old)</li>
<li>syn ^2.0.46 c v2.0.77</li>
</ul></li>
<li>syn ^0.11 c v0.11.11 (for old)</li>
</ul></li>
<li>serde<sub>json</sub> 1.0 c v1.0.127 <a href="https://github.com/serde-rs/json">https://github.com/serde-rs/json</a> <a href="https://crates.io/crates/serde_json">https://crates.io/crates/serde_json</a>
<ul class="org-ul">
<li>itoa ^1.0 c v1.0.11</li>
<li>memchr ^2 c v2.7.4</li>
<li>ryu ^1.0 c v1.0.18</li>
<li>indexmap (optional) ^2.2.3 c v2.5.0 - A hash table with consistent order and fast iteration.
<ul class="org-ul">
<li>equivalent</li>
<li>hashbrown</li>
<li>arbitrary</li>
<li>borsh</li>
<li>quickcheck</li>
<li>rayon</li>
<li>rustc-rayon (optional)</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>tokenizers <a href="https://github.com/huggingface/tokenizers">https://github.com/huggingface/tokenizers</a>
<ul class="org-ul">
<li>Provides an implementation of today's most used tokenizers,</li>
<li>Big amount of Rust Carge open-source dependencies.</li>
</ul></li>
<li>huggingface<sub>hub</sub> <a href="https://github.com/huggingface/huggingface_hub">https://github.com/huggingface/huggingface_hub</a>
<ul class="org-ul">
<li>Python client for the Huggingface Hub.</li>
</ul></li>
<li>dev-python/regex</li>
</ul>
</div>
<div id="outline-container-org1c24a91" class="outline-4">
<h4 id="org1c24a91"><span class="section-number-4">20.18.1.</span> setup.py and gentoo ebuild</h4>
<div class="outline-text-4" id="text-20-18-1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #cae682;">install_requires</span> = [
    deps[<span style="color: #95e454;">"filelock"</span>],  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">filesystem locks, e.g., to prevent parallel downloads</span>
    deps[<span style="color: #95e454;">"huggingface-hub"</span>],
    deps[<span style="color: #95e454;">"numpy"</span>],
    deps[<span style="color: #95e454;">"packaging"</span>],  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">utilities from PyPA to e.g., compare versions</span>
    deps[<span style="color: #95e454;">"pyyaml"</span>],  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">used for the model cards metadata</span>
    deps[<span style="color: #95e454;">"regex"</span>],  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">for OpenAI GPT</span>
    deps[<span style="color: #95e454;">"requests"</span>],  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">for downloading models over HTTPS</span>
    deps[<span style="color: #95e454;">"tokenizers"</span>],
    deps[<span style="color: #95e454;">"safetensors"</span>],
    deps[<span style="color: #95e454;">"tqdm"</span>],  <span style="color: #fa8072;"># </span><span style="color: #99968b; font-style: italic;">progress bars in model download and training scripts</span>
]
</pre>
</div>

<div class="org-src-container">
<pre class="src src-conf"><span style="color: #cae682;">RDEPEND</span>=<span style="color: #95e454;">"</span>
<span style="color: #95e454;">        sci-libs/tokenizers[${PYTHON_SINGLE_USEDEP}]</span>
<span style="color: #95e454;">        $(python_gen_cond_dep '</span>
<span style="color: #95e454;">                dev-python/filelock[${PYTHON_USEDEP}]</span>
<span style="color: #95e454;">                dev-python/numpy[${PYTHON_USEDEP}]</span>
<span style="color: #95e454;">                dev-python/packaging[${PYTHON_USEDEP}]</span>
<span style="color: #95e454;">                dev-python/pyyaml[${PYTHON_USEDEP}]</span>
<span style="color: #95e454;">                dev-python/regex[${PYTHON_USEDEP}]</span>
<span style="color: #95e454;">                dev-python/requests[${PYTHON_USEDEP}]</span>
<span style="color: #95e454;">                dev-python/tqdm[${PYTHON_USEDEP}]</span>
<span style="color: #95e454;">                sci-libs/huggingface_hub[${PYTHON_USEDEP}]</span>
<span style="color: #95e454;">                &gt;=sci-libs/safetensors-0.4.1[${PYTHON_USEDEP}]</span>
<span style="color: #95e454;">        ')</span>
<span style="color: #95e454;">"</span>
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org73a93b3" class="outline-3">
<h3 id="org73a93b3"><span class="section-number-3">20.19.</span> troubleshooting</h3>
<div class="outline-text-3" id="text-20-19">
</div>
<div id="outline-container-org61d0476" class="outline-4">
<h4 id="org61d0476"><span class="section-number-4">20.19.1.</span> TypeError: unhashable type: 'AddedToken' in transformers/tokenization<sub>utils.py</sub>", line 437</h4>
<div class="outline-text-4" id="text-20-19-1">
<ul class="org-ul">
<li>if we use fast version of Tokenizer. from tokenizers import AddedToken - used, which have hash function</li>
</ul>

<p>
to tokenization<sub>utils</sub><sub>base.py</sub>::84 we just add to class AddedToken
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__hash__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>):
    <span style="color: #8ac6f2; font-weight: bold;">return</span> <span style="color: #e5786d;">hash</span>((<span style="color: #8ac6f2; font-weight: bold;">self</span>.content, <span style="color: #8ac6f2; font-weight: bold;">self</span>.single_word, <span style="color: #8ac6f2; font-weight: bold;">self</span>.lstrip, <span style="color: #8ac6f2; font-weight: bold;">self</span>.rstrip, <span style="color: #8ac6f2; font-weight: bold;">self</span>.special, <span style="color: #8ac6f2; font-weight: bold;">self</span>.normalized))

<span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__eq__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, other):
    <span style="color: #8ac6f2; font-weight: bold;">if</span> <span style="color: #8ac6f2; font-weight: bold;">not</span> <span style="color: #e5786d;">isinstance</span>(other, AddedToken):
        <span style="color: #8ac6f2; font-weight: bold;">return</span> <span style="color: #e5786d; font-weight: bold;">False</span>
    <span style="color: #8ac6f2; font-weight: bold;">return</span> (<span style="color: #8ac6f2; font-weight: bold;">self</span>.content, <span style="color: #8ac6f2; font-weight: bold;">self</span>.single_word, <span style="color: #8ac6f2; font-weight: bold;">self</span>.lstrip, <span style="color: #8ac6f2; font-weight: bold;">self</span>.rstrip, <span style="color: #8ac6f2; font-weight: bold;">self</span>.special, <span style="color: #8ac6f2; font-weight: bold;">self</span>.normalized) == (
        other.content, other.single_word, other.lstrip, other.rstrip, other.special, other.normalized
    )
</pre>
</div>
</div>
</div>
<div id="outline-container-org765f496" class="outline-4">
<h4 id="org765f496"><span class="section-number-4">20.19.2.</span> AttributeError: 'AddedToken' object has no attribute '<span class="underline"><span class="underline">setstate</span></span>'. Did you mean: '<span class="underline"><span class="underline">getstate</span></span>'?</h4>
<div class="outline-text-4" id="text-20-19-2">
<pre class="example">
token.__setstate__({"special": True, "normalized": token.normalized})
</pre>


<p>
add to class AddedToken tokenization<sub>utils.py</sub>
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #8ac6f2; font-weight: bold;">def</span> <span style="color: #cae682; font-weight: bold;">__setstate__</span>(<span style="color: #8ac6f2; font-weight: bold;">self</span>, state):
    <span style="color: #8ac6f2; font-weight: bold;">self</span>.<span style="color: #e5786d;">__dict__</span>.update(state)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-orgd120938" class="outline-3">
<h3 id="orgd120938"><span class="section-number-3">20.20.</span> distributed</h3>
<div class="outline-text-3" id="text-20-20">
<p>
<a href="https://huggingface.co/docs/accelerate/index">https://huggingface.co/docs/accelerate/index</a>
</p>
<ul class="org-ul">
<li><a href="https://github.com/microsoft/DeepSpeed/">https://github.com/microsoft/DeepSpeed/</a></li>
</ul>
</div>
</div>

<div id="outline-container-org6c12ceb" class="outline-3">
<h3 id="org6c12ceb"><span class="section-number-3">20.21.</span> Text embeddings models</h3>
<div class="outline-text-3" id="text-20-21">
<p>
<a href="https://huggingface.co/thenlper/gte-small">https://huggingface.co/thenlper/gte-small</a>
</p>

<p>
output - class BaseModelOutputWithPoolingAndCrossAttentions(ModelOutput)
</p>
<ul class="org-ul">
<li>class ModelOutput(OrderedDict)</li>
</ul>

<p>
file: transformers/modeling<sub>outputs.py</sub>::70
</p>

<p>
doc <a href="https://huggingface.co/docs/transformers/main_classes/output">https://huggingface.co/docs/transformers/main_classes/output</a>
</p>
</div>
</div>
<div id="outline-container-orgd09095a" class="outline-3">
<h3 id="orgd09095a"><span class="section-number-3">20.22.</span> links</h3>
<div class="outline-text-3" id="text-20-22">
<ul class="org-ul">
<li><a href="https://huggingface.co/docs/transformers/create_a_model">https://huggingface.co/docs/transformers/create_a_model</a></li>
<li><a href="https://huggingface.co/docs/huggingface_hub/index">https://huggingface.co/docs/huggingface_hub/index</a></li>
</ul>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2025-01-14 Tue 13:11</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
